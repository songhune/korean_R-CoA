{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "benchmark_overview",
   "metadata": {},
   "source": [
    "# K-ClassicBench: 한국 고전 문헌 이해 벤치마크\n",
    "\n",
    "**C3Bench 기반 한국형 고전 문헌 벤치마크**\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 프로젝트 개요\n",
    "\n",
    "K-ClassicBench는 중국의 C3Bench를 참고하여 개발한 **한국 고전 문헌 이해를 위한 포괄적인 벤치마크**입니다.\n",
    "\n",
    "### 🎯 목표\n",
    "\n",
    "- 대규모 언어 모델(LLM)의 **한국 고전 한문 및 사서 데이터**에 대한 이해 능력 평가\n",
    "- 5가지 핵심 태스크를 통한 **다각적 성능 측정**\n",
    "- 과거시험 데이터와 사서 데이터를 활용한 **실제적이고 의미있는 평가**\n",
    "\n",
    "### 📊 벤치마크 통계\n",
    "\n",
    "| 항목 | 값 |\n",
    "|:---|:---|\n",
    "| **총 항목 수** | 7,871개 |\n",
    "| **태스크 수** | 5개 |\n",
    "| **지원 언어** | 고전 한문, 한국어, 영어 |\n",
    "| **데이터 소스** | 과거시험 데이터, 사서(四書) |\n",
    "| **버전** | 1.0 |\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 5가지 핵심 태스크\n",
    "\n",
    "### 1. Classification (분류) - 808개\n",
    "\n",
    "**목적**: 주어진 고전 문헌의 문체를 분류\n",
    "\n",
    "- **입력**: 고전 한문 텍스트\n",
    "- **출력**: 문체 레이블 (賦/詩/疑/義/策/表 등 21개 카테고리)\n",
    "- **평가 지표**: Accuracy\n",
    "\n",
    "#### 문체 분포\n",
    "\n",
    "주요 문체:\n",
    "- **賦** (부): 95개 - 서사적 산문체\n",
    "- **詩** (시): 95개 - 운문체\n",
    "- **疑** (의): 95개 - 의문문체\n",
    "- **義** (의): 95개 - 의리를 논하는 글\n",
    "- **策** (책): 95개 - 정책을 논하는 글\n",
    "- **表** (표): 95개 - 임금에게 올리는 글\n",
    "- **論** (논): 51개 - 논설문\n",
    "- **銘** (명): 53개 - 교훈적 글\n",
    "- **箋** (전): 49개 - 편지글\n",
    "\n",
    "**예시**:\n",
    "```\n",
    "입력: \"蓋麟云\"\n",
    "출력: \"賦\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Retrieval (검색) - 1,209개\n",
    "\n",
    "**목적**: 주어진 문장이 유래한 원문의 출처(Book/Chapter) 식별\n",
    "\n",
    "- **입력**: 고전 한문 문장\n",
    "- **출력**: 책 이름 + 장(章)\n",
    "- **평가 지표**: Accuracy\n",
    "\n",
    "#### 책별 분포\n",
    "\n",
    "| 책 | 항목 수 |\n",
    "|:---|---:|\n",
    "| **論語** | 500 |\n",
    "| **孟子** | 500 |\n",
    "| **中庸** | 137 |\n",
    "| **大學** | 72 |\n",
    "\n",
    "**예시**:\n",
    "```\n",
    "입력: \"學而時習之，不亦說乎\"\n",
    "출력: \"論語 - 學而\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Punctuation (구두점 찍기) - 2,000개\n",
    "\n",
    "**목적**: 구두점이 없는 백문(白文)에 적절한 구두점 복원\n",
    "\n",
    "- **입력**: 구두점이 제거된 한글 번역문\n",
    "- **출력**: 올바른 구두점이 포함된 문장\n",
    "- **평가 지표**: F1 Score\n",
    "\n",
    "#### 데이터 구성\n",
    "\n",
    "- **사서 데이터**: 50% (1,000개)\n",
    "- **과거시험 데이터**: 50% (1,000개)\n",
    "\n",
    "**예시**:\n",
    "```\n",
    "입력: \"공자께서말씀하시기를지혜로운자는그것에이르고어진자는그것을지킬수있으며\"\n",
    "출력: \"공자께서 말씀하시기를, 지혜로운 자는 그것에 이르고, 어진 자는 그것을 지킬 수 있으며\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. NLI (자연언어추론) - 1,854개\n",
    "\n",
    "**목적**: 두 문장 간의 논리적 관계 판단\n",
    "\n",
    "- **입력**: Premise (전제) + Hypothesis (가설)\n",
    "- **출력**: entailment (함의) / contradiction (모순) / neutral (중립)\n",
    "- **평가 지표**: Accuracy\n",
    "\n",
    "#### 레이블 분포\n",
    "\n",
    "| 레이블 | 항목 수 | 비율 |\n",
    "|:---|---:|---:|\n",
    "| **entailment** | 1,313 | 70.8% |\n",
    "| **neutral** | 400 | 21.6% |\n",
    "| **contradiction** | 141 | 7.6% |\n",
    "\n",
    "#### NLI 카테고리\n",
    "\n",
    "1. **translation_equivalence**: 번역 등가성 (원문 ↔ 번역)\n",
    "2. **cross_lingual_entailment**: 언어 간 함의 (한글 ↔ 영어)\n",
    "3. **cross_text_relation**: 텍스트 간 관계 (다른 문헌)\n",
    "4. **negation_based**: 부정 기반 모순\n",
    "5. **metaphorical_reasoning**: 비유적 추론\n",
    "6. **analogical_reasoning**: 유추 추론\n",
    "\n",
    "**예시**:\n",
    "```\n",
    "Premise: \"禮與食孰重？\" (예와 밥은 어느 것이 더 중한가?)\n",
    "Hypothesis: \"예의와 음식 중 어느 것이 더 중요한가?\"\n",
    "Label: entailment\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Translation (번역) - 2,000개\n",
    "\n",
    "**목적**: 한문, 한글, 영문 간의 번역 수행\n",
    "\n",
    "- **입력**: 원문 (source_lang)\n",
    "- **출력**: 번역문 (target_lang)\n",
    "- **평가 지표**: BLEU Score\n",
    "\n",
    "#### 언어 쌍 분포\n",
    "\n",
    "| 언어 쌍 | 항목 수 | 비율 |\n",
    "|:---|---:|---:|\n",
    "| **고전 한문 → 한국어** | 1,320 | 66.0% |\n",
    "| **한국어 → 영어** | 680 | 34.0% |\n",
    "\n",
    "**예시 1 (한문→한글)**:\n",
    "```\n",
    "입력: \"學而時習之，不亦說乎\"\n",
    "출력: \"배우고 때때로 익히니, 또한 기쁘지 아니한가\"\n",
    "```\n",
    "\n",
    "**예시 2 (한글→영문)**:\n",
    "```\n",
    "입력: \"배우고 때때로 익히니, 또한 기쁘지 아니한가\"\n",
    "출력: \"To learn and practice what one has learned, is this not a pleasure?\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 전체 태스크 비교\n",
    "\n",
    "| 태스크 | 항목 수 | 비율 | 평가 지표 | 난이도 |\n",
    "|:---|---:|---:|:---|:---|\n",
    "| Classification | 808 | 10.3% | Accuracy | ⭐⭐ |\n",
    "| Retrieval | 1,209 | 15.4% | Accuracy | ⭐⭐⭐ |\n",
    "| Punctuation | 2,000 | 25.4% | F1 Score | ⭐⭐ |\n",
    "| NLI | 1,854 | 23.6% | Accuracy | ⭐⭐⭐⭐ |\n",
    "| Translation | 2,000 | 25.4% | BLEU | ⭐⭐⭐⭐⭐ |\n",
    "| **총계** | **7,871** | **100%** | - | - |\n",
    "\n",
    "---\n",
    "\n",
    "## 💾 데이터 구조\n",
    "\n",
    "### JSON 포맷 예시\n",
    "\n",
    "#### Classification\n",
    "```json\n",
    "{\n",
    "  \"task\": \"classification\",\n",
    "  \"id\": \"cls_0001\",\n",
    "  \"input\": \"蓋麟云\",\n",
    "  \"label\": \"賦\",\n",
    "  \"question_id\": \"Qab67a7ae089c\",\n",
    "  \"metadata\": {\n",
    "    \"has_korean\": true,\n",
    "    \"has_english\": true\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Retrieval\n",
    "```json\n",
    "{\n",
    "  \"task\": \"retrieval\",\n",
    "  \"id\": \"ret_0001\",\n",
    "  \"input\": \"學而時習之，不亦說乎\",\n",
    "  \"answer\": \" 論語 - 論語序說\",\n",
    "  \"book\": \" 論語\",\n",
    "  \"chapter\": \"論語序說\",\n",
    "  \"metadata\": {\n",
    "    \"has_translation\": true,\n",
    "    \"has_comment\": true\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### NLI\n",
    "```json\n",
    "{\n",
    "  \"task\": \"nli\",\n",
    "  \"id\": \"nli_0001\",\n",
    "  \"premise\": \"임나라 사람이 옥려자에게 물었다. 예와 밥은 어느 것이 더 중한가?\",\n",
    "  \"hypothesis\": \"옥려자는 예가 더 중요하다고 답했다.\",\n",
    "  \"label\": \"entailment\",\n",
    "  \"source\": \"맹자\",\n",
    "  \"difficulty\": \"easy\",\n",
    "  \"category\": \"direct_inference\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 사용 방법\n",
    "\n",
    "### 1. 데이터 로드\n",
    "\n",
    "```python\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# JSON으로 로드\n",
    "with open('benchmark/k_classic_bench/k_classic_bench_full.json', 'r', encoding='utf-8') as f:\n",
    "    benchmark = json.load(f)\n",
    "\n",
    "# CSV로 로드 (분석 편의)\n",
    "df_classification = pd.read_csv('benchmark/k_classic_bench/k_classic_bench_classification.csv')\n",
    "df_nli = pd.read_csv('benchmark/k_classic_bench/k_classic_bench_nli.csv')\n",
    "```\n",
    "\n",
    "### 2. 태스크별 접근\n",
    "\n",
    "```python\n",
    "# 특정 태스크만 로드\n",
    "classification_data = benchmark['tasks']['classification']['data']\n",
    "\n",
    "# 예시 출력\n",
    "for item in classification_data[:5]:\n",
    "    print(f\"Input: {item['input']}\")\n",
    "    print(f\"Label: {item['label']}\")\n",
    "    print()\n",
    "```\n",
    "\n",
    "### 3. 평가 예시\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Classification 평가\n",
    "y_true = [item['label'] for item in classification_data]\n",
    "y_pred = model.predict([item['input'] for item in classification_data])\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# NLI 평가\n",
    "nli_data = benchmark['tasks']['nli']['data']\n",
    "nli_true = [item['label'] for item in nli_data]\n",
    "nli_pred = model.predict_nli(nli_data)\n",
    "nli_accuracy = accuracy_score(nli_true, nli_pred)\n",
    "print(f\"NLI Accuracy: {nli_accuracy:.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 C3Bench와의 비교\n",
    "\n",
    "| 항목 | C3Bench | K-ClassicBench |\n",
    "|:---|:---:|:---:|\n",
    "| **총 항목 수** | 50,000 | 7,871 |\n",
    "| **태스크 수** | 5 | 5 |\n",
    "| **분류 태스크** | 10,000 (10개 분야) | 808 (21개 문체) |\n",
    "| **검색 태스크** | 10,000 | 1,209 (4서) |\n",
    "| **구두점 태스크** | 10,000 | 2,000 |\n",
    "| **NER 태스크** | 10,000 | ❌ (NLI로 대체) |\n",
    "| **NLI 태스크** | ❌ | 1,854 |\n",
    "| **번역 태스크** | 10,000 | 2,000 (3개 언어) |\n",
    "| **언어** | 고전 중국어, 현대 중국어 | 고전 한문, 한국어, 영어 |\n",
    "\n",
    "### 주요 차이점\n",
    "\n",
    "1. **NLI 태스크 추가**: C3Bench의 NER 대신 NLI(자연언어추론) 포함\n",
    "2. **다국어 지원**: 한문-한글-영문 3개 언어 지원\n",
    "3. **문체 세분화**: 21개의 세밀한 문체 카테고리\n",
    "4. **실용적 규모**: 약 8천개 항목으로 실험 가능한 규모\n",
    "\n",
    "---\n",
    "\n",
    "## 🎓 데이터 출처\n",
    "\n",
    "### 1. 과거시험 데이터 (3,348 → 2,849 항목)\n",
    "\n",
    "- **파일**: `translated_full_20251020_212605.csv`\n",
    "- **내용**: 조선시대 과거시험 문제 및 답안\n",
    "- **포함 정보**:\n",
    "  - question_id, category (문체)\n",
    "  - abstract, content (원문 한문)\n",
    "  - abstract_ko, content_ko (한글 번역)\n",
    "  - abstract_en, content_en (영문 번역)\n",
    "\n",
    "### 2. 사서(四書) 데이터 (2,624 → 2,119 항목)\n",
    "\n",
    "- **파일**: `External_raw.csv`\n",
    "- **포함 서적**:\n",
    "  - 論語 (논어)\n",
    "  - 孟子 (맹자)\n",
    "  - 大學 (대학)\n",
    "  - 中庸 (중용)\n",
    "- **포함 정보**:\n",
    "  - Book, Chapter, Volume, Index\n",
    "  - Original (원문 한문)\n",
    "  - Original_trans (한글 번역)\n",
    "  - Comment (주석)\n",
    "\n",
    "### 3. NLI 예시 데이터 (15 항목)\n",
    "\n",
    "- **파일**: `nli_examples.json`\n",
    "- **내용**: 자연언어추론 템플릿 및 예시\n",
    "- **활용**: NLI 태스크 생성 시 가이드라인\n",
    "\n",
    "---\n",
    "\n",
    "## 🔬 생성 프로세스\n",
    "\n",
    "### 1. 데이터 전처리\n",
    "\n",
    "```\n",
    "과거시험 데이터: 3,348 → 2,849 항목 (결측치 제거)\n",
    "사서 데이터: 2,624 → 2,119 항목 (결측치 제거)\n",
    "```\n",
    "\n",
    "### 2. 태스크별 생성 전략\n",
    "\n",
    "#### Classification (808개)\n",
    "- 카테고리별 균등 샘플링 (각 95개)\n",
    "- abstract 또는 content 사용\n",
    "\n",
    "#### Retrieval (1,209개)\n",
    "- 책별 균등 샘플링\n",
    "- Book + Chapter 정보 포함\n",
    "\n",
    "#### Punctuation (2,000개)\n",
    "- 한글 번역문에서 구두점 제거\n",
    "- 최소 길이 10자 이상 필터링\n",
    "- 사서 50% + 과거시험 50%\n",
    "\n",
    "#### NLI (1,854개)\n",
    "- **Entailment (70.8%)**:\n",
    "  - 원문 → 번역 관계\n",
    "  - 한문 → 한글 → 영문\n",
    "- **Neutral (21.6%)**:\n",
    "  - 다른 책의 문장 페어링\n",
    "- **Contradiction (7.6%)**:\n",
    "  - 부정 표현 추가\n",
    "  - 다른 카테고리 문장 조합\n",
    "\n",
    "#### Translation (2,000개)\n",
    "- 한문 → 한글 (66%)\n",
    "- 한글 → 영문 (34%)\n",
    "\n",
    "### 3. 품질 검증\n",
    "\n",
    "- 이중 검증 (데이터 전처리 단계)\n",
    "- 최소 길이 필터링\n",
    "- 레이블 분포 균형 확인\n",
    "\n",
    "---\n",
    "\n",
    "## 📁 파일 구조\n",
    "\n",
    "```\n",
    "korean_eda/\n",
    "├── benchmark/\n",
    "│   └── k_classic_bench/\n",
    "│       ├── k_classic_bench_full.json          (5.0 MB)\n",
    "│       ├── k_classic_bench_classification.json (248 KB)\n",
    "│       ├── k_classic_bench_retrieval.json      (447 KB)\n",
    "│       ├── k_classic_bench_punctuation.json    (1.6 MB)\n",
    "│       ├── k_classic_bench_nli.json            (1.1 MB)\n",
    "│       ├── k_classic_bench_translation.json    (1.3 MB)\n",
    "│       ├── k_classic_bench_classification.csv  (134 KB)\n",
    "│       ├── k_classic_bench_retrieval.csv       (239 KB)\n",
    "│       ├── k_classic_bench_punctuation.csv     (1.3 MB)\n",
    "│       ├── k_classic_bench_nli.csv             (774 KB)\n",
    "│       ├── k_classic_bench_translation.csv     (952 KB)\n",
    "│       └── README.md                           (4.4 KB)\n",
    "├── notebook/experiments/\n",
    "│   ├── k_classic_bench_generator.py            (생성 스크립트)\n",
    "│   ├── k_classic_bench_summary.ipynb           (본 문서)\n",
    "│   └── 4번실험.ipynb                           (C3Bench 제안서)\n",
    "└── data/\n",
    "    ├── External_raw.csv                        (사서 데이터)\n",
    "    └── translated_full_20251020_212605.csv     (과거시험 데이터)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔮 향후 계획\n",
    "\n",
    "### Phase 1: 벤치마크 확장 (목표: 10,000+ 항목)\n",
    "- [ ] Classification: 1,000개로 증가 (더 많은 문체)\n",
    "- [ ] Retrieval: 2,000개로 증가 (오경 추가)\n",
    "- [ ] NER 태스크 추가 (인명, 지명, 관직명 등)\n",
    "\n",
    "### Phase 2: 품질 개선\n",
    "- [ ] 전문가 검증 (고전문헌학자)\n",
    "- [ ] NLI Contradiction 샘플 품질 향상\n",
    "- [ ] 난이도 레이블링 추가\n",
    "\n",
    "### Phase 3: 평가 실험\n",
    "- [ ] 주요 LLM 평가 (GPT-4, Claude, Gemini 등)\n",
    "- [ ] 한국어 특화 모델 평가 (HyperCLOVA X, EXAONE 등)\n",
    "- [ ] 베이스라인 모델 구축\n",
    "\n",
    "### Phase 4: 공개 및 배포\n",
    "- [ ] GitHub 공개 저장소\n",
    "- [ ] Hugging Face Datasets 등록\n",
    "- [ ] 리더보드 구축\n",
    "- [ ] 논문 작성 및 투고\n",
    "\n",
    "---\n",
    "\n",
    "## 📜 라이선스 및 인용\n",
    "\n",
    "### 인용 방법\n",
    "\n",
    "```bibtex\n",
    "@misc{k_classic_bench_2024,\n",
    "  title={K-ClassicBench: Korean Classical Literature Understanding Benchmark},\n",
    "  author={[Your Name]},\n",
    "  year={2024},\n",
    "  note={Inspired by C3Bench},\n",
    "  url={https://github.com/[your-repo]/k-classic-bench}\n",
    "}\n",
    "```\n",
    "\n",
    "### 참고 문헌\n",
    "\n",
    "- **C3Bench**: Sun et al., \"C3Bench: A Comprehensive Classical Chinese Understanding Benchmark for Large Language Models\"\n",
    "\n",
    "---\n",
    "\n",
    "## 📧 문의\n",
    "\n",
    "벤치마크 관련 문의사항은 이메일로 연락 주시기 바랍니다.\n",
    "\n",
    "---\n",
    "\n",
    "**생성일**: 2024-10-21\n",
    "\n",
    "**버전**: 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loading_data",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 데이터 로드 및 탐색\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"✅ 라이브러리 로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 벤치마크 로드\n",
    "with open('../../benchmark/k_classic_bench/k_classic_bench_full.json', 'r', encoding='utf-8') as f:\n",
    "    benchmark = json.load(f)\n",
    "\n",
    "print(\"📋 벤치마크 정보:\")\n",
    "print(f\"  - 이름: {benchmark['benchmark_info']['name']}\")\n",
    "print(f\"  - 총 항목 수: {benchmark['benchmark_info']['total_size']:,}개\")\n",
    "print(f\"  - 태스크 수: {len(benchmark['benchmark_info']['tasks'])}개\")\n",
    "print(f\"  - 지원 언어: {', '.join(benchmark['benchmark_info']['languages'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_csvs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 데이터 로드\n",
    "df_classification = pd.read_csv('../../benchmark/k_classic_bench/k_classic_bench_classification.csv')\n",
    "df_retrieval = pd.read_csv('../../benchmark/k_classic_bench/k_classic_bench_retrieval.csv')\n",
    "df_punctuation = pd.read_csv('../../benchmark/k_classic_bench/k_classic_bench_punctuation.csv')\n",
    "df_nli = pd.read_csv('../../benchmark/k_classic_bench/k_classic_bench_nli.csv')\n",
    "df_translation = pd.read_csv('../../benchmark/k_classic_bench/k_classic_bench_translation.csv')\n",
    "\n",
    "print(\"✅ 모든 태스크 데이터 로드 완료\")\n",
    "print(f\"  - Classification: {len(df_classification):,} 항목\")\n",
    "print(f\"  - Retrieval: {len(df_retrieval):,} 항목\")\n",
    "print(f\"  - Punctuation: {len(df_punctuation):,} 항목\")\n",
    "print(f\"  - NLI: {len(df_nli):,} 항목\")\n",
    "print(f\"  - Translation: {len(df_translation):,} 항목\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## 📈 데이터 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_task_distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태스크별 항목 수 분포\n",
    "task_sizes = {\n",
    "    'Classification': len(df_classification),\n",
    "    'Retrieval': len(df_retrieval),\n",
    "    'Punctuation': len(df_punctuation),\n",
    "    'NLI': len(df_nli),\n",
    "    'Translation': len(df_translation)\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(task_sizes.keys(), task_sizes.values(), color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8'])\n",
    "plt.title('K-ClassicBench 태스크별 항목 수 분포', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('태스크', fontsize=12)\n",
    "plt.ylabel('항목 수', fontsize=12)\n",
    "plt.xticks(rotation=15)\n",
    "for i, (task, size) in enumerate(task_sizes.items()):\n",
    "    plt.text(i, size + 50, f'{size:,}', ha='center', fontsize=11, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification 문체 분포\n",
    "classification_counts = df_classification['label'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "classification_counts.plot(kind='barh', color='#FF6B6B')\n",
    "plt.title('Classification: 문체별 분포 (Top 10)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('항목 수', fontsize=12)\n",
    "plt.ylabel('문체', fontsize=12)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_nli",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLI 레이블 분포\n",
    "nli_counts = df_nli['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(nli_counts.values, labels=nli_counts.index, autopct='%1.1f%%', \n",
    "        colors=['#4ECDC4', '#FFA07A', '#FF6B6B'], startangle=90)\n",
    "plt.title('NLI: 레이블 분포', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n레이블별 항목 수:\")\n",
    "for label, count in nli_counts.items():\n",
    "    print(f\"  {label}: {count:,}개 ({count/len(df_nli)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation 언어 쌍 분포\n",
    "df_translation['lang_pair'] = df_translation['source_lang'] + ' → ' + df_translation['target_lang']\n",
    "translation_counts = df_translation['lang_pair'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "translation_counts.plot(kind='bar', color='#98D8C8')\n",
    "plt.title('Translation: 언어 쌍 분포', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('언어 쌍', fontsize=12)\n",
    "plt.ylabel('항목 수', fontsize=12)\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "examples",
   "metadata": {},
   "source": [
    "## 💡 데이터 예시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📋 Classification 예시:\")\n",
    "print(\"=\" * 70)\n",
    "for i, row in df_classification.head(3).iterrows():\n",
    "    print(f\"\\n[{i+1}] ID: {row['id']}\")\n",
    "    print(f\"입력: {row['input'][:100]}...\")\n",
    "    print(f\"레이블: {row['label']}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_nli",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🧠 NLI 예시:\")\n",
    "print(\"=\" * 70)\n",
    "for i, row in df_nli.head(3).iterrows():\n",
    "    print(f\"\\n[{i+1}] ID: {row['id']}\")\n",
    "    print(f\"Premise: {row['premise'][:80]}...\")\n",
    "    print(f\"Hypothesis: {row['hypothesis'][:80]}...\")\n",
    "    print(f\"Label: {row['label']}\")\n",
    "    print(f\"Category: {row['category']}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🌐 Translation 예시:\")\n",
    "print(\"=\" * 70)\n",
    "for i, row in df_translation.head(3).iterrows():\n",
    "    print(f\"\\n[{i+1}] ID: {row['id']}\")\n",
    "    print(f\"Source ({row['source_lang']}): {row['source_text'][:80]}...\")\n",
    "    print(f\"Target ({row['target_lang']}): {row['target_text'][:80]}...\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistics",
   "metadata": {},
   "source": [
    "## 📊 상세 통계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stats_text_length",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 길이 통계\n",
    "df_classification['input_length'] = df_classification['input'].apply(len)\n",
    "df_nli['premise_length'] = df_nli['premise'].apply(len)\n",
    "df_nli['hypothesis_length'] = df_nli['hypothesis'].apply(len)\n",
    "df_translation['source_length'] = df_translation['source_text'].apply(len)\n",
    "\n",
    "print(\"📏 텍스트 길이 통계:\")\n",
    "print(\"\\nClassification (입력):\")\n",
    "print(f\"  평균: {df_classification['input_length'].mean():.1f}자\")\n",
    "print(f\"  중앙값: {df_classification['input_length'].median():.1f}자\")\n",
    "print(f\"  최소/최대: {df_classification['input_length'].min()}자 / {df_classification['input_length'].max()}자\")\n",
    "\n",
    "print(\"\\nNLI (Premise):\")\n",
    "print(f\"  평균: {df_nli['premise_length'].mean():.1f}자\")\n",
    "print(f\"  중앙값: {df_nli['premise_length'].median():.1f}자\")\n",
    "\n",
    "print(\"\\nTranslation (Source):\")\n",
    "print(f\"  평균: {df_translation['source_length'].mean():.1f}자\")\n",
    "print(f\"  중앙값: {df_translation['source_length'].median():.1f}자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ 결론\n",
    "\n",
    "K-ClassicBench v1.0이 성공적으로 생성되었습니다!\n",
    "\n",
    "### 주요 성과\n",
    "\n",
    "✅ **총 7,871개 항목** 생성\n",
    "\n",
    "✅ **5가지 핵심 태스크** 구성\n",
    "- Classification (808개)\n",
    "- Retrieval (1,209개)\n",
    "- Punctuation (2,000개)\n",
    "- NLI (1,854개)\n",
    "- Translation (2,000개)\n",
    "\n",
    "✅ **다양한 데이터 소스** 활용\n",
    "- 과거시험 데이터\n",
    "- 사서(四書) 데이터\n",
    "- NLI 템플릿\n",
    "\n",
    "✅ **3개 언어 지원**: 고전 한문, 한국어, 영어\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "1. **벤치마크 확장**: 10,000+ 항목 목표\n",
    "2. **품질 개선**: 전문가 검증\n",
    "3. **LLM 평가**: 주요 모델 성능 측정\n",
    "4. **공개 배포**: GitHub, Hugging Face\n",
    "\n",
    "---\n",
    "\n",
    "**K-ClassicBench v1.0**\n",
    "\n",
    "_한국 고전 문헌 이해의 새로운 기준_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
