# ì‹¤í—˜ 5: KLSBench ë²¤ì¹˜ë§ˆí¬ í‰ê°€

C3Benchë¥¼ ì°¸ê³ í•˜ì—¬ ê°œë°œí•œ KLSBenchë¡œ ë‹¤ì–‘í•œ LLMì„ í‰ê°€í•˜ëŠ” ì‹¤í—˜ì…ë‹ˆë‹¤.

## ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ë²¤ì¹˜ë§ˆí¬ êµ¬ì„±](#ë²¤ì¹˜ë§ˆí¬-êµ¬ì„±)
3. [ì„¤ì¹˜ ë° ì„¤ì •](#ì„¤ì¹˜-ë°-ì„¤ì •)
4. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
5. [í‰ê°€ ëª¨ë¸](#í‰ê°€-ëª¨ë¸)
6. [ê²°ê³¼ ë¶„ì„](#ê²°ê³¼-ë¶„ì„)

---

## ê°œìš”

**KLSBench**ëŠ” í•œêµ­ ê³ ì „ ë¬¸í—Œ ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.

- **ì´ í•­ëª© ìˆ˜**: 7,871ê°œ
- **íƒœìŠ¤í¬ ìˆ˜**: 5ê°œ
- **ì–¸ì–´**: í•œë¬¸, í•œêµ­ì–´, ì˜ë¬¸

---

## ë²¤ì¹˜ë§ˆí¬ êµ¬ì„±

| íƒœìŠ¤í¬ | ì„¤ëª… | í•­ëª© ìˆ˜ | í‰ê°€ ì§€í‘œ |
|:---|:---|---:|:---|
| **Classification** | ë¬¸ì²´ ë¶„ë¥˜ (è³¦/è©©/ç–‘/ç¾© ë“±) | 808 | Accuracy |
| **Retrieval** | ì¶œì²˜ ì‹ë³„ (è«–èª/å­Ÿå­/å¤§å­¸/ä¸­åº¸) | 1,209 | Accuracy |
| **Punctuation** | êµ¬ë‘ì  ë³µì› (ë°±ë¬¸ â†’ êµ¬ë‘ì ë³¸) | 2,000 | F1 Score |
| **NLI** | ìì—°ì–¸ì–´ì¶”ë¡  | 1,854 | Accuracy |
| **Translation** | ë²ˆì—­ (í•œë¬¸â†”í•œê¸€â†”ì˜ë¬¸) | 2,000 | BLEU Score |

---

## ì„¤ì¹˜ ë° ì„¤ì •

### 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

**requirements.txt**:
```
pandas
numpy
scikit-learn
rouge-score
nltk
tqdm
matplotlib
seaborn

# API ëª¨ë¸ìš©
openai
anthropic

# ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ìš©
transformers
torch
accelerate
```

### 2. API í‚¤ ì„¤ì •

API ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ í™˜ê²½ ë³€ìˆ˜ì— API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.

```bash
# OpenAI (GPT-4, GPT-3.5)
export OPENAI_API_KEY='your-openai-api-key'

# Anthropic (Claude)
export ANTHROPIC_API_KEY='your-anthropic-api-key'
```

---

## ì‚¬ìš© ë°©ë²•

### ë°©ë²• 1: ì»¤ë§¨ë“œë¼ì¸ ì§ì ‘ ì‹¤í–‰

#### API ëª¨ë¸ í‰ê°€

```bash
# GPT-4 í‰ê°€ (í…ŒìŠ¤íŠ¸: ê° íƒœìŠ¤í¬ë‹¹ 10ê°œ)
python exp5_benchmark_evaluation.py \
    --model-type api \
    --model-name gpt-4-turbo \
    --api-key $OPENAI_API_KEY \
    --max-samples 10

# Claude 3.5 Sonnet í‰ê°€ (ì „ì²´)
python exp5_benchmark_evaluation.py \
    --model-type api \
    --model-name claude-3-5-sonnet-20241022 \
    --api-key $ANTHROPIC_API_KEY
```

#### ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ í‰ê°€

```bash
# Llama 3.1 8B í‰ê°€
python exp5_benchmark_evaluation.py \
    --model-type opensource \
    --model-name meta-llama/Llama-3.1-8B-Instruct \
    --max-samples 10

# Qwen 2.5 7B í‰ê°€
python exp5_benchmark_evaluation.py \
    --model-type opensource \
    --model-name Qwen/Qwen2.5-7B-Instruct
```

### ë°©ë²• 2: ë°°ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

ëª¨ë“  ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ í‰ê°€:

```bash
# í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ê° íƒœìŠ¤í¬ë‹¹ 10ê°œ ìƒ˜í”Œ)
./run_all_evaluations.sh test

# ì „ì²´ í‰ê°€ ëª¨ë“œ
./run_all_evaluations.sh full
```

### ë°©ë²• 3: Jupyter ë…¸íŠ¸ë¶

```bash
jupyter notebook 5ë²ˆì‹¤í—˜.ipynb
```

---

## í‰ê°€ ëª¨ë¸

### 1. ë¹„ê³µê°œ API ëª¨ë¸

- **GPT-4 Turbo** (`gpt-4-turbo`)
- **GPT-3.5 Turbo** (`gpt-3.5-turbo`)
- **Claude 3.5 Sonnet** (`claude-3-5-sonnet-20241022`)
- **Claude 3 Opus** (`claude-3-opus-20240229`)

### 2. ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸

- **Llama 3.1 8B** (`meta-llama/Llama-3.1-8B-Instruct`)
- **Llama 3.1 70B** (`meta-llama/Llama-3.1-70B-Instruct`)
- **Qwen 2.5 7B** (`Qwen/Qwen2.5-7B-Instruct`)
- **Qwen 2.5 14B** (`Qwen/Qwen2.5-14B-Instruct`)
- **Qwen 2.5 72B** (`Qwen/Qwen2.5-72B-Instruct`)
- **EXAONE 3.0 7.8B** (`LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct`)

### 3. ì§€ë„í•™ìŠµ ëª¨ë¸

- **Tongu**: í•œë¬¸ ì²˜ë¦¬ íŠ¹í™” ëª¨ë¸
- **GwenBert**: ê³ ì „ ë¬¸í—Œ ì´í•´ ëª¨ë¸

> **ì£¼ì˜**: ì§€ë„í•™ìŠµ ëª¨ë¸ì€ ë³„ë„ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤.

---

## ê²°ê³¼ ë¶„ì„

### ê²°ê³¼ íŒŒì¼

í‰ê°€ ì™„ë£Œ í›„ ë‹¤ìŒ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤:

```
../../benchmark/results/
â”œâ”€â”€ results_{model_name}_{timestamp}.json  # ì „ì²´ ê²°ê³¼ (ì˜ˆì¸¡ê°’ í¬í•¨)
â””â”€â”€ summary_{model_name}_{timestamp}.csv   # ìš”ì•½ (ë©”íŠ¸ë¦­ë§Œ)
```

### ê²°ê³¼ í™•ì¸

#### 1. CSV ìš”ì•½ íŒŒì¼

```python
import pandas as pd

df = pd.read_csv('../../benchmark/results/summary_gpt-4-turbo_20241021_120000.csv')
print(df)
```

| model | task | accuracy | f1 | bleu | ... |
|:---|:---|---:|---:|---:|:---|
| gpt-4-turbo | classification | 0.85 | 0.84 | - | ... |
| gpt-4-turbo | retrieval | 0.92 | - | - | ... |
| gpt-4-turbo | punctuation | - | - | - | ... |
| gpt-4-turbo | nli | 0.78 | 0.77 | - | ... |
| gpt-4-turbo | translation | - | - | 0.65 | ... |

#### 2. ìƒì„¸ ê²°ê³¼ (JSON)

```python
import json

with open('../../benchmark/results/results_gpt-4-turbo_20241021_120000.json', 'r') as f:
    results = json.load(f)

# ëª¨ë¸ ì •ë³´
print(results['model_name'])
print(results['model_type'])

# íƒœìŠ¤í¬ë³„ ê²°ê³¼
for task_name, task_results in results['tasks'].items():
    print(f"\n{task_name}:")
    print(f"  Metrics: {task_results['metrics']}")
    print(f"  Sample predictions: {task_results['predictions'][:3]}")
```

### ì‹œê°í™”

ë…¸íŠ¸ë¶(`5ë²ˆì‹¤í—˜.ipynb`)ì—ì„œ ë‹¤ìŒ ì‹œê°í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

1. **íƒœìŠ¤í¬ë³„ ì„±ëŠ¥ ë¹„êµ**: ë§‰ëŒ€ ê·¸ë˜í”„
2. **ëª¨ë¸ë³„ íˆíŠ¸ë§µ**: íƒœìŠ¤í¬ Ã— ëª¨ë¸ ì„±ëŠ¥
3. **ì¢…í•© ì ìˆ˜ ë­í‚¹**: í‰ê·  ì„±ëŠ¥ ìˆœìœ„

---

## ì»¤ë§¨ë“œë¼ì¸ ì˜µì…˜

```bash
python exp5_benchmark_evaluation.py [ì˜µì…˜]
```

### í•„ìˆ˜ ì˜µì…˜

- `--model-name`: ëª¨ë¸ ì´ë¦„ (ì˜ˆ: `gpt-4-turbo`, `meta-llama/Llama-3.1-8B-Instruct`)

### ì„ íƒ ì˜µì…˜

| ì˜µì…˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|:---|:---|:---|
| `--benchmark` | ë²¤ì¹˜ë§ˆí¬ JSON ê²½ë¡œ | `../../benchmark/kls_bench/kls_bench_full.json` |
| `--output` | ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ | `../../benchmark/results` |
| `--model-type` | ëª¨ë¸ íƒ€ì… (`api`/`opensource`/`supervised`) | `api` |
| `--api-key` | API í‚¤ (API ëª¨ë¸ìš©) | `None` |
| `--max-samples` | íƒœìŠ¤í¬ë‹¹ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©) | `None` (ì „ì²´) |

---

## ë¬¸ì œ í•´ê²°

### 1. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±

ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ í‰ê°€ ì‹œ GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ê²½ìš°:

```python
# ëª¨ë¸ ë¡œë”© ì‹œ 8bit quantization ì‚¬ìš©
from transformers import BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(load_in_8bit=True)

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=quantization_config,
    device_map="auto"
)
```

### 2. API Rate Limit

API í˜¸ì¶œ ì œí•œì— ê±¸ë¦° ê²½ìš°:

- `exp5_benchmark_evaluation.py`ì˜ `time.sleep(0.5)` ê°’ì„ ëŠ˜ë¦¬ì„¸ìš”.
- ë˜ëŠ” `--max-samples` ì˜µì…˜ìœ¼ë¡œ ìƒ˜í”Œ ìˆ˜ë¥¼ ì¤„ì´ì„¸ìš”.

### 3. Tokenizer ì—ëŸ¬

Chat templateì´ ì—†ëŠ” ëª¨ë¸ì˜ ê²½ìš°:

- ì½”ë“œê°€ ìë™ìœ¼ë¡œ fallback (ë‹¨ìˆœ ì—°ê²°)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ í¬ë§·ì„ ì§€ì •í•˜ì„¸ìš”.

---

## í–¥í›„ ê³„íš

1. ê¸°ë³¸ ë²¤ì¹˜ë§ˆí¬ êµ¬ì¶•
2. í‰ê°€ í”„ë ˆì„ì›Œí¬ ê°œë°œ
3. ğŸ”„ Few-shot learning ì§€ì›
4. ë” ë§ì€ ëª¨ë¸ ì¶”ê°€
5. ë„ë©”ì¸ íŠ¹í™” Fine-tuning

---

## ì°¸ê³  ìë£Œ

- **C3Bench**: [ë…¼ë¬¸ ë§í¬]
- **ë²¤ì¹˜ë§ˆí¬ ìƒì„¸**: `../../benchmark/kls_bench/README.md`

---

## ë¬¸ì˜

ë²¤ì¹˜ë§ˆí¬ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì€ ì´ë©”ì¼ë¡œ ì—°ë½ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.

---

**Generated**: 2024-10-21
