# Temperature Ablation Study - ì‹¤í–‰ ê°€ì´ë“œ

## ê°œìš”

Temperature íŒŒë¼ë¯¸í„°ê°€ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ëŠ” ì‹¤í—˜ì…ë‹ˆë‹¤.

### ì‹¤í—˜ ì„¤ì •
- **ëª¨ë¸**: 7ê°œ (GPT-4-turbo, GPT-3.5-turbo, Claude Sonnet 4.5, Claude Opus 3, Llama-3.1-8B, Qwen2.5-7B, EXAONE-3.0-7.8B)
- **Temperature**: 3ê°œ (0.0, 0.3, 0.7)
- **ìƒ˜í”Œë§**: 10% (787ê°œ ìƒ˜í”Œ)
- **ì´ ì‹¤í—˜**: 21íšŒ (7 models Ã— 3 temps)

### ì˜ˆìƒ ì†Œìš” ì‹œê°„
- **Mac (API ëª¨ë¸)**: ì•½ 5.5ì‹œê°„
- **H100 GPU (ì˜¤í”ˆì†ŒìŠ¤)**: ì•½ 1ì‹œê°„
- **ë³‘ë ¬ ì‹¤í–‰ ì‹œ**: ì•½ 5.5ì‹œê°„

---

## ğŸ“‹ ì‹¤í–‰ ì ˆì°¨

### Option 1: Macì—ì„œë§Œ ì‹¤í–‰ (API ëª¨ë¸ë§Œ)

```bash
# 1. í™˜ê²½ í™•ì¸
cd /Users/songhune/Workspace/korean_eda/notebook/experiments/exp5
cat .env  # API í‚¤ í™•ì¸

# 2. HF_TOKEN ì œê±° (ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ê±´ë„ˆë›°ê¸°)
export HF_TOKEN=""

# 3. ì‹¤í—˜ ì‹¤í–‰
./run_temperature_ablation.sh sample

# ê²°ê³¼: GPT-4, GPT-3.5, Claude Sonnet 4.5, Claude Opusë§Œ ì‹¤í–‰
```

---

### Option 2: H100 GPUì—ì„œë§Œ ì‹¤í–‰ (ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ë§Œ)

```bash
# 1. í™˜ê²½ ì„¤ì •
cd /path/to/korean_eda/notebook/experiments/exp5
./setup_exp5_gpu.sh

# 2. HuggingFace í† í° ì„¤ì •
export HF_TOKEN='hf_your_token_here'

# 3. API í‚¤ ì œê±° (API ëª¨ë¸ ê±´ë„ˆë›°ê¸°)
unset OPENAI_API_KEY
unset ANTHROPIC_API_KEY

# 4. ì‹¤í—˜ ì‹¤í–‰
./run_temperature_ablation.sh sample

# ê²°ê³¼: Llama-3.1-8B, Qwen2.5-7B, EXAONE-3.0-7.8Bë§Œ ì‹¤í–‰
```

---

### Option 3: ë³‘ë ¬ ì‹¤í–‰ (ê¶Œì¥) âš¡

**Mac (Terminal 1):**
```bash
cd /Users/songhune/Workspace/korean_eda/notebook/experiments/exp5

# HF_TOKEN ì œê±°
export HF_TOKEN=""

# API ëª¨ë¸ë§Œ ì‹¤í–‰
./run_temperature_ablation.sh sample
```

**H100 GPU (Terminal 2):**
```bash
cd /path/to/korean_eda/notebook/experiments/exp5

# í™˜ê²½ ì„¤ì • (ìµœì´ˆ 1íšŒ)
./setup_exp5_gpu.sh

# HuggingFace í† í° ì„¤ì •
export HF_TOKEN='hf_your_token_here'

# API í‚¤ ì œê±°
unset OPENAI_API_KEY
unset ANTHROPIC_API_KEY

# ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ë§Œ ì‹¤í–‰
./run_temperature_ablation.sh sample
```

---

## ğŸ” ì£¼ìš” ë³€ê²½ì‚¬í•­

### 1. Temperature ì„¤ì •
- **ë³€ê²½ ì „**: 5ê°œ (0.0, 0.1, 0.3, 0.5, 0.7)
- **ë³€ê²½ í›„**: 3ê°œ (0.0, 0.3, 0.7)
- **ì´ìœ **: GPT-4 Turbo ë¶„ì„ ê²°ê³¼ temperature ì˜í–¥ì´ ë§¤ìš° ì‘ìŒ (ë³€í™”ëŸ‰ < 0.4%)

### 2. ìƒ˜í”Œë§ ë¹„ìœ¨
- **ë³€ê²½ ì „**: 30% (2,361ê°œ)
- **ë³€ê²½ í›„**: 10% (787ê°œ)
- **ì´ìœ **: ì‹œê°„/ë¹„ìš© ì ˆê° (ì‹¤í—˜ ì‹œê°„ 88% ë‹¨ì¶•)

### 3. Claude ëª¨ë¸ëª… ìˆ˜ì •
- **ë³€ê²½ ì „**: `claude-3-5-sonnet-20241022` (ì¡´ì¬í•˜ì§€ ì•ŠìŒ â†’ 404 ì—ëŸ¬)
- **ë³€ê²½ í›„**:
  - `claude-sonnet-4-5-20250929` (ìµœì‹ )
  - `claude-3-opus-20240229`

---

## ğŸš¨ ì¤‘ìš” ì²´í¬ë¦¬ìŠ¤íŠ¸

### Mac ì‹¤í–‰ ì „
- [ ] `.env` íŒŒì¼ì— `OPENAI_API_KEY`, `ANTHROPIC_API_KEY` ì¡´ì¬
- [ ] `HF_TOKEN` ì œê±° ë˜ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
- [ ] ê¸°ì¡´ ì‹¤í—˜ ê²°ê³¼ ë°±ì—… (í•„ìš”ì‹œ)

### H100 GPU ì‹¤í–‰ ì „
- [ ] CUDA ë° GPU ë“œë¼ì´ë²„ ì„¤ì¹˜ í™•ì¸
- [ ] Python 3.8+ í™˜ê²½
- [ ] `HF_TOKEN` í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Llama ì•¡ì„¸ìŠ¤ìš©)
- [ ] ë””ìŠ¤í¬ ê³µê°„ ìµœì†Œ 50GB í™•ë³´ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©)
- [ ] API í‚¤ ì œê±° (OPENAI_API_KEY, ANTHROPIC_API_KEY)

---

## ğŸ“¦ ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ

### HuggingFace ëª¨ë¸ (ì²˜ìŒ ì‹¤í–‰ ì‹œ)

ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì€ ì²˜ìŒ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤:

1. **Llama-3.1-8B** (`meta-llama/Llama-3.1-8B-Instruct`)
   - í¬ê¸°: ~16GB
   - ì•¡ì„¸ìŠ¤: HF_TOKEN í•„ìš” (gated model)
   - ì•¡ì„¸ìŠ¤ ìš”ì²­: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct

2. **Qwen2.5-7B** (`Qwen/Qwen2.5-7B-Instruct`)
   - í¬ê¸°: ~15GB
   - ì•¡ì„¸ìŠ¤: Public (í† í° ë¶ˆí•„ìš”)

3. **EXAONE-3.0-7.8B** (`LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct`)
   - í¬ê¸°: ~16GB
   - ì•¡ì„¸ìŠ¤: Public (í† í° ë¶ˆí•„ìš”)

**ì´ ë‹¤ìš´ë¡œë“œ**: ~47GB

### ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜
- ê¸°ë³¸: `~/.cache/huggingface/hub/`
- ë³€ê²½: `export HF_HOME=/your/custom/path`

---

## ğŸ“Š ì‹¤í–‰ ëª¨ë‹ˆí„°ë§

### ì§„í–‰ ìƒí™© í™•ì¸
```bash
# ê²°ê³¼ íŒŒì¼ í™•ì¸
ls -lh results/temperature_ablation/

# ì‹¤ì‹œê°„ ë¡œê·¸
tail -f nohup.out  # background ì‹¤í–‰ ì‹œ
```

### ì˜ˆìƒ ì¶œë ¥
```
[LOAD] Benchmark: /path/to/kls_bench_full.json
[SAMPLING] Limited to 10% of data
Temperature values to test: 0.0 0.3 0.7

Model: gpt-4-turbo
Temperature: 0.0
========================================
[classification] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81
[retrieval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121
...
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### 1. Claude API 404 ì—ëŸ¬
```
Error code: 404 - model: claude-3-5-sonnet-20241022
```
**í•´ê²°**: ìŠ¤í¬ë¦½íŠ¸ê°€ ì´ë¯¸ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì‹  ë²„ì „ ì‚¬ìš©í•˜ì„¸ìš”.

### 2. Llama ì•¡ì„¸ìŠ¤ ê±°ë¶€
```
Error: You are trying to access a gated repo
```
**í•´ê²°**:
1. https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct ì ‘ì†
2. "Request access" í´ë¦­
3. ìŠ¹ì¸ í›„ `export HF_TOKEN='your_token'`

### 3. CUDA Out of Memory
```
RuntimeError: CUDA out of memory
```
**í•´ê²°**:
- H100 GPU (80GB)ì—ì„œëŠ” ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨
- ë°œìƒ ì‹œ: `torch_dtype=torch.float16` í™•ì¸
- ë˜ëŠ” batch size ì¡°ì •

### 4. API Rate Limit
```
RateLimitError: Rate limit exceeded
```
**í•´ê²°**:
- ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹¤í–‰
- ìŠ¤í¬ë¦½íŠ¸ê°€ ìë™ìœ¼ë¡œ ì¤‘ë‹¨ëœ ì§€ì ë¶€í„° ì¬ê°œ

---

## ğŸ“ ê²°ê³¼ íŒŒì¼

ì‹¤í—˜ ì™„ë£Œ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼:

```
results/temperature_ablation/
â”œâ”€â”€ results_gpt-4-turbo_TIMESTAMP.json       # ì›ì‹œ ê²°ê³¼
â”œâ”€â”€ results_claude-sonnet-4-5_TIMESTAMP.json
â”œâ”€â”€ results_meta-llama_Llama-3.1-8B-Instruct_TIMESTAMP.json
â”œâ”€â”€ ...
â”œâ”€â”€ summary_*.csv                             # ìš”ì•½ CSV
â”œâ”€â”€ temperature_ablation_summary.csv          # í†µí•© ìš”ì•½
â””â”€â”€ temperature_ablation_*.pdf                # ì‹œê°í™”
```

### ê²°ê³¼ ë¶„ì„
```bash
# ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python3 analyze_temperature_ablation.py results/temperature_ablation/
```

---

## ğŸ“ ì§€ì›

ë¬¸ì œ ë°œìƒ ì‹œ:
1. ë¡œê·¸ íŒŒì¼ í™•ì¸
2. í™˜ê²½ ë³€ìˆ˜ ì¬í™•ì¸ (`env | grep -E "HF|OPENAI|ANTHROPIC"`)
3. GPU ìƒíƒœ í™•ì¸ (`nvidia-smi`)

---

**Last Updated**: 2025-11-12
**Version**: 2.0 (10% sampling, 3 temperatures)
