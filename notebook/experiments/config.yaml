# KLSBench Evaluation Configuration
# ====================================

# Benchmark paths
benchmark:
  full: "../../benchmark/kls_bench/kls_bench_full.json"
  classification: "../../benchmark/kls_bench/kls_bench_classification.json"
  retrieval: "../../benchmark/kls_bench/kls_bench_retrieval.json"
  punctuation: "../../benchmark/kls_bench/kls_bench_punctuation.json"
  nli: "../../benchmark/kls_bench/kls_bench_nli.json"
  translation: "../../benchmark/kls_bench/kls_bench_translation.json"

# Output directories
output:
  base: "../../benchmark/results"
  fewshot: "../../benchmark/results/fewshot"
  aggregated: "../../benchmark/results/aggregated"

# Evaluation modes
modes:
  test:
    max_samples: 10
    description: "Test with 10 samples per task"

  sample:
    default_ratio: 0.3
    description: "Sample a ratio of full benchmark"
    ratios:
      quick: 0.1      # ~787 items
      balanced: 0.3   # ~2,361 items (recommended)
      detailed: 0.5   # ~3,936 items

  full:
    description: "Evaluate full benchmark (7,871 items)"

# Few-shot configurations
fewshot:
  enabled: true
  shots: [1, 3, 5]
  max_samples: 50
  tasks: ["classification", "nli"]

# Model configurations
models:
  api:
    openai:
      - name: "gpt-4-turbo"
        enabled: true
      - name: "gpt-3.5-turbo"
        enabled: true

    anthropic:
      - name: "claude-3-5-sonnet-20241022"
        enabled: true
      - name: "claude-3-opus-20240229"
        enabled: true

  opensource:
    - name: "meta-llama/Llama-3.1-8B-Instruct"
      enabled: true
    - name: "Qwen/Qwen2.5-7B-Instruct"
      enabled: true
    - name: "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct"
      enabled: true

  supervised:
    - name: "SCUT-DLVCLab/TongGu-7B-Instruct"
      enabled: true
    - name: "ethanyt/guwenbert-base"
      enabled: false
      note: "Encoder model, not suitable for generation tasks"

# Task information
tasks:
  classification:
    total_items: 808
    description: "Classify literary style (Fu/Shi/Yi/I)"
    metric: "Accuracy"

  retrieval:
    total_items: 1209
    description: "Identify source from Four Books"
    metric: "Accuracy"

  punctuation:
    total_items: 2000
    description: "Restore punctuation to classical Chinese"
    metric: "F1 Score"

  nli:
    total_items: 1854
    description: "Determine logical relationship"
    metric: "Accuracy"

  translation:
    total_items: 2000
    description: "Translate between languages"
    metric: "BLEU Score"

# Python environment
environment:
  pythonpath_append: "${HOME}/.local/lib/python3.12/site-packages"
  env_file: ".env"
