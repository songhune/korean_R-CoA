{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "benchmark_overview",
   "metadata": {},
   "source": [
    "# KLSBench: í•œêµ­ ê³ ì „ ë¬¸í—Œ ì´í•´ ë²¤ì¹˜ë§ˆí¬\n",
    "\n",
    "**C3Bench ê¸°ë°˜ í•œêµ­í˜• ê³ ì „ ë¬¸í—Œ ë²¤ì¹˜ë§ˆí¬**\n",
    "\n",
    "---\n",
    "\n",
    "## í”„ë¡œì íŠ¸ ê°œìš”\n",
    "\n",
    "KLSBench ì¤‘êµ­ì˜ C3Benchë¥¼ ì°¸ê³ í•˜ì—¬ ê°œë°œí•œ **í•œêµ­ ê³ ì „ ë¬¸í—Œ ì´í•´ë¥¼ ìœ„í•œ í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬**ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ëª©í‘œ\n",
    "\n",
    "- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ **í•œêµ­ ê³ ì „ í•œë¬¸ ë° ì‚¬ì„œ ë°ì´í„°**ì— ëŒ€í•œ ì´í•´ ëŠ¥ë ¥ í‰ê°€\n",
    "- 5ê°€ì§€ í•µì‹¬ íƒœìŠ¤í¬ë¥¼ í†µí•œ **ë‹¤ê°ì  ì„±ëŠ¥ ì¸¡ì •**\n",
    "- ê³¼ê±°ì‹œí—˜ ë°ì´í„°ì™€ ì‚¬ì„œ ë°ì´í„°ë¥¼ í™œìš©í•œ **ì‹¤ì œì ì´ê³  ì˜ë¯¸ìˆëŠ” í‰ê°€**\n",
    "\n",
    "### ë²¤ì¹˜ë§ˆí¬ í†µê³„\n",
    "\n",
    "| í•­ëª© | ê°’ |\n",
    "|:---|:---|\n",
    "| **ì´ í•­ëª© ìˆ˜** | 7,871ê°œ |\n",
    "| **íƒœìŠ¤í¬ ìˆ˜** | 5ê°œ |\n",
    "| **ì§€ì› ì–¸ì–´** | ê³ ì „ í•œë¬¸, í•œêµ­ì–´, ì˜ì–´ |\n",
    "| **ë°ì´í„° ì†ŒìŠ¤** | ê³¼ê±°ì‹œí—˜ ë°ì´í„°, ì‚¬ì„œ(å››æ›¸) |\n",
    "| **ë²„ì „** | 1.0 |\n",
    "\n",
    "---\n",
    "\n",
    "## 5ê°€ì§€ í•µì‹¬ íƒœìŠ¤í¬\n",
    "\n",
    "### 1. Classification (ë¶„ë¥˜) - 808ê°œ\n",
    "\n",
    "**ëª©ì **: ì£¼ì–´ì§„ ê³ ì „ ë¬¸í—Œì˜ ë¬¸ì²´ë¥¼ ë¶„ë¥˜\n",
    "\n",
    "- **ì…ë ¥**: ê³ ì „ í•œë¬¸ í…ìŠ¤íŠ¸\n",
    "- **ì¶œë ¥**: ë¬¸ì²´ ë ˆì´ë¸” (è³¦/è©©/ç–‘/ç¾©/ç­–/è¡¨ ë“± 21ê°œ ì¹´í…Œê³ ë¦¬)\n",
    "- **í‰ê°€ ì§€í‘œ**: Accuracy\n",
    "\n",
    "#### ë¬¸ì²´ ë¶„í¬\n",
    "\n",
    "ì£¼ìš” ë¬¸ì²´:\n",
    "- **è³¦** (ë¶€): 95ê°œ - ì„œì‚¬ì  ì‚°ë¬¸ì²´\n",
    "- **è©©** (ì‹œ): 95ê°œ - ìš´ë¬¸ì²´\n",
    "- **ç–‘** (ì˜): 95ê°œ - ì˜ë¬¸ë¬¸ì²´\n",
    "- **ç¾©** (ì˜): 95ê°œ - ì˜ë¦¬ë¥¼ ë…¼í•˜ëŠ” ê¸€\n",
    "- **ç­–** (ì±…): 95ê°œ - ì •ì±…ì„ ë…¼í•˜ëŠ” ê¸€\n",
    "- **è¡¨** (í‘œ): 95ê°œ - ì„ê¸ˆì—ê²Œ ì˜¬ë¦¬ëŠ” ê¸€\n",
    "- **è«–** (ë…¼): 51ê°œ - ë…¼ì„¤ë¬¸\n",
    "- **éŠ˜** (ëª…): 53ê°œ - êµí›ˆì  ê¸€\n",
    "- **ç®‹** (ì „): 49ê°œ - í¸ì§€ê¸€\n",
    "\n",
    "**ì˜ˆì‹œ**:\n",
    "```\n",
    "ì…ë ¥: \"è“‹éºŸäº‘\"\n",
    "ì¶œë ¥: \"è³¦\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Retrieval (ê²€ìƒ‰) - 1,209ê°œ\n",
    "\n",
    "**ëª©ì **: ì£¼ì–´ì§„ ë¬¸ì¥ì´ ìœ ë˜í•œ ì›ë¬¸ì˜ ì¶œì²˜(Book/Chapter) ì‹ë³„\n",
    "\n",
    "- **ì…ë ¥**: ê³ ì „ í•œë¬¸ ë¬¸ì¥\n",
    "- **ì¶œë ¥**: ì±… ì´ë¦„ + ì¥(ç« )\n",
    "- **í‰ê°€ ì§€í‘œ**: Accuracy\n",
    "\n",
    "#### ì±…ë³„ ë¶„í¬\n",
    "\n",
    "| ì±… | í•­ëª© ìˆ˜ |\n",
    "|:---|---:|\n",
    "| **è«–èª** | 500 |\n",
    "| **å­Ÿå­** | 500 |\n",
    "| **ä¸­åº¸** | 137 |\n",
    "| **å¤§å­¸** | 72 |\n",
    "\n",
    "**ì˜ˆì‹œ**:\n",
    "```\n",
    "ì…ë ¥: \"å­¸è€Œæ™‚ç¿’ä¹‹ï¼Œä¸äº¦èªªä¹\"\n",
    "ì¶œë ¥: \"è«–èª - å­¸è€Œ\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Punctuation (êµ¬ë‘ì  ì°ê¸°) - 2,000ê°œ\n",
    "\n",
    "**ëª©ì **: êµ¬ë‘ì ì´ ì—†ëŠ” ë°±ë¬¸(ç™½æ–‡)ì— ì ì ˆí•œ êµ¬ë‘ì  ë³µì›\n",
    "\n",
    "- **ì…ë ¥**: êµ¬ë‘ì ì´ ì œê±°ëœ í•œê¸€ ë²ˆì—­ë¬¸\n",
    "- **ì¶œë ¥**: ì˜¬ë°”ë¥¸ êµ¬ë‘ì ì´ í¬í•¨ëœ ë¬¸ì¥\n",
    "- **í‰ê°€ ì§€í‘œ**: F1 Score\n",
    "\n",
    "#### ë°ì´í„° êµ¬ì„±\n",
    "\n",
    "- **ì‚¬ì„œ ë°ì´í„°**: 50% (1,000ê°œ)\n",
    "- **ê³¼ê±°ì‹œí—˜ ë°ì´í„°**: 50% (1,000ê°œ)\n",
    "\n",
    "**ì˜ˆì‹œ**:\n",
    "```\n",
    "ì…ë ¥: \"ê³µìê»˜ì„œë§ì”€í•˜ì‹œê¸°ë¥¼ì§€í˜œë¡œìš´ìëŠ”ê·¸ê²ƒì—ì´ë¥´ê³ ì–´ì§„ìëŠ”ê·¸ê²ƒì„ì§€í‚¬ìˆ˜ìˆìœ¼ë©°\"\n",
    "ì¶œë ¥: \"ê³µìê»˜ì„œ ë§ì”€í•˜ì‹œê¸°ë¥¼, ì§€í˜œë¡œìš´ ìëŠ” ê·¸ê²ƒì— ì´ë¥´ê³ , ì–´ì§„ ìëŠ” ê·¸ê²ƒì„ ì§€í‚¬ ìˆ˜ ìˆìœ¼ë©°\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. NLI (ìì—°ì–¸ì–´ì¶”ë¡ ) - 1,854ê°œ\n",
    "\n",
    "**ëª©ì **: ë‘ ë¬¸ì¥ ê°„ì˜ ë…¼ë¦¬ì  ê´€ê³„ íŒë‹¨\n",
    "\n",
    "- **ì…ë ¥**: Premise (ì „ì œ) + Hypothesis (ê°€ì„¤)\n",
    "- **ì¶œë ¥**: entailment (í•¨ì˜) / contradiction (ëª¨ìˆœ) / neutral (ì¤‘ë¦½)\n",
    "- **í‰ê°€ ì§€í‘œ**: Accuracy\n",
    "\n",
    "#### ë ˆì´ë¸” ë¶„í¬\n",
    "\n",
    "| ë ˆì´ë¸” | í•­ëª© ìˆ˜ | ë¹„ìœ¨ |\n",
    "|:---|---:|---:|\n",
    "| **entailment** | 1,313 | 70.8% |\n",
    "| **neutral** | 400 | 21.6% |\n",
    "| **contradiction** | 141 | 7.6% |\n",
    "\n",
    "#### NLI ì¹´í…Œê³ ë¦¬\n",
    "\n",
    "1. **translation_equivalence**: ë²ˆì—­ ë“±ê°€ì„± (ì›ë¬¸ â†” ë²ˆì—­)\n",
    "2. **cross_lingual_entailment**: ì–¸ì–´ ê°„ í•¨ì˜ (í•œê¸€ â†” ì˜ì–´)\n",
    "3. **cross_text_relation**: í…ìŠ¤íŠ¸ ê°„ ê´€ê³„ (ë‹¤ë¥¸ ë¬¸í—Œ)\n",
    "4. **negation_based**: ë¶€ì • ê¸°ë°˜ ëª¨ìˆœ\n",
    "5. **metaphorical_reasoning**: ë¹„ìœ ì  ì¶”ë¡ \n",
    "6. **analogical_reasoning**: ìœ ì¶” ì¶”ë¡ \n",
    "\n",
    "**ì˜ˆì‹œ**:\n",
    "```\n",
    "Premise: \"ç¦®èˆ‡é£Ÿå­°é‡ï¼Ÿ\" (ì˜ˆì™€ ë°¥ì€ ì–´ëŠ ê²ƒì´ ë” ì¤‘í•œê°€?)\n",
    "Hypothesis: \"ì˜ˆì˜ì™€ ìŒì‹ ì¤‘ ì–´ëŠ ê²ƒì´ ë” ì¤‘ìš”í•œê°€?\"\n",
    "Label: entailment\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Translation (ë²ˆì—­) - 2,000ê°œ\n",
    "\n",
    "**ëª©ì **: í•œë¬¸, í•œê¸€, ì˜ë¬¸ ê°„ì˜ ë²ˆì—­ ìˆ˜í–‰\n",
    "\n",
    "- **ì…ë ¥**: ì›ë¬¸ (source_lang)\n",
    "- **ì¶œë ¥**: ë²ˆì—­ë¬¸ (target_lang)\n",
    "- **í‰ê°€ ì§€í‘œ**: BLEU Score\n",
    "\n",
    "#### ì–¸ì–´ ìŒ ë¶„í¬\n",
    "\n",
    "| ì–¸ì–´ ìŒ | í•­ëª© ìˆ˜ | ë¹„ìœ¨ |\n",
    "|:---|---:|---:|\n",
    "| **ê³ ì „ í•œë¬¸ â†’ í•œêµ­ì–´** | 1,320 | 66.0% |\n",
    "| **í•œêµ­ì–´ â†’ ì˜ì–´** | 680 | 34.0% |\n",
    "\n",
    "**ì˜ˆì‹œ 1 (í•œë¬¸â†’í•œê¸€)**:\n",
    "```\n",
    "ì…ë ¥: \"å­¸è€Œæ™‚ç¿’ä¹‹ï¼Œä¸äº¦èªªä¹\"\n",
    "ì¶œë ¥: \"ë°°ìš°ê³  ë•Œë•Œë¡œ ìµíˆë‹ˆ, ë˜í•œ ê¸°ì˜ì§€ ì•„ë‹ˆí•œê°€\"\n",
    "```\n",
    "\n",
    "**ì˜ˆì‹œ 2 (í•œê¸€â†’ì˜ë¬¸)**:\n",
    "```\n",
    "ì…ë ¥: \"ë°°ìš°ê³  ë•Œë•Œë¡œ ìµíˆë‹ˆ, ë˜í•œ ê¸°ì˜ì§€ ì•„ë‹ˆí•œê°€\"\n",
    "ì¶œë ¥: \"To learn and practice what one has learned, is this not a pleasure?\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ì „ì²´ íƒœìŠ¤í¬ ë¹„êµ\n",
    "\n",
    "| íƒœìŠ¤í¬ | í•­ëª© ìˆ˜ | ë¹„ìœ¨ | í‰ê°€ ì§€í‘œ | ë‚œì´ë„ |\n",
    "|:---|---:|---:|:---|:---|\n",
    "| Classification | 808 | 10.3% | Accuracy | â­â­ |\n",
    "| Retrieval | 1,209 | 15.4% | Accuracy | â­â­â­ |\n",
    "| Punctuation | 2,000 | 25.4% | F1 Score | â­â­ |\n",
    "| NLI | 1,854 | 23.6% | Accuracy | â­â­â­â­ |\n",
    "| Translation | 2,000 | 25.4% | BLEU | â­â­â­â­â­ |\n",
    "| **ì´ê³„** | **7,871** | **100%** | - | - |\n",
    "\n",
    "---\n",
    "\n",
    "## ë°ì´í„° êµ¬ì¡°\n",
    "\n",
    "### JSON í¬ë§· ì˜ˆì‹œ\n",
    "\n",
    "#### Classification\n",
    "```json\n",
    "{\n",
    "  \"task\": \"classification\",\n",
    "  \"id\": \"cls_0001\",\n",
    "  \"input\": \"è“‹éºŸäº‘\",\n",
    "  \"label\": \"è³¦\",\n",
    "  \"question_id\": \"Qab67a7ae089c\",\n",
    "  \"metadata\": {\n",
    "    \"has_korean\": true,\n",
    "    \"has_english\": true\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Retrieval\n",
    "```json\n",
    "{\n",
    "  \"task\": \"retrieval\",\n",
    "  \"id\": \"ret_0001\",\n",
    "  \"input\": \"å­¸è€Œæ™‚ç¿’ä¹‹ï¼Œä¸äº¦èªªä¹\",\n",
    "  \"answer\": \" è«–èª - è«–èªåºèªª\",\n",
    "  \"book\": \" è«–èª\",\n",
    "  \"chapter\": \"è«–èªåºèªª\",\n",
    "  \"metadata\": {\n",
    "    \"has_translation\": true,\n",
    "    \"has_comment\": true\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### NLI\n",
    "```json\n",
    "{\n",
    "  \"task\": \"nli\",\n",
    "  \"id\": \"nli_0001\",\n",
    "  \"premise\": \"ì„ë‚˜ë¼ ì‚¬ëŒì´ ì˜¥ë ¤ìì—ê²Œ ë¬¼ì—ˆë‹¤. ì˜ˆì™€ ë°¥ì€ ì–´ëŠ ê²ƒì´ ë” ì¤‘í•œê°€?\",\n",
    "  \"hypothesis\": \"ì˜¥ë ¤ìëŠ” ì˜ˆê°€ ë” ì¤‘ìš”í•˜ë‹¤ê³  ë‹µí–ˆë‹¤.\",\n",
    "  \"label\": \"entailment\",\n",
    "  \"source\": \"ë§¹ì\",\n",
    "  \"difficulty\": \"easy\",\n",
    "  \"category\": \"direct_inference\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ì‚¬ìš© ë°©ë²•\n",
    "\n",
    "### 1. ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "```python\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# JSONìœ¼ë¡œ ë¡œë“œ\n",
    "with open('benchmark/k_classic_bench/k_classic_bench_full.json', 'r', encoding='utf-8') as f:\n",
    "    benchmark = json.load(f)\n",
    "\n",
    "# CSVë¡œ ë¡œë“œ (ë¶„ì„ í¸ì˜)\n",
    "df_classification = pd.read_csv('benchmark/k_classic_bench/k_classic_bench_classification.csv')\n",
    "df_nli = pd.read_csv('benchmark/k_classic_bench/k_classic_bench_nli.csv')\n",
    "```\n",
    "\n",
    "### 2. íƒœìŠ¤í¬ë³„ ì ‘ê·¼\n",
    "\n",
    "```python\n",
    "# íŠ¹ì • íƒœìŠ¤í¬ë§Œ ë¡œë“œ\n",
    "classification_data = benchmark['tasks']['classification']['data']\n",
    "\n",
    "# ì˜ˆì‹œ ì¶œë ¥\n",
    "for item in classification_data[:5]:\n",
    "    print(f\"Input: {item['input']}\")\n",
    "    print(f\"Label: {item['label']}\")\n",
    "    print()\n",
    "```\n",
    "\n",
    "### 3. í‰ê°€ ì˜ˆì‹œ\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Classification í‰ê°€\n",
    "y_true = [item['label'] for item in classification_data]\n",
    "y_pred = model.predict([item['input'] for item in classification_data])\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# NLI í‰ê°€\n",
    "nli_data = benchmark['tasks']['nli']['data']\n",
    "nli_true = [item['label'] for item in nli_data]\n",
    "nli_pred = model.predict_nli(nli_data)\n",
    "nli_accuracy = accuracy_score(nli_true, nli_pred)\n",
    "print(f\"NLI Accuracy: {nli_accuracy:.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## C3Benchì™€ì˜ ë¹„êµ\n",
    "\n",
    "| í•­ëª© | C3Bench | KLSBench |\n",
    "|:---|:---:|:---:|\n",
    "| **ì´ í•­ëª© ìˆ˜** | 50,000 | 7,871 |\n",
    "| **íƒœìŠ¤í¬ ìˆ˜** | 5 | 5 |\n",
    "| **ë¶„ë¥˜ íƒœìŠ¤í¬** | 10,000 (10ê°œ ë¶„ì•¼) | 808 (21ê°œ ë¬¸ì²´) |\n",
    "| **ê²€ìƒ‰ íƒœìŠ¤í¬** | 10,000 | 1,209 (4ì„œ) |\n",
    "| **êµ¬ë‘ì  íƒœìŠ¤í¬** | 10,000 | 2,000 |\n",
    "| **NER íƒœìŠ¤í¬** | 10,000 | âŒ (NLIë¡œ ëŒ€ì²´) |\n",
    "| **NLI íƒœìŠ¤í¬** | âŒ | 1,854 |\n",
    "| **ë²ˆì—­ íƒœìŠ¤í¬** | 10,000 | 2,000 (3ê°œ ì–¸ì–´) |\n",
    "| **ì–¸ì–´** | ê³ ì „ ì¤‘êµ­ì–´, í˜„ëŒ€ ì¤‘êµ­ì–´ | ê³ ì „ í•œë¬¸, í•œêµ­ì–´, ì˜ì–´ |\n",
    "\n",
    "### ì£¼ìš” ì°¨ì´ì \n",
    "\n",
    "1. **NLI íƒœìŠ¤í¬ ì¶”ê°€**: C3Benchì˜ NER ëŒ€ì‹  NLI(ìì—°ì–¸ì–´ì¶”ë¡ ) í¬í•¨\n",
    "2. **ë‹¤êµ­ì–´ ì§€ì›**: í•œë¬¸-í•œê¸€-ì˜ë¬¸ 3ê°œ ì–¸ì–´ ì§€ì›\n",
    "3. **ë¬¸ì²´ ì„¸ë¶„í™”**: 21ê°œì˜ ì„¸ë°€í•œ ë¬¸ì²´ ì¹´í…Œê³ ë¦¬\n",
    "4. **ì‹¤ìš©ì  ê·œëª¨**: ì•½ 8ì²œê°œ í•­ëª©ìœ¼ë¡œ ì‹¤í—˜ ê°€ëŠ¥í•œ ê·œëª¨\n",
    "\n",
    "---\n",
    "\n",
    "## ë°ì´í„° ì¶œì²˜\n",
    "\n",
    "### 1. ê³¼ê±°ì‹œí—˜ ë°ì´í„° (3,348 â†’ 2,849 í•­ëª©)\n",
    "\n",
    "- **íŒŒì¼**: `translated_full_20251020_212605.csv`\n",
    "- **ë‚´ìš©**: ì¡°ì„ ì‹œëŒ€ ê³¼ê±°ì‹œí—˜ ë¬¸ì œ ë° ë‹µì•ˆ\n",
    "- **í¬í•¨ ì •ë³´**:\n",
    "  - question_id, category (ë¬¸ì²´)\n",
    "  - abstract, content (ì›ë¬¸ í•œë¬¸)\n",
    "  - abstract_ko, content_ko (í•œê¸€ ë²ˆì—­)\n",
    "  - abstract_en, content_en (ì˜ë¬¸ ë²ˆì—­)\n",
    "\n",
    "### 2. ì‚¬ì„œ(å››æ›¸) ë°ì´í„° (2,624 â†’ 2,119 í•­ëª©)\n",
    "\n",
    "- **íŒŒì¼**: `External_raw.csv`\n",
    "- **í¬í•¨ ì„œì **:\n",
    "  - è«–èª (ë…¼ì–´)\n",
    "  - å­Ÿå­ (ë§¹ì)\n",
    "  - å¤§å­¸ (ëŒ€í•™)\n",
    "  - ä¸­åº¸ (ì¤‘ìš©)\n",
    "- **í¬í•¨ ì •ë³´**:\n",
    "  - Book, Chapter, Volume, Index\n",
    "  - Original (ì›ë¬¸ í•œë¬¸)\n",
    "  - Original_trans (í•œê¸€ ë²ˆì—­)\n",
    "  - Comment (ì£¼ì„)\n",
    "\n",
    "### 3. NLI ì˜ˆì‹œ ë°ì´í„° (15 í•­ëª©)\n",
    "\n",
    "- **íŒŒì¼**: `nli_examples.json`\n",
    "- **ë‚´ìš©**: ìì—°ì–¸ì–´ì¶”ë¡  í…œí”Œë¦¿ ë° ì˜ˆì‹œ\n",
    "- **í™œìš©**: NLI íƒœìŠ¤í¬ ìƒì„± ì‹œ ê°€ì´ë“œë¼ì¸\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¬ ìƒì„± í”„ë¡œì„¸ìŠ¤\n",
    "\n",
    "### 1. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "```\n",
    "ê³¼ê±°ì‹œí—˜ ë°ì´í„°: 3,348 â†’ 2,849 í•­ëª© (ê²°ì¸¡ì¹˜ ì œê±°)\n",
    "ì‚¬ì„œ ë°ì´í„°: 2,624 â†’ 2,119 í•­ëª© (ê²°ì¸¡ì¹˜ ì œê±°)\n",
    "```\n",
    "\n",
    "### 2. íƒœìŠ¤í¬ë³„ ìƒì„± ì „ëµ\n",
    "\n",
    "#### Classification (808ê°œ)\n",
    "- ì¹´í…Œê³ ë¦¬ë³„ ê· ë“± ìƒ˜í”Œë§ (ê° 95ê°œ)\n",
    "- abstract ë˜ëŠ” content ì‚¬ìš©\n",
    "\n",
    "#### Retrieval (1,209ê°œ)\n",
    "- ì±…ë³„ ê· ë“± ìƒ˜í”Œë§\n",
    "- Book + Chapter ì •ë³´ í¬í•¨\n",
    "\n",
    "#### Punctuation (2,000ê°œ)\n",
    "- í•œê¸€ ë²ˆì—­ë¬¸ì—ì„œ êµ¬ë‘ì  ì œê±°\n",
    "- ìµœì†Œ ê¸¸ì´ 10ì ì´ìƒ í•„í„°ë§\n",
    "- ì‚¬ì„œ 50% + ê³¼ê±°ì‹œí—˜ 50%\n",
    "\n",
    "#### NLI (1,854ê°œ)\n",
    "- **Entailment (70.8%)**:\n",
    "  - ì›ë¬¸ â†’ ë²ˆì—­ ê´€ê³„\n",
    "  - í•œë¬¸ â†’ í•œê¸€ â†’ ì˜ë¬¸\n",
    "- **Neutral (21.6%)**:\n",
    "  - ë‹¤ë¥¸ ì±…ì˜ ë¬¸ì¥ í˜ì–´ë§\n",
    "- **Contradiction (7.6%)**:\n",
    "  - ë¶€ì • í‘œí˜„ ì¶”ê°€\n",
    "  - ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ ë¬¸ì¥ ì¡°í•©\n",
    "\n",
    "#### Translation (2,000ê°œ)\n",
    "- í•œë¬¸ â†’ í•œê¸€ (66%)\n",
    "- í•œê¸€ â†’ ì˜ë¬¸ (34%)\n",
    "\n",
    "### 3. í’ˆì§ˆ ê²€ì¦\n",
    "\n",
    "- ì´ì¤‘ ê²€ì¦ (ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„)\n",
    "- ìµœì†Œ ê¸¸ì´ í•„í„°ë§\n",
    "- ë ˆì´ë¸” ë¶„í¬ ê· í˜• í™•ì¸\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ íŒŒì¼ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "korean_eda/\n",
    "â”œâ”€â”€ benchmark/\n",
    "â”‚   â””â”€â”€ k_classic_bench/\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_full.json          (5.0 MB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_classification.json (248 KB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_retrieval.json      (447 KB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_punctuation.json    (1.6 MB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_nli.json            (1.1 MB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_translation.json    (1.3 MB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_classification.csv  (134 KB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_retrieval.csv       (239 KB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_punctuation.csv     (1.3 MB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_nli.csv             (774 KB)\n",
    "â”‚       â”œâ”€â”€ k_classic_bench_translation.csv     (952 KB)\n",
    "â”‚       â””â”€â”€ README.md                           (4.4 KB)\n",
    "â”œâ”€â”€ notebook/experiments/\n",
    "â”‚   â”œâ”€â”€ k_classic_bench_generator.py            (ìƒì„± ìŠ¤í¬ë¦½íŠ¸)\n",
    "â”‚   â”œâ”€â”€ k_classic_bench_summary.ipynb           (ë³¸ ë¬¸ì„œ)\n",
    "â”‚   â””â”€â”€ 4ë²ˆì‹¤í—˜.ipynb                           (C3Bench ì œì•ˆì„œ)\n",
    "â””â”€â”€ data/\n",
    "    â”œâ”€â”€ External_raw.csv                        (ì‚¬ì„œ ë°ì´í„°)\n",
    "    â””â”€â”€ translated_full_20251020_212605.csv     (ê³¼ê±°ì‹œí—˜ ë°ì´í„°)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## í–¥í›„ ê³„íš\n",
    "\n",
    "### Phase 1: ë²¤ì¹˜ë§ˆí¬ í™•ì¥ (ëª©í‘œ: 10,000+ í•­ëª©)\n",
    "- [ ] Classification: 1,000ê°œë¡œ ì¦ê°€ (ë” ë§ì€ ë¬¸ì²´)\n",
    "- [ ] Retrieval: 2,000ê°œë¡œ ì¦ê°€ (ì˜¤ê²½ ì¶”ê°€)\n",
    "- [ ] NER íƒœìŠ¤í¬ ì¶”ê°€ (ì¸ëª…, ì§€ëª…, ê´€ì§ëª… ë“±)\n",
    "\n",
    "### Phase 2: í’ˆì§ˆ ê°œì„ \n",
    "- [ ] ì „ë¬¸ê°€ ê²€ì¦ (ê³ ì „ë¬¸í—Œí•™ì)\n",
    "- [ ] NLI Contradiction ìƒ˜í”Œ í’ˆì§ˆ í–¥ìƒ\n",
    "- [ ] ë‚œì´ë„ ë ˆì´ë¸”ë§ ì¶”ê°€\n",
    "\n",
    "### Phase 3: í‰ê°€ ì‹¤í—˜\n",
    "- [ ] ì£¼ìš” LLM í‰ê°€ (GPT-4, Claude, Gemini ë“±)\n",
    "- [ ] í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ í‰ê°€ (HyperCLOVA X, EXAONE ë“±)\n",
    "- [ ] ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ êµ¬ì¶•\n",
    "\n",
    "### Phase 4: ê³µê°œ ë° ë°°í¬\n",
    "- [ ] GitHub ê³µê°œ ì €ì¥ì†Œ\n",
    "- [ ] Hugging Face Datasets ë“±ë¡\n",
    "- [ ] ë¦¬ë”ë³´ë“œ êµ¬ì¶•\n",
    "- [ ] ë…¼ë¬¸ ì‘ì„± ë° íˆ¬ê³ \n",
    "\n",
    "---\n",
    "\n",
    "## ë¼ì´ì„ ìŠ¤ ë° ì¸ìš©\n",
    "\n",
    "### ì¸ìš© ë°©ë²•\n",
    "\n",
    "```bibtex\n",
    "@misc{k_classic_bench_2024,\n",
    "  title={KLSBench: Korean Classical Literature Understanding Benchmark},\n",
    "  author={[Your Name]},\n",
    "  year={2025},\n",
    "  note={Inspired by C3Bench},\n",
    "  url={https://github.com/[your-repo]/k-classic-bench}\n",
    "}\n",
    "```\n",
    "\n",
    "### ì°¸ê³  ë¬¸í—Œ\n",
    "\n",
    "- **C3Bench**: Sun et al., \"C3Bench: A Comprehensive Classical Chinese Understanding Benchmark for Large Language Models\"\n",
    "\n",
    "---\n",
    "\n",
    "## ë¬¸ì˜\n",
    "\n",
    "ë²¤ì¹˜ë§ˆí¬ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì€ ì´ë©”ì¼ë¡œ ì—°ë½ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "**ìƒì„±ì¼**: 2024-10-21\n",
    "\n",
    "**ë²„ì „**: 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loading_data",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_libraries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded and plotting style configured.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str((Path.cwd() / 'notebook/experiments/utils').resolve()))\n",
    "from font_fix import setup_korean_fonts_robust\n",
    "\n",
    "setup_korean_fonts_robust()\n",
    "\n",
    "# Configure plotting for A4-friendly PDF exports\n",
    "A4_WIDTH_INCH = 8.27\n",
    "A4_HEIGHT_INCH = 11.69\n",
    "DEFAULT_FIGSIZE = (A4_WIDTH_INCH, A4_HEIGHT_INCH * 0.6)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': DEFAULT_FIGSIZE,\n",
    "    'savefig.dpi': 300,\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 13,\n",
    "    'xtick.labelsize': 11,\n",
    "    'ytick.labelsize': 11,\n",
    "    'legend.fontsize': 11\n",
    "})\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "BENCHMARK_PATH = '/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/kls_bench_full.json'\n",
    "RESULTS_DIR = '/Users/songhune/Workspace/korean_eda/results'\n",
    "RESULTS_DIR_PATH = Path(RESULTS_DIR)\n",
    "RESULTS_DIR_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_plot_as_pdf(fig, filename: str, directory: Path | None = None) -> Path:\n",
    "    # Save the figure as a high-resolution PDF.\n",
    "    target_dir = directory or RESULTS_DIR_PATH\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    pdf_path = target_dir / f\"{filename}.pdf\"\n",
    "    fig.savefig(pdf_path, format='pdf', bbox_inches='tight')\n",
    "    print(f'ğŸ“„ PDF saved: {pdf_path}')\n",
    "    return pdf_path\n",
    "\n",
    "print(\" í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "load_benchmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Benchmark overview:\n",
      "  - Name: KLSBench\n",
      "  - Total items: 7,871\n",
      "  - Tasks: 5\n",
      "  - Languages: Classical Chinese, Korean, English\n"
     ]
    }
   ],
   "source": [
    "# Load benchmark metadata\n",
    "with open('/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/kls_bench_full.json', 'r', encoding='utf-8') as f:\n",
    "    benchmark = json.load(f)\n",
    "\n",
    "print('ğŸ“‹ Benchmark overview:')\n",
    "print(f\"  - Name: {benchmark['benchmark_info']['name']}\")\n",
    "print(f\"  - Total items: {benchmark['benchmark_info']['total_size']:,}\")\n",
    "print(f\"  - Tasks: {len(benchmark['benchmark_info']['tasks'])}\")\n",
    "print(f\"  - Languages: {', '.join(benchmark['benchmark_info']['languages'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_csvs",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/kls_bench_classification.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load task-level CSV data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_classification \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/kls_bench_classification.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_retrieval \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/kls_bench_retrieval.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m df_punctuation \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/kls_bench_punctuation.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/kls_bench_classification.csv'"
     ]
    }
   ],
   "source": [
    "# Load task-level CSV data\n",
    "df_classification = pd.read_csv('/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/k_classic_bench_classification.csv')\n",
    "df_retrieval = pd.read_csv('/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/k_classic_bench_retrieval.csv')\n",
    "df_punctuation = pd.read_csv('/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/k_classic_bench_punctuation.csv')\n",
    "df_nli = pd.read_csv('/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/k_classic_bench_nli.csv')\n",
    "df_translation = pd.read_csv('/Users/songhune/Workspace/korean_eda/benchmark/kls_bench/k_classic_bench_translation.csv')\n",
    "\n",
    "print(' Task datasets loaded successfully:')\n",
    "print(f\"  - Classification: {len(df_classification):,} samples\")\n",
    "print(f\"  - Retrieval: {len(df_retrieval):,} samples\")\n",
    "print(f\"  - Punctuation: {len(df_punctuation):,} samples\")\n",
    "print(f\"  - NLI: {len(df_nli):,} samples\")\n",
    "print(f\"  - Translation: {len(df_translation):,} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì‹œê°í™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_task_distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task volume by category\n",
    "task_sizes = {\n",
    "    'Classification': len(df_classification),\n",
    "    'Retrieval': len(df_retrieval),\n",
    "    'Punctuation': len(df_punctuation),\n",
    "    'NLI': len(df_nli),\n",
    "    'Translation': len(df_translation)\n",
    "}\n",
    "total_items = sum(task_sizes.values())\n",
    "category_count = len(task_sizes)\n",
    "fig_height = max(A4_HEIGHT_INCH * 0.6, 0.45 * category_count)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(A4_WIDTH_INCH * 1.05, fig_height))\n",
    "bars = ax.bar(task_sizes.keys(), task_sizes.values(), color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8'])\n",
    "labels = [f\"{size:,} ({size / total_items * 100:.1f}%)\" for size in task_sizes.values()]\n",
    "ax.bar_label(bars, labels=labels, padding=8, fontsize=11, fontweight='bold', label_type='edge')\n",
    "\n",
    "ax.set_title('KLSBench Task Distribution by Volume')\n",
    "ax.set_xlabel('Task category')\n",
    "ax.set_ylabel('Sample count')\n",
    "ax.set_ylim(0, max(task_sizes.values()) * 1.18)\n",
    "ax.tick_params(axis='x', rotation=15)\n",
    "ax.grid(axis='y', alpha=0.25)\n",
    "ax.margins(x=0.05)\n",
    "ax.text(0.02, 0.94, f\"Total samples: {total_items:,}\", transform=ax.transAxes, fontsize=11, fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "save_plot_as_pdf(fig, 'k_classicbench_task_distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification: top 10 styles\n",
    "classification_counts = df_classification['label'].value_counts().head(10)\n",
    "classification_total = len(df_classification)\n",
    "sorted_counts = classification_counts.sort_values()\n",
    "fig_height = max(A4_HEIGHT_INCH * 0.6, 0.45 * len(sorted_counts))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(A4_WIDTH_INCH * 1.2, fig_height))\n",
    "bars = ax.barh(sorted_counts.index, sorted_counts.values, color='#FF6B6B')\n",
    "labels = [f\"{count:,} ({count / classification_total * 100:.1f}%)\" for count in sorted_counts.values]\n",
    "ax.bar_label(bars, labels=labels, padding=8, fontsize=11, fontweight='bold', label_type='edge')\n",
    "\n",
    "ax.set_title('Classification Task: Top 10 Styles by Sample Count')\n",
    "ax.set_xlabel('Sample count')\n",
    "ax.set_ylabel('Style label')\n",
    "ax.grid(axis='x', alpha=0.25)\n",
    "ax.margins(y=0.08)\n",
    "ax.text(0.02, 0.94, f\"Total samples: {classification_total:,}\", transform=ax.transAxes, fontsize=11, fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "save_plot_as_pdf(fig, 'classification_style_top10')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_nli",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLI label distribution\n",
    "nli_counts = df_nli['label'].value_counts()\n",
    "total_nli = nli_counts.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(A4_WIDTH_INCH, A4_HEIGHT_INCH * 0.8))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    nli_counts.values,\n",
    "    labels=nli_counts.index,\n",
    "    autopct=lambda pct: f\"{pct:.1f}%\\n({int(round(pct / 100 * total_nli)):,})\",\n",
    "    colors=['#4ECDC4', '#FFA07A', '#FF6B6B'],\n",
    "    startangle=90,\n",
    "    pctdistance=0.78,\n",
    "    labeldistance=1.08,\n",
    "    textprops={'fontsize': 11}\n",
    ")\n",
    "centre_circle = plt.Circle((0, 0), 0.45, fc='white')\n",
    "fig.gca().add_artist(centre_circle)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "ax.set_title('NLI Task: Label Distribution')\n",
    "ax.axis('equal')\n",
    "ax.legend(\n",
    "    wedges,\n",
    "    [f\"{label}: {count:,}\" for label, count in nli_counts.items()],\n",
    "    title='Label (count)',\n",
    "    loc='center left',\n",
    "    bbox_to_anchor=(1.05, 0.5),\n",
    "    frameon=False\n",
    ")\n",
    "ax.text(0, 0, f\"Total\\n{total_nli:,}\", ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "save_plot_as_pdf(fig, 'nli_label_distribution')\n",
    "plt.show()\n",
    "\n",
    "print('\n",
    "Label statistics:')\n",
    "for label, count in nli_counts.items():\n",
    "    print(f\"  - {label}: {count:,} samples ({count / total_nli * 100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz_translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation: language pair distribution\n",
    "df_translation['lang_pair'] = df_translation['source_lang'] + ' -> ' + df_translation['target_lang']\n",
    "translation_counts = df_translation['lang_pair'].value_counts()\n",
    "translation_total = len(df_translation)\n",
    "\n",
    "top_limit = 12\n",
    "if len(translation_counts) > top_limit:\n",
    "    top_counts = translation_counts.head(top_limit)\n",
    "    others_total = translation_counts.iloc[top_limit:].sum()\n",
    "    translation_summary = pd.concat([top_counts, pd.Series({'Others': others_total})])\n",
    "else:\n",
    "    translation_summary = translation_counts\n",
    "\n",
    "ordered_counts = translation_summary.sort_values()\n",
    "fig_height = max(A4_HEIGHT_INCH * 0.6, 0.4 * len(ordered_counts))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(A4_WIDTH_INCH * 1.25, fig_height))\n",
    "bars = ax.barh(ordered_counts.index, ordered_counts.values, color='#98D8C8')\n",
    "labels = [f\"{count:,} ({count / translation_total * 100:.1f}%)\" for count in ordered_counts.values]\n",
    "ax.bar_label(bars, labels=labels, padding=8, fontsize=11, fontweight='bold', label_type='edge')\n",
    "\n",
    "ax.set_title('Translation Task: Language Pair Distribution (Top Segments)')\n",
    "ax.set_xlabel('Sample count')\n",
    "ax.set_ylabel('Language pair')\n",
    "ax.grid(axis='x', alpha=0.25)\n",
    "ax.margins(y=0.12)\n",
    "ax.set_xlim(0, ordered_counts.max() * 1.12)\n",
    "ax.text(0.02, 0.94, f\"Total samples: {translation_total:,}\", transform=ax.transAxes, fontsize=11, fontweight='bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "save_plot_as_pdf(fig, 'translation_language_pair_distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "examples",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì˜ˆì‹œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Classification ì˜ˆì‹œ:\")\n",
    "print(\"=\" * 70)\n",
    "for i, row in df_classification.head(3).iterrows():\n",
    "    print(f\"\\n[{i+1}] ID: {row['id']}\")\n",
    "    print(f\"ì…ë ¥: {row['input'][:100]}...\")\n",
    "    print(f\"ë ˆì´ë¸”: {row['label']}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_nli",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" NLI ì˜ˆì‹œ:\")\n",
    "print(\"=\" * 70)\n",
    "for i, row in df_nli.head(3).iterrows():\n",
    "    print(f\"\\n[{i+1}] ID: {row['id']}\")\n",
    "    print(f\"Premise: {row['premise'][:80]}...\")\n",
    "    print(f\"Hypothesis: {row['hypothesis'][:80]}...\")\n",
    "    print(f\"Label: {row['label']}\")\n",
    "    print(f\"Category: {row['category']}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Translation ì˜ˆì‹œ:\")\n",
    "print(\"=\" * 70)\n",
    "for i, row in df_translation.head(3).iterrows():\n",
    "    print(f\"\\n[{i+1}] ID: {row['id']}\")\n",
    "    print(f\"Source ({row['source_lang']}): {row['source_text'][:80]}...\")\n",
    "    print(f\"Target ({row['target_lang']}): {row['target_text'][:80]}...\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistics",
   "metadata": {},
   "source": [
    "## ìƒì„¸ í†µê³„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stats_text_length",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ ê¸¸ì´ í†µê³„\n",
    "df_classification['input_length'] = df_classification['input'].apply(len)\n",
    "df_nli['premise_length'] = df_nli['premise'].apply(len)\n",
    "df_nli['hypothesis_length'] = df_nli['hypothesis'].apply(len)\n",
    "df_translation['source_length'] = df_translation['source_text'].apply(len)\n",
    "\n",
    "print(\"ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´ í†µê³„:\")\n",
    "print(\"\\nClassification (ì…ë ¥):\")\n",
    "print(f\"  í‰ê· : {df_classification['input_length'].mean():.1f}ì\")\n",
    "print(f\"  ì¤‘ì•™ê°’: {df_classification['input_length'].median():.1f}ì\")\n",
    "print(f\"  ìµœì†Œ/ìµœëŒ€: {df_classification['input_length'].min()}ì / {df_classification['input_length'].max()}ì\")\n",
    "\n",
    "print(\"\\nNLI (Premise):\")\n",
    "print(f\"  í‰ê· : {df_nli['premise_length'].mean():.1f}ì\")\n",
    "print(f\"  ì¤‘ì•™ê°’: {df_nli['premise_length'].median():.1f}ì\")\n",
    "\n",
    "print(\"\\nTranslation (Source):\")\n",
    "print(f\"  í‰ê· : {df_translation['source_length'].mean():.1f}ì\")\n",
    "print(f\"  ì¤‘ì•™ê°’: {df_translation['source_length'].median():.1f}ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  ê²°ë¡ \n",
    "\n",
    "KLSBench v1.0ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "### ì£¼ìš” ì„±ê³¼\n",
    "\n",
    " **ì´ 7,871ê°œ í•­ëª©** ìƒì„±\n",
    "\n",
    " **5ê°€ì§€ í•µì‹¬ íƒœìŠ¤í¬** êµ¬ì„±\n",
    "- Classification (808ê°œ)\n",
    "- Retrieval (1,209ê°œ)\n",
    "- Punctuation (2,000ê°œ)\n",
    "- NLI (1,854ê°œ)\n",
    "- Translation (2,000ê°œ)\n",
    "\n",
    " **ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤** í™œìš©\n",
    "- ê³¼ê±°ì‹œí—˜ ë°ì´í„°\n",
    "- ì‚¬ì„œ(å››æ›¸) ë°ì´í„°\n",
    "- NLI í…œí”Œë¦¿\n",
    "\n",
    " **3ê°œ ì–¸ì–´ ì§€ì›**: ê³ ì „ í•œë¬¸, í•œêµ­ì–´, ì˜ì–´\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **ë²¤ì¹˜ë§ˆí¬ í™•ì¥**: 10,000+ í•­ëª© ëª©í‘œ\n",
    "2. **í’ˆì§ˆ ê°œì„ **: ì „ë¬¸ê°€ ê²€ì¦\n",
    "3. **LLM í‰ê°€**: ì£¼ìš” ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì •\n",
    "4. **ê³µê°œ ë°°í¬**: GitHub, Hugging Face\n",
    "\n",
    "---\n",
    "\n",
    "**KLSBench v1.0**\n",
    "\n",
    "_í•œêµ­ ê³ ì „ ë¬¸í—Œ ì´í•´ì˜ ìƒˆë¡œìš´ ê¸°ì¤€_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153637e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
