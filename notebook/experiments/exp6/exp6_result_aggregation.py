"""
Experiment 6: K-ClassicBench Result Aggregation and Visualization
ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ê²°ê³¼ë¥¼ í†µí•©í•˜ê³  ì‹œê°í™”í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ê¸°ëŠ¥:
1. ëª¨ë“  í‰ê°€ ê²°ê³¼ JSON/CSV íŒŒì¼ì„ ë¡œë“œ
2. ìµœì‹  ê²°ê³¼ë§Œ ì„ íƒ (ê°™ì€ ëª¨ë¸ì˜ ì—¬ëŸ¬ ì‹¤í–‰ ì¤‘)
3. ê²°ê³¼ë¥¼ í†µí•© í…Œì´ë¸”ë¡œ ì •ë¦¬
4. ì‹œê°í™” ìƒì„±:
   - íƒœìŠ¤í¬ë³„ ì„±ëŠ¥ ë¹„êµ (íˆíŠ¸ë§µ)
   - ëª¨ë¸ë³„ ì¢…í•© ì„±ëŠ¥ (ë°” ì°¨íŠ¸)
   - ë ˆì´ë” ì°¨íŠ¸
"""

import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List
from collections import defaultdict
import argparse
import sys

CURRENT_DIR = Path(__file__).resolve().parent
UTILS_DIR = CURRENT_DIR.parent / "utils"
if str(UTILS_DIR) not in sys.path:
    sys.path.append(str(UTILS_DIR))

try:
    from font_fix import setup_korean_fonts_robust
except ImportError:
    setup_korean_fonts_robust = None

A4_WIDTH_INCH = 8.27
A4_HEIGHT_INCH = 11.69
PROJECT_ROOT = Path(__file__).resolve().parents[3]
DEFAULT_RESULTS_DIR = PROJECT_ROOT / "results" / "raw_evaluation"
DEFAULT_OUTPUT_DIR = PROJECT_ROOT / "results" / "aggregated"


def abbreviate_model_name(model_name: str) -> str:
    """
    ëª¨ë¸ ì´ë¦„ì„ ì¶•ì•½í•˜ì—¬ ê·¸ë˜í”„ì—ì„œ ë³´ê¸° ì¢‹ê²Œ ë§Œë“¦

    ì˜ˆì‹œ:
    - meta-llama/Llama-3.1-8B-Instruct -> Llama-3.1-8B
    - Qwen/Qwen2.5-7B-Instruct -> Qwen2.5-7B
    - claude-3-5-sonnet-20241022 -> Claude-3.5-Sonnet
    """
    # OpenAI ëª¨ë¸
    if 'gpt-4o' in model_name.lower():
        if 'mini' in model_name.lower():
            return 'GPT-4o-mini'
        return 'GPT-4o'
    if 'gpt-4-turbo' in model_name.lower():
        return 'GPT-4-Turbo'
    if 'gpt-3.5-turbo' in model_name.lower():
        return 'GPT-3.5-Turbo'

    # Anthropic ëª¨ë¸
    if 'claude-3-5-sonnet' in model_name.lower() or 'claude-3.5-sonnet' in model_name.lower():
        return 'Claude-3.5-Sonnet'
    if 'claude-3-opus' in model_name.lower():
        return 'Claude-3-Opus'
    if 'claude-3-sonnet' in model_name.lower():
        return 'Claude-3-Sonnet'
    if 'claude-3-haiku' in model_name.lower():
        return 'Claude-3-Haiku'

    # Meta Llama ëª¨ë¸
    if 'llama' in model_name.lower():
        if '3.3' in model_name:
            size = '70B' if '70b' in model_name.lower() else '8B'
            return f'Llama-3.3-{size}'
        if '3.1' in model_name:
            size = '70B' if '70b' in model_name.lower() else '8B'
            return f'Llama-3.1-{size}'
        if '3.0' in model_name or 'llama-3-' in model_name.lower():
            size = '70B' if '70b' in model_name.lower() else '8B'
            return f'Llama-3-{size}'

    # Qwen ëª¨ë¸
    if 'qwen' in model_name.lower():
        if '2.5' in model_name:
            size = '72B' if '72b' in model_name.lower() else '32B' if '32b' in model_name.lower() else '7B'
            return f'Qwen2.5-{size}'
        if '2' in model_name:
            size = '72B' if '72b' in model_name.lower() else '7B'
            return f'Qwen2-{size}'

    # Google Gemini ëª¨ë¸
    if 'gemini' in model_name.lower():
        if '1.5-pro' in model_name.lower():
            return 'Gemini-1.5-Pro'
        if '1.5-flash' in model_name.lower():
            return 'Gemini-1.5-Flash'
        if '1.0-pro' in model_name.lower():
            return 'Gemini-1.0-Pro'

    # ê¸°íƒ€ ëª¨ë¸ - ê²½ë¡œ ì œê±°
    if '/' in model_name:
        model_name = model_name.split('/')[-1]

    # -Instruct, -Chat ë“± ì ‘ë¯¸ì‚¬ ì œê±°
    for suffix in ['-Instruct', '-Chat', '-instruct', '-chat']:
        model_name = model_name.replace(suffix, '')

    return model_name


def configure_matplotlib():
    """Ensure consistent typography and sizing for publication-ready figures."""
    if setup_korean_fonts_robust:
        setup_korean_fonts_robust()
    else:
        plt.rcParams['font.family'] = 'AppleGothic'
        plt.rcParams['axes.unicode_minus'] = False

    plt.rcParams.update({
        'figure.figsize': (A4_WIDTH_INCH, A4_HEIGHT_INCH * 0.6),
        'savefig.dpi': 300,
        'font.size': 11,
        'axes.titlesize': 16,
        'axes.labelsize': 13,
        'xtick.labelsize': 11,
        'ytick.labelsize': 11,
        'legend.fontsize': 11,
    })


class ResultAggregator:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ í†µí•© í´ë˜ìŠ¤"""

    def __init__(self, results_dir: str):
        self.results_dir = Path(results_dir)
        self.results = []
        self.df = None

    def load_all_results(self):
        """ëª¨ë“  ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
        print("ğŸ“‚ ê²°ê³¼ íŒŒì¼ ë¡œë”© ì¤‘...")

        # JSON íŒŒì¼ ì°¾ê¸°
        json_files = list(self.results_dir.glob("results_*.json"))
        print(f"  âœ“ ì´ {len(json_files)}ê°œ ê²°ê³¼ íŒŒì¼ ë°œê²¬")

        # ëª¨ë¸ë³„ë¡œ ê·¸ë£¹í™” (ìµœì‹  ê²°ê³¼ë§Œ ì„ íƒ)
        model_results = defaultdict(list)

        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    result = json.load(f)
                    model_name = result['model_name']
                    # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
                    timestamp = json_file.stem.split('_')[-2:]
                    timestamp_str = '_'.join(timestamp)
                    result['timestamp'] = timestamp_str
                    result['file_path'] = str(json_file)
                    model_results[model_name].append(result)
            except Exception as e:
                print(f"    íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {json_file.name} - {e}")

        # ê° ëª¨ë¸ì˜ ìµœì‹  ê²°ê³¼ë§Œ ì„ íƒ
        print(f"\n ëª¨ë¸ë³„ ìµœì‹  ê²°ê³¼ ì„ íƒ:")
        for model_name, results in model_results.items():
            # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ ì •ë ¬
            results.sort(key=lambda x: x['timestamp'], reverse=True)
            latest = results[0]
            self.results.append(latest)
            print(f"  âœ“ {model_name}: {latest['timestamp']}")

        print(f"\n ì´ {len(self.results)}ê°œ ëª¨ë¸ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ")

    def create_summary_table(self) -> pd.DataFrame:
        """ê²°ê³¼ë¥¼ ìš”ì•½ í…Œì´ë¸”ë¡œ ë³€í™˜"""
        print("\n ìš”ì•½ í…Œì´ë¸” ìƒì„± ì¤‘...")

        rows = []
        for result in self.results:
            model_name = result['model_name']
            model_name_short = abbreviate_model_name(model_name)
            model_type = result.get('model_type', 'unknown')

            # ê° íƒœìŠ¤í¬ì˜ ì£¼ìš” ë©”íŠ¸ë¦­ ì¶”ì¶œ
            for task_name, task_result in result['tasks'].items():
                metrics = task_result['metrics']

                row = {
                    'model': model_name_short,
                    'model_full': model_name,
                    'model_type': model_type,
                    'task': task_name,
                }

                # íƒœìŠ¤í¬ë³„ ì£¼ìš” ë©”íŠ¸ë¦­ ì¶”ê°€
                if task_name == 'classification':
                    row['accuracy'] = metrics.get('accuracy', 0)
                    row['f1'] = metrics.get('f1', 0)
                    row['primary_metric'] = metrics.get('accuracy', 0)

                elif task_name == 'retrieval':
                    row['accuracy'] = metrics.get('accuracy', 0)
                    row['primary_metric'] = metrics.get('accuracy', 0)

                elif task_name == 'punctuation':
                    row['char_f1'] = metrics.get('char_f1', 0)
                    row['rougeL_f1'] = metrics.get('rougeL_f1', 0)
                    row['primary_metric'] = metrics.get('char_f1', 0)

                elif task_name == 'nli':
                    row['accuracy'] = metrics.get('accuracy', 0)
                    row['f1'] = metrics.get('f1', 0)
                    row['primary_metric'] = metrics.get('accuracy', 0)

                elif task_name == 'translation':
                    row['bleu'] = metrics.get('bleu', 0)
                    row['rougeL_f1'] = metrics.get('rougeL_f1', 0)
                    row['primary_metric'] = metrics.get('bleu', 0)

                rows.append(row)

        self.df = pd.DataFrame(rows)
        print(f"  âœ“ {len(self.df)}ê°œ í–‰ ìƒì„± ì™„ë£Œ")

        return self.df

    def save_aggregated_results(self, output_dir: str):
        """í†µí•© ê²°ê³¼ ì €ì¥"""
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        # 1. ì „ì²´ ìš”ì•½ í…Œì´ë¸”
        summary_path = output_dir / "aggregated_summary.csv"
        self.df.to_csv(summary_path, index=False, encoding='utf-8-sig')
        print(f"\n ìš”ì•½ í…Œì´ë¸” ì €ì¥: {summary_path}")

        # 2. í”¼ë²— í…Œì´ë¸” (ëª¨ë¸ Ã— íƒœìŠ¤í¬)
        pivot = self.df.pivot_table(
            index='model',
            columns='task',
            values='primary_metric',
            aggfunc='first'
        )
        pivot_path = output_dir / "aggregated_pivot.csv"
        pivot.to_csv(pivot_path, encoding='utf-8-sig')
        print(f" í”¼ë²— í…Œì´ë¸” ì €ì¥: {pivot_path}")

        # 3. ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥
        model_avg = self.df.groupby('model')['primary_metric'].mean().sort_values(ascending=False)
        model_avg_path = output_dir / "model_average_performance.csv"
        model_avg.to_csv(model_avg_path, header=['average_score'], encoding='utf-8-sig')
        print(f" ëª¨ë¸ í‰ê·  ì„±ëŠ¥: {model_avg_path}")

        return pivot

    def visualize_results(self, output_dir: str):
        """ê²°ê³¼ ì‹œê°í™”"""
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        print("\n ì‹œê°í™” ìƒì„± ì¤‘...")

        configure_matplotlib()

        # 1. íˆíŠ¸ë§µ: ëª¨ë¸ Ã— íƒœìŠ¤í¬ ì„±ëŠ¥
        self._create_heatmap(output_dir)

        # 2. ë°” ì°¨íŠ¸: ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥
        self._create_bar_chart(output_dir)

        # 3. íƒœìŠ¤í¬ë³„ ì„±ëŠ¥ ë¹„êµ (ê·¸ë£¹ ë°” ì°¨íŠ¸)
        self._create_grouped_bar_chart(output_dir)

        # 4. ë ˆì´ë” ì°¨íŠ¸
        self._create_radar_chart(output_dir)

        print(f" ì‹œê°í™” ì™„ë£Œ: {output_dir}")

    def _create_heatmap(self, output_dir: Path):
        """íˆíŠ¸ë§µ ìƒì„±"""
        pivot = self.df.pivot_table(
            index='model',
            columns='task',
            values='primary_metric',
            aggfunc='first'
        )

        fig, ax = plt.subplots(figsize=(A4_WIDTH_INCH, A4_HEIGHT_INCH * 0.7))
        sns.heatmap(
            pivot,
            annot=True,
            fmt='.3f',
            cmap='YlOrRd',
            cbar_kws={'label': 'Score'},
            annot_kws={'fontsize': 12},
            ax=ax
        )
        ax.set_title('K-ClassicBench: Model Performance Heatmap', fontsize=18, fontweight='bold')
        ax.set_xlabel('Task')
        ax.set_ylabel('Model')
        ax.tick_params(axis='x', rotation=45, labelsize=11)
        ax.tick_params(axis='y', labelsize=11)
        fig.tight_layout()

        heatmap_path = output_dir / 'heatmap_performance.pdf'
        fig.savefig(heatmap_path, format='pdf', bbox_inches='tight')
        plt.close(fig)
        print(f"  âœ“ íˆíŠ¸ë§µ: {heatmap_path}")

    def _create_bar_chart(self, output_dir: Path):
        """ë°” ì°¨íŠ¸: ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥"""
        model_avg = self.df.groupby('model')['primary_metric'].mean().sort_values(ascending=True)

        fig, ax = plt.subplots(figsize=(A4_WIDTH_INCH, A4_HEIGHT_INCH * 0.65))
        colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(model_avg)))
        model_avg.plot(kind='barh', color=colors, ax=ax)
        ax.set_title('K-ClassicBench: Average Model Performance', fontsize=18, fontweight='bold')
        ax.set_xlabel('Average Score')
        ax.set_ylabel('Model')
        ax.grid(axis='x', alpha=0.3)
        fig.tight_layout()

        bar_path = output_dir / 'bar_average_performance.pdf'
        fig.savefig(bar_path, format='pdf', bbox_inches='tight')
        plt.close(fig)
        print(f"  âœ“ ë°” ì°¨íŠ¸: {bar_path}")

    def _create_grouped_bar_chart(self, output_dir: Path):
        """ê·¸ë£¹ ë°” ì°¨íŠ¸: íƒœìŠ¤í¬ë³„ ëª¨ë¸ ì„±ëŠ¥"""
        pivot = self.df.pivot_table(
            index='model',
            columns='task',
            values='primary_metric',
            aggfunc='first'
        )

        fig, ax = plt.subplots(figsize=(A4_WIDTH_INCH * 1.05, A4_HEIGHT_INCH * 0.75))
        pivot.plot(kind='bar', ax=ax, width=0.8)
        ax.set_title('K-ClassicBench: Task-wise Model Performance', fontsize=18, fontweight='bold')
        ax.set_xlabel('Model')
        ax.set_ylabel('Score')
        ax.legend(title='Task', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)
        ax.tick_params(axis='x', rotation=45, labelsize=11)
        ax.tick_params(axis='y', labelsize=11)
        ax.grid(axis='y', alpha=0.3)
        fig.tight_layout()

        grouped_bar_path = output_dir / 'grouped_bar_taskwise.pdf'
        fig.savefig(grouped_bar_path, format='pdf', bbox_inches='tight')
        plt.close(fig)
        print(f"  âœ“ ê·¸ë£¹ ë°” ì°¨íŠ¸: {grouped_bar_path}")

    def _create_radar_chart(self, output_dir: Path):
        """ë ˆì´ë” ì°¨íŠ¸: ëª¨ë¸ë³„ íƒœìŠ¤í¬ ì„±ëŠ¥"""
        pivot = self.df.pivot_table(
            index='model',
            columns='task',
            values='primary_metric',
            aggfunc='first'
        ).fillna(0)

        # íƒœìŠ¤í¬ ìˆ˜
        categories = list(pivot.columns)
        N = len(categories)

        # ê°ë„ ê³„ì‚°
        angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()
        angles += angles[:1]  # ì›ì„ ë‹«ê¸° ìœ„í•´

        fig, ax = plt.subplots(figsize=(A4_WIDTH_INCH * 0.9, A4_HEIGHT_INCH * 0.9), subplot_kw=dict(projection='polar'))

        colors = plt.cm.Set2(np.linspace(0, 1, len(pivot)))

        for idx, (model, row) in enumerate(pivot.iterrows()):
            values = row.tolist()
            values += values[:1]  # ì›ì„ ë‹«ê¸° ìœ„í•´

            ax.plot(angles, values, 'o-', linewidth=2, label=model, color=colors[idx])
            ax.fill(angles, values, alpha=0.15, color=colors[idx])

        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, size=14)
        ax.set_ylim(0, 1)
        ax.set_title('K-ClassicBench: Radar Chart - Model Performance',
                     size=18, fontweight='bold', pad=20)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=12)
        ax.grid(True)

        fig.tight_layout()
        radar_path = output_dir / 'radar_chart.pdf'
        fig.savefig(radar_path, format='pdf', bbox_inches='tight')
        plt.close(fig)
        print(f"  âœ“ ë ˆì´ë” ì°¨íŠ¸: {radar_path}")

    def print_summary_statistics(self):
        """ìš”ì•½ í†µê³„ ì¶œë ¥"""
        print("\n" + "=" * 70)
        print(" K-ClassicBench í‰ê°€ ê²°ê³¼ ìš”ì•½")
        print("=" * 70)

        # 1. ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥
        print("\nğŸ† ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥:")
        model_avg = self.df.groupby('model')['primary_metric'].mean().sort_values(ascending=False)
        for rank, (model, score) in enumerate(model_avg.items(), 1):
            print(f"  {rank}. {model:50s} {score:.4f}")

        # 2. íƒœìŠ¤í¬ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        print("\n íƒœìŠ¤í¬ë³„ ìµœê³  ì„±ëŠ¥:")
        for task in self.df['task'].unique():
            task_df = self.df[self.df['task'] == task]
            best_row = task_df.loc[task_df['primary_metric'].idxmax()]
            print(f"  - {task:15s}: {best_row['model']:40s} ({best_row['primary_metric']:.4f})")

        # 3. ëª¨ë¸ íƒ€ì…ë³„ í‰ê·  ì„±ëŠ¥
        print("\n ëª¨ë¸ íƒ€ì…ë³„ í‰ê·  ì„±ëŠ¥:")
        type_avg = self.df.groupby('model_type')['primary_metric'].mean().sort_values(ascending=False)
        for model_type, score in type_avg.items():
            print(f"  - {model_type:15s}: {score:.4f}")

        print("\n" + "=" * 70)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='K-ClassicBench Result Aggregation')
    parser.add_argument('--results-dir', type=str,
                       default=str(DEFAULT_RESULTS_DIR),
                       help='ê²°ê³¼ íŒŒì¼ ë””ë ‰í† ë¦¬')
    parser.add_argument('--output-dir', type=str,
                       default=str(DEFAULT_OUTPUT_DIR),
                       help='í†µí•© ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')

    args = parser.parse_args()

    # ê²°ê³¼ í†µí•©
    aggregator = ResultAggregator(args.results_dir)
    aggregator.load_all_results()
    aggregator.create_summary_table()

    # ê²°ê³¼ ì €ì¥
    aggregator.save_aggregated_results(args.output_dir)

    # ì‹œê°í™”
    aggregator.visualize_results(args.output_dir)

    # í†µê³„ ì¶œë ¥
    aggregator.print_summary_statistics()

    print("\n ê²°ê³¼ í†µí•© ë° ì‹œê°í™” ì™„ë£Œ!")


if __name__ == "__main__":
    main()
