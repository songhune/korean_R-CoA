import pandas as pd
import chardet
import codecs
from pathlib import Path

class EncodingDetector:
    """CSV íŒŒì¼ì˜ ì¸ì½”ë”©ì„ ê°ì§€í•˜ê³  ìˆ˜ì •í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.common_encodings = [
            'utf-8', 'utf-8-sig', 'euc-kr', 'cp949', 
            'iso-8859-1', 'cp1252', 'latin1', 'ascii'
        ]
    
    def detect_file_encoding(self, file_path: str) -> dict:
        """íŒŒì¼ì˜ ì¸ì½”ë”©ì„ ìë™ ê°ì§€"""
        with open(file_path, 'rb') as f:
            raw_data = f.read(100000)  # ì²˜ìŒ 100KBë§Œ ì½ì–´ì„œ ê°ì§€
        
        detected = chardet.detect(raw_data)
        print(f"ğŸ” ìë™ ê°ì§€ ê²°ê³¼: {detected}")
        
        return detected
    
    def try_read_with_encodings(self, file_path: str, sample_rows: int = 5):
        """ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸° ì‹œë„"""
        print(f"\n=== {file_path} ì¸ì½”ë”© í…ŒìŠ¤íŠ¸ ===")
        
        results = {}
        
        for encoding in self.common_encodings:
            try:
                # pandasë¡œ ì½ê¸° ì‹œë„
                df = pd.read_csv(file_path, encoding=encoding, nrows=sample_rows)
                
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì˜ ì²« ë²ˆì§¸ ê°’ì„ ìƒ˜í”Œë¡œ í™•ì¸
                sample_text = ""
                if len(df.columns) > 0 and len(df) > 0:
                    first_col = df.columns[0]
                    if pd.notna(df.iloc[0][first_col]):
                        sample_text = str(df.iloc[0][first_col])[:100]
                
                results[encoding] = {
                    'success': True,
                    'sample': sample_text,
                    'shape': df.shape,
                    'columns': list(df.columns)[:5]  # ì²˜ìŒ 5ê°œ ì»¬ëŸ¼ë§Œ
                }
                
                print(f"âœ… {encoding:12} | ìƒ˜í”Œ: {sample_text[:50]}...")
                
            except Exception as e:
                results[encoding] = {
                    'success': False,
                    'error': str(e)[:100]
                }
                print(f"âŒ {encoding:12} | ì—ëŸ¬: {str(e)[:50]}...")
        
        return results
    
    def check_korean_characters(self, text: str) -> dict:
        """í•œê¸€ ë¬¸ì í¬í•¨ ì—¬ë¶€ ë° í’ˆì§ˆ ê²€ì‚¬"""
        if not text:
            return {'has_korean': False, 'quality': 'empty'}
        
        # í•œê¸€ ë¬¸ì ë²”ìœ„ ì²´í¬
        korean_chars = 0
        broken_chars = 0
        total_chars = len(text)
        
        for char in text:
            # í•œê¸€ ì™„ì„±í˜• (ê°€-í£)
            if '\uAC00' <= char <= '\uD7A3':
                korean_chars += 1
            # í•œê¸€ ìëª¨ (ã„±-ã…, ã…-ã…£)
            elif '\u3131' <= char <= '\u318E':
                korean_chars += 1
            # ê¹¨ì§„ ë¬¸ì íŒ¨í„´
            elif char in 'ÃƒÃŠÂ½ÃŒÂ³Ã¢ÃÂ¦Â´Ã«Â°ÃºÃ‹ÃÃ—Ã¸Ã©Ã¶':
                broken_chars += 1
        
        korean_ratio = korean_chars / total_chars if total_chars > 0 else 0
        broken_ratio = broken_chars / total_chars if total_chars > 0 else 0
        
        # í’ˆì§ˆ íŒì •
        if broken_ratio > 0.1:
            quality = 'broken'
        elif korean_ratio > 0.3:
            quality = 'good'
        elif korean_ratio > 0.1:
            quality = 'fair'
        else:
            quality = 'poor'
        
        return {
            'has_korean': korean_chars > 0,
            'korean_ratio': korean_ratio,
            'broken_ratio': broken_ratio,
            'quality': quality,
            'korean_chars': korean_chars,
            'broken_chars': broken_chars
        }
    
    def find_best_encoding(self, file_path: str) -> str:
        """ê°€ì¥ ì í•©í•œ ì¸ì½”ë”© ì°¾ê¸°"""
        print(f"\nğŸ¯ {file_path} ìµœì  ì¸ì½”ë”© ì°¾ê¸°")
        
        # 1. ìë™ ê°ì§€
        detected = self.detect_file_encoding(file_path)
        
        # 2. ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
        results = self.try_read_with_encodings(file_path)
        
        # 3. í’ˆì§ˆ í‰ê°€
        best_encoding = None
        best_score = -1
        
        print(f"\nğŸ“Š í’ˆì§ˆ í‰ê°€:")
        for encoding, result in results.items():
            if not result['success']:
                continue
            
            quality_info = self.check_korean_characters(result['sample'])
            
            # ì ìˆ˜ ê³„ì‚° (í•œê¸€ ë¹„ìœ¨ ë†’ê³ , ê¹¨ì§„ ë¬¸ì ì ì„ìˆ˜ë¡ ì¢‹ìŒ)
            score = quality_info['korean_ratio'] - quality_info['broken_ratio'] * 2
            
            print(f"{encoding:12} | í’ˆì§ˆ: {quality_info['quality']:6} | ì ìˆ˜: {score:.3f} | í•œê¸€: {quality_info['korean_ratio']:.1%} | ê¹¨ì§: {quality_info['broken_ratio']:.1%}")
            
            if score > best_score:
                best_score = score
                best_encoding = encoding
        
        print(f"\nğŸ† ìµœì  ì¸ì½”ë”©: {best_encoding} (ì ìˆ˜: {best_score:.3f})")
        return best_encoding
    
    def convert_file_encoding(self, input_path: str, output_path: str, 
                             source_encoding: str, target_encoding: str = 'utf-8'):
        """íŒŒì¼ ì¸ì½”ë”© ë³€í™˜"""
        try:
            with open(input_path, 'r', encoding=source_encoding) as f:
                content = f.read()
            
            with open(output_path, 'w', encoding=target_encoding) as f:
                f.write(content)
            
            print(f"âœ… ë³€í™˜ ì™„ë£Œ: {input_path} â†’ {output_path}")
            print(f"   {source_encoding} â†’ {target_encoding}")
            
        except Exception as e:
            print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def check_all_files(self, file_paths: list):
        """ì—¬ëŸ¬ íŒŒì¼ì˜ ì¸ì½”ë”©ì„ ì¼ê´„ ì ê²€"""
        print("=== ì „ì²´ íŒŒì¼ ì¸ì½”ë”© ì ê²€ ===\n")
        
        results = {}
        for file_path in file_paths:
            if Path(file_path).exists():
                best_encoding = self.find_best_encoding(file_path)
                results[file_path] = best_encoding
            else:
                print(f"âŒ íŒŒì¼ ì—†ìŒ: {file_path}")
                results[file_path] = None
        
        print(f"\nğŸ“‹ ìµœì¢… ê¶Œì¥ ì¸ì½”ë”©:")
        for file_path, encoding in results.items():
            if encoding:
                print(f"{Path(file_path).name:20} â†’ {encoding}")
        
        return results

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    detector = EncodingDetector()
    
    # 1. ê°œë³„ íŒŒì¼ ì ê²€
    files_to_check = ["./data/gwashi.csv", "./data/munjib.csv", "./data/sigwon.csv"]

    # 2. ì „ì²´ íŒŒì¼ ì¼ê´„ ì ê²€
    encoding_results = detector.check_all_files(files_to_check)
    
    # 3. í•„ìš”ì‹œ ì¸ì½”ë”© ë³€í™˜
    # detector.convert_file_encoding("gwashi.csv", "gwashi_utf8.csv", "euc-kr", "utf-8")

# íŠ¹ë³„íˆ gwashi.csv ë¬¸ì œ í•´ê²°
def fix_gwashi_encoding():
    """gwashi.csvì˜ íŠ¹ìˆ˜í•œ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°"""
    detector = EncodingDetector()
    
    print("=== gwashi.csv íŠ¹ë³„ ì ê²€ ===")
    
    # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì‹œë„
    file_path = "./data/gwashi.csv"

    # ë°©ë²• 1: ì—¬ëŸ¬ ì¸ì½”ë”© ì¡°í•© ì‹œë„
    encoding_combinations = [
        ('utf-8', 'cp1252'),  # UTF-8ì„ CP1252ë¡œ ì˜ëª» ì½ì€ ê²½ìš°
        ('euc-kr', 'cp1252'), # EUC-KRì„ CP1252ë¡œ ì˜ëª» ì½ì€ ê²½ìš°
        ('cp949', 'cp1252'),  # CP949ë¥¼ CP1252ë¡œ ì˜ëª» ì½ì€ ê²½ìš°
    ]
    
    for original, wrong in encoding_combinations:
        try:
            # ì˜ëª»ëœ ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸°
            with open(file_path, 'r', encoding=wrong) as f:
                content = f.read(1000)  # ìƒ˜í”Œë§Œ
            
            # ì˜¬ë°”ë¥¸ ì¸ì½”ë”©ìœ¼ë¡œ ì¬í•´ì„
            correct_content = content.encode(wrong).decode(original)
            
            print(f"ğŸ§ª {wrong}â†’{original} í…ŒìŠ¤íŠ¸:")
            print(f"   ì›ë³¸: {content[:100]}...")
            print(f"   ìˆ˜ì •: {correct_content[:100]}...")
            
            # í•œê¸€ í™•ì¸
            quality = detector.check_korean_characters(correct_content)
            print(f"   í’ˆì§ˆ: {quality['quality']} (í•œê¸€: {quality['korean_ratio']:.1%})")
            print()
            
        except Exception as e:
            print(f"âŒ {wrong}â†’{original} ì‹¤íŒ¨: {e}")

# gwashi.csv ë¬¸ì œ í•´ê²° ì‹¤í–‰
fix_gwashi_encoding()