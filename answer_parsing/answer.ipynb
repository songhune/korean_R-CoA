{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8456b63d",
   "metadata": {},
   "source": [
    "# 이 미친 인간들이 과시 데이터를 전부 링크로 퉁치면 어떡해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0b9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1872.0000-20101008.B043a_065_00633_XXX',\n",
    "'https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1872.0000-20101008.B043a_065_00634_XXX',\n",
    "'https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1873.0000-20101008.B047a_071_00188_XXX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8b2eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songhune/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "\n",
    "def fetch_page(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0'\n",
    "    }\n",
    "    try:\n",
    "        res = requests.get(url, headers=headers)\n",
    "        if res.status_code == 200:\n",
    "            return res.text\n",
    "        else:\n",
    "            print(f\"Failed to fetch {url}: {res.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_main_text(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # 페이지 구조에 따라 조정 필요\n",
    "    content = soup.find(\"div\", class_=\"board-view\")  # 예시\n",
    "    return content.get_text(strip=True) if content else None\n",
    "\n",
    "def archive_crawl(url_list, output_dir=\"archive_data\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i, url in enumerate(url_list):\n",
    "        html = fetch_page(url)\n",
    "        if html:\n",
    "            text = extract_main_text(html)\n",
    "            if text:\n",
    "                with open(f\"{output_dir}/doc_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(text)\n",
    "        time.sleep(1.5)  # 서버에 무리 안 가게\n",
    "\n",
    "# 예시\n",
    "archive_crawl(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14002c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ content 하위 div[4] 없음\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 예시 URL (archive.aks.ac.kr의 시권 데이터 중 하나)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0'\n",
    "}\n",
    "\n",
    "res = requests.get(links[0], headers=headers)\n",
    "res.raise_for_status()  # 에러 발생 시 중단\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# id=content 하위 네 번째 div (div[4])\n",
    "content_div = soup.find(id=\"content\")\n",
    "divs = content_div.find_all(\"div\", recursive=False)\n",
    "if len(divs) >= 4:\n",
    "    target_div = divs[3]  # Python index는 0-based, XPath는 1-based\n",
    "\n",
    "    # 세 번째 dl 선택\n",
    "    dls = target_div.find_all(\"dl\", recursive=False)\n",
    "    if len(dls) >= 3:\n",
    "        target_dl = dls[2]\n",
    "\n",
    "        dd = target_dl.find(\"dd\")\n",
    "        if dd:\n",
    "            inner_div = dd.find(\"div\")\n",
    "            if inner_div:\n",
    "                first_content = inner_div.find(\"div\")\n",
    "                if first_content:\n",
    "                    print(\"📄 첫 줄 텍스트:\", first_content.get_text(strip=True).splitlines()[0])\n",
    "                else:\n",
    "                    print(\"❌ <div> 내부 첫 번째 <div> 없음\")\n",
    "            else:\n",
    "                print(\"❌ <dd> 내부 <div> 없음\")\n",
    "        else:\n",
    "            print(\"❌ <dl> 내부 <dd> 없음\")\n",
    "    else:\n",
    "        print(\"❌ dl[3] 없음\")\n",
    "else:\n",
    "    print(\"❌ content 하위 div[4] 없음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf1ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ wrap__text__body--info__text not found (렌더링 안 됨)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(links[0], headers={'User-Agent': 'Mozilla/5.0'})\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# div.wrap__text__body--info__text 요소를 먼저 확인\n",
    "wrapper = soup.select_one('#content > div.wrap__text__body--info__text')\n",
    "if not wrapper:\n",
    "    print(\"❌ wrap__text__body--info__text not found (렌더링 안 됨)\")\n",
    "else:\n",
    "    print(\"✅ wrapper found. Showing child <dl> elements:\")\n",
    "    for i, dl in enumerate(wrapper.find_all(\"dl\")):\n",
    "        print(f\"\\n--- DL #{i+1} ---\")\n",
    "        print(dl.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75b65f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (2025.4.26)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-4.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a8c4f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 본문 추출 결과:\n",
      " 주제\n",
      "晉나라 때의 백성들이 叔子를 더욱 그리워하였다는 내용의 부이다. 叔子는 羊祜의 字인데 훌륭한 인품으로 공적을 세워 명망이 높았던 관리이다. 그리고 자신의 후임으로 杜預라는 훌륭한 장수를 천거하여 아름다운 미담을 남겼다. 부의 대체적인 내용은 다음과 같다. 그대들은 杜預를 좋아하나 나는 양호를 사랑한다. 은택이 지금도 부로들에게 전해지고 있고, 특히 襄陽의 峴山에서 치적이 탁월하여 백성들이 세워 준 비석이 지금도 눈물짓게 한다. 양호는 공적도 훌륭하지만 어진 마음을 중시하여 누구나 흠모하여 감격하였는데, 특히 그의 仁德은 백성을 사랑할 때 더욱 빛났다. 양호는 가벼운 가죽옷으로 검소하게 지내면서 군사들을 잘 먹이니 적들의 마음도 우리에게 쏠렸고, 江水․漢水가 씻어주듯 가르치고 감싸주니 백성들은 남긴 옷을 볼 때마다 양호를 더욱 그리워하였다. 峴山의 정자에 양호와 두예를 기리고 있는데, 그 공적을 말하면 똑같다. 그런데 양양의 부로들이 눈물짓고, 남쪽의 오랑캐가 덕을 칭송하기로는 양호에게서 더욱 간절하다. 문필에도 뛰어났고 강물처럼 은택의 물결이 그침이 없으며 초목에까지 미쳐 지금도 칭송되니, 천년 후에도 영원할 것이다. 이제와 옛날을 회고하면 양호야말로 賢者라 이를 만하다. 이는 뚜렷한 실상이 있었기에 가능한 일이라, 천년 후에 무릎을 치며 성대한 글을 지어 탄식한다.\n",
      "\n",
      "인물\n",
      "李紀元(1830〜?)： 자는 春敷, 호는 省齋이다. 驪州李氏 23세로 求菴公 浚으로부터 10세, 李壽聃으로부터는 6세 후손이다. 成均進士로 文學과 孝友를 겸비하였다. 부인은 仁同 張氏 希旭의 따님이다.羊祜： 晉나라 泰山 南城사람. 자는 叔子, 荊州의 都督이 되었을 때, 학교를 열어 원근의 백성을 진무하여 인심을 크게 얻었다. 襄陽을 다스렸을 때에는 그의 공덕에 감격한 백성들이 峴山에 비석을 건립하였다. 검소하여 늘 가벼운 가죽 갖옷을 입었고, 이후 여러 벼슬을 지내며 공을 세웠으면서도 겸손한 마음을 지녀 내외의 명망이 높았다. 자신의 후임으로 훌륭한 장수인 杜預를 천거하였다.杜預： 晉나라 사람. 자는 元凱, 시호는 成. 吳나라를 평정하는데 큰 공을 세웠다. 말년에는 經籍에 전념하여 『春秋左傳集解』를 지어 후대에 끼친 영향이 매우 크다.\n",
      "\n",
      "특징\n",
      "시권의 앞부분에 ‘五然(?)’이란 글씨가 적혀 있고, 중간 부분에 ‘次上’이란 성적이 朱墨으로 적혀 있다.\n",
      "집필자 : 김채식／작성일：2002-08-16\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# 크롬 옵션 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # 브라우저 창을 띄우지 않음\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# 드라이버 실행\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# 접근할 URL\n",
    "driver.get(links[0])\n",
    "time.sleep(3)  # JavaScript 로딩 대기\n",
    "\n",
    "# 본문 영역 추출 시도\n",
    "try:\n",
    "    element = driver.find_element(By.CSS_SELECTOR, '#content > div.wrap__text__body--info__text > dl:nth-child(3) > dd > div')\n",
    "    print(\"✅ 본문 추출 결과:\\n\", element.text)\n",
    "except Exception as e:\n",
    "    print(\"❌ 요소 추출 실패:\", e)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4607c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] 처리 중: http://www.emuseum.go.kr/detail?relicId=PS0100200100106199100000\n",
      "❌ 오류 발생: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"#content > div.wrap__text__body--info__text > dl:nth-child(3) > dd > div\"}\n",
      "  (Session info: chrome=136.0.7103.114); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001011143e0 cxxbridge1$str$ptr + 2829900\n",
      "1   chromedriver                        0x000000010110c6a8 cxxbridge1$str$ptr + 2797844\n",
      "2   chromedriver                        0x0000000100c49fbc cxxbridge1$string$len + 90140\n",
      "3   chromedriver                        0x0000000100c911bc cxxbridge1$string$len + 381468\n",
      "4   chromedriver                        0x0000000100cd2044 cxxbridge1$string$len + 647332\n",
      "5   chromedriver                        0x0000000100c853f8 cxxbridge1$string$len + 332888\n",
      "6   chromedriver                        0x00000001010d8804 cxxbridge1$str$ptr + 2585200\n",
      "7   chromedriver                        0x00000001010dbad4 cxxbridge1$str$ptr + 2598208\n",
      "8   chromedriver                        0x00000001010b9dd8 cxxbridge1$str$ptr + 2459716\n",
      "9   chromedriver                        0x00000001010dc34c cxxbridge1$str$ptr + 2600376\n",
      "10  chromedriver                        0x00000001010ab664 cxxbridge1$str$ptr + 2400464\n",
      "11  chromedriver                        0x00000001010fc2b0 cxxbridge1$str$ptr + 2731292\n",
      "12  chromedriver                        0x00000001010fc43c cxxbridge1$str$ptr + 2731688\n",
      "13  chromedriver                        0x000000010110c2f4 cxxbridge1$str$ptr + 2796896\n",
      "14  libsystem_pthread.dylib             0x000000019b436c0c _pthread_start + 136\n",
      "15  libsystem_pthread.dylib             0x000000019b431b80 thread_start + 8\n",
      "\n",
      "[2/5] 처리 중: nan\n",
      "[3/5] 처리 중: https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1555.0000-20101008.B001a_001_00140_XXX\n",
      "❌ 오류 발생: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"#content > div.wrap__text__body--info__text > dl:nth-child(3) > dd > div\"}\n",
      "  (Session info: chrome=136.0.7103.114); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001011143e0 cxxbridge1$str$ptr + 2829900\n",
      "1   chromedriver                        0x000000010110c6a8 cxxbridge1$str$ptr + 2797844\n",
      "2   chromedriver                        0x0000000100c49fbc cxxbridge1$string$len + 90140\n",
      "3   chromedriver                        0x0000000100c911bc cxxbridge1$string$len + 381468\n",
      "4   chromedriver                        0x0000000100cd2044 cxxbridge1$string$len + 647332\n",
      "5   chromedriver                        0x0000000100c853f8 cxxbridge1$string$len + 332888\n",
      "6   chromedriver                        0x00000001010d8804 cxxbridge1$str$ptr + 2585200\n",
      "7   chromedriver                        0x00000001010dbad4 cxxbridge1$str$ptr + 2598208\n",
      "8   chromedriver                        0x00000001010b9dd8 cxxbridge1$str$ptr + 2459716\n",
      "9   chromedriver                        0x00000001010dc34c cxxbridge1$str$ptr + 2600376\n",
      "10  chromedriver                        0x00000001010ab664 cxxbridge1$str$ptr + 2400464\n",
      "11  chromedriver                        0x00000001010fc2b0 cxxbridge1$str$ptr + 2731292\n",
      "12  chromedriver                        0x00000001010fc43c cxxbridge1$str$ptr + 2731688\n",
      "13  chromedriver                        0x000000010110c2f4 cxxbridge1$str$ptr + 2796896\n",
      "14  libsystem_pthread.dylib             0x000000019b436c0c _pthread_start + 136\n",
      "15  libsystem_pthread.dylib             0x000000019b431b80 thread_start + 8\n",
      "\n",
      "[4/5] 처리 중: https://archive.aks.ac.kr/link.do?dataUCI=G002+AKS+KSM-XD.1555.1111-20101008.B001a_001_00143_XXX\n",
      "[5/5] 처리 중: https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1561.0000-20101008.B028a_043_00397_XXX\n",
      "\n",
      "✅ 모든 추출 완료! 결과 저장: 시권_본문_추출결과.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# CSV 불러오기\n",
    "df = pd.read_csv(\"./temp.csv\")\n",
    "\n",
    "# Selenium 드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# 본문을 저장할 리스트\n",
    "extracted_texts = []\n",
    "\n",
    "for i, url in enumerate(df['webResourceURL']):\n",
    "    print(f\"[{i+1}/{len(df)}] 처리 중: {url}\")\n",
    "    if pd.isna(url) or not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "        extracted_texts.append(\"\")  # URL이 없으면 빈칸 처리\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # 페이지 로딩 대기 (필요시 늘릴 수 있음)\n",
    "        element = driver.find_element(By.CSS_SELECTOR, '#content > div.wrap__text__body--info__text > dl:nth-child(3) > dd > div')\n",
    "        extracted_texts.append(element.text.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "        extracted_texts.append(\"\")\n",
    "\n",
    "# 크롬 종료\n",
    "driver.quit()\n",
    "\n",
    "# 본문 컬럼 추가\n",
    "df['본문'] = extracted_texts\n",
    "\n",
    "# 결과 저장\n",
    "output_path = \"시권_본문_추출결과.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n✅ 모든 추출 완료! 결과 저장: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de6ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
