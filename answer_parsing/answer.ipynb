{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8456b63d",
   "metadata": {},
   "source": [
    "# ì´ ë¯¸ì¹œ ì¸ê°„ë“¤ì´ ê³¼ì‹œ ë°ì´í„°ë¥¼ ì „ë¶€ ë§í¬ë¡œ í‰ì¹˜ë©´ ì–´ë–¡í•´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0b9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = ['https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1872.0000-20101008.B043a_065_00633_XXX',\n",
    "'https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1872.0000-20101008.B043a_065_00634_XXX',\n",
    "'https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1873.0000-20101008.B047a_071_00188_XXX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8b2eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songhune/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "\n",
    "def fetch_page(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0'\n",
    "    }\n",
    "    try:\n",
    "        res = requests.get(url, headers=headers)\n",
    "        if res.status_code == 200:\n",
    "            return res.text\n",
    "        else:\n",
    "            print(f\"Failed to fetch {url}: {res.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_main_text(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # í˜ì´ì§€ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”\n",
    "    content = soup.find(\"div\", class_=\"board-view\")  # ì˜ˆì‹œ\n",
    "    return content.get_text(strip=True) if content else None\n",
    "\n",
    "def archive_crawl(url_list, output_dir=\"archive_data\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i, url in enumerate(url_list):\n",
    "        html = fetch_page(url)\n",
    "        if html:\n",
    "            text = extract_main_text(html)\n",
    "            if text:\n",
    "                with open(f\"{output_dir}/doc_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(text)\n",
    "        time.sleep(1.5)  # ì„œë²„ì— ë¬´ë¦¬ ì•ˆ ê°€ê²Œ\n",
    "\n",
    "# ì˜ˆì‹œ\n",
    "archive_crawl(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14002c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ content í•˜ìœ„ div[4] ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ì˜ˆì‹œ URL (archive.aks.ac.krì˜ ì‹œê¶Œ ë°ì´í„° ì¤‘ í•˜ë‚˜)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0'\n",
    "}\n",
    "\n",
    "res = requests.get(links[0], headers=headers)\n",
    "res.raise_for_status()  # ì—ëŸ¬ ë°œìƒ ì‹œ ì¤‘ë‹¨\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# id=content í•˜ìœ„ ë„¤ ë²ˆì§¸ div (div[4])\n",
    "content_div = soup.find(id=\"content\")\n",
    "divs = content_div.find_all(\"div\", recursive=False)\n",
    "if len(divs) >= 4:\n",
    "    target_div = divs[3]  # Python indexëŠ” 0-based, XPathëŠ” 1-based\n",
    "\n",
    "    # ì„¸ ë²ˆì§¸ dl ì„ íƒ\n",
    "    dls = target_div.find_all(\"dl\", recursive=False)\n",
    "    if len(dls) >= 3:\n",
    "        target_dl = dls[2]\n",
    "\n",
    "        dd = target_dl.find(\"dd\")\n",
    "        if dd:\n",
    "            inner_div = dd.find(\"div\")\n",
    "            if inner_div:\n",
    "                first_content = inner_div.find(\"div\")\n",
    "                if first_content:\n",
    "                    print(\"ğŸ“„ ì²« ì¤„ í…ìŠ¤íŠ¸:\", first_content.get_text(strip=True).splitlines()[0])\n",
    "                else:\n",
    "                    print(\"âŒ <div> ë‚´ë¶€ ì²« ë²ˆì§¸ <div> ì—†ìŒ\")\n",
    "            else:\n",
    "                print(\"âŒ <dd> ë‚´ë¶€ <div> ì—†ìŒ\")\n",
    "        else:\n",
    "            print(\"âŒ <dl> ë‚´ë¶€ <dd> ì—†ìŒ\")\n",
    "    else:\n",
    "        print(\"âŒ dl[3] ì—†ìŒ\")\n",
    "else:\n",
    "    print(\"âŒ content í•˜ìœ„ div[4] ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf1ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ wrap__text__body--info__text not found (ë Œë”ë§ ì•ˆ ë¨)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(links[0], headers={'User-Agent': 'Mozilla/5.0'})\n",
    "res.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# div.wrap__text__body--info__text ìš”ì†Œë¥¼ ë¨¼ì € í™•ì¸\n",
    "wrapper = soup.select_one('#content > div.wrap__text__body--info__text')\n",
    "if not wrapper:\n",
    "    print(\"âŒ wrap__text__body--info__text not found (ë Œë”ë§ ì•ˆ ë¨)\")\n",
    "else:\n",
    "    print(\"âœ… wrapper found. Showing child <dl> elements:\")\n",
    "    for i, dl in enumerate(wrapper.find_all(\"dl\")):\n",
    "        print(f\"\\n--- DL #{i+1} ---\")\n",
    "        print(dl.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75b65f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/songhune/Library/Python/3.9/lib/python/site-packages (from requests->webdriver-manager) (2025.4.26)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-4.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a8c4f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³¸ë¬¸ ì¶”ì¶œ ê²°ê³¼:\n",
      " ì£¼ì œ\n",
      "æ™‰ë‚˜ë¼ ë•Œì˜ ë°±ì„±ë“¤ì´ å”å­ë¥¼ ë”ìš± ê·¸ë¦¬ì›Œí•˜ì˜€ë‹¤ëŠ” ë‚´ìš©ì˜ ë¶€ì´ë‹¤. å”å­ëŠ” ç¾Šç¥œì˜ å­—ì¸ë° í›Œë¥­í•œ ì¸í’ˆìœ¼ë¡œ ê³µì ì„ ì„¸ì›Œ ëª…ë§ì´ ë†’ì•˜ë˜ ê´€ë¦¬ì´ë‹¤. ê·¸ë¦¬ê³  ìì‹ ì˜ í›„ì„ìœ¼ë¡œ æœé ë¼ëŠ” í›Œë¥­í•œ ì¥ìˆ˜ë¥¼ ì²œê±°í•˜ì—¬ ì•„ë¦„ë‹¤ìš´ ë¯¸ë‹´ì„ ë‚¨ê²¼ë‹¤. ë¶€ì˜ ëŒ€ì²´ì ì¸ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. ê·¸ëŒ€ë“¤ì€ æœé ë¥¼ ì¢‹ì•„í•˜ë‚˜ ë‚˜ëŠ” ì–‘í˜¸ë¥¼ ì‚¬ë‘í•œë‹¤. ì€íƒì´ ì§€ê¸ˆë„ ë¶€ë¡œë“¤ì—ê²Œ ì „í•´ì§€ê³  ìˆê³ , íŠ¹íˆ è¥„é™½ì˜ å³´å±±ì—ì„œ ì¹˜ì ì´ íƒì›”í•˜ì—¬ ë°±ì„±ë“¤ì´ ì„¸ì›Œ ì¤€ ë¹„ì„ì´ ì§€ê¸ˆë„ ëˆˆë¬¼ì§“ê²Œ í•œë‹¤. ì–‘í˜¸ëŠ” ê³µì ë„ í›Œë¥­í•˜ì§€ë§Œ ì–´ì§„ ë§ˆìŒì„ ì¤‘ì‹œí•˜ì—¬ ëˆ„êµ¬ë‚˜ í ëª¨í•˜ì—¬ ê°ê²©í•˜ì˜€ëŠ”ë°, íŠ¹íˆ ê·¸ì˜ ä»å¾·ì€ ë°±ì„±ì„ ì‚¬ë‘í•  ë•Œ ë”ìš± ë¹›ë‚¬ë‹¤. ì–‘í˜¸ëŠ” ê°€ë²¼ìš´ ê°€ì£½ì˜·ìœ¼ë¡œ ê²€ì†Œí•˜ê²Œ ì§€ë‚´ë©´ì„œ êµ°ì‚¬ë“¤ì„ ì˜ ë¨¹ì´ë‹ˆ ì ë“¤ì˜ ë§ˆìŒë„ ìš°ë¦¬ì—ê²Œ ì ë ¸ê³ , æ±Ÿæ°´â€¤æ¼¢æ°´ê°€ ì”»ì–´ì£¼ë“¯ ê°€ë¥´ì¹˜ê³  ê°ì‹¸ì£¼ë‹ˆ ë°±ì„±ë“¤ì€ ë‚¨ê¸´ ì˜·ì„ ë³¼ ë•Œë§ˆë‹¤ ì–‘í˜¸ë¥¼ ë”ìš± ê·¸ë¦¬ì›Œí•˜ì˜€ë‹¤. å³´å±±ì˜ ì •ìì— ì–‘í˜¸ì™€ ë‘ì˜ˆë¥¼ ê¸°ë¦¬ê³  ìˆëŠ”ë°, ê·¸ ê³µì ì„ ë§í•˜ë©´ ë˜‘ê°™ë‹¤. ê·¸ëŸ°ë° ì–‘ì–‘ì˜ ë¶€ë¡œë“¤ì´ ëˆˆë¬¼ì§“ê³ , ë‚¨ìª½ì˜ ì˜¤ë‘ìºê°€ ë•ì„ ì¹­ì†¡í•˜ê¸°ë¡œëŠ” ì–‘í˜¸ì—ê²Œì„œ ë”ìš± ê°„ì ˆí•˜ë‹¤. ë¬¸í•„ì—ë„ ë›°ì–´ë‚¬ê³  ê°•ë¬¼ì²˜ëŸ¼ ì€íƒì˜ ë¬¼ê²°ì´ ê·¸ì¹¨ì´ ì—†ìœ¼ë©° ì´ˆëª©ì—ê¹Œì§€ ë¯¸ì³ ì§€ê¸ˆë„ ì¹­ì†¡ë˜ë‹ˆ, ì²œë…„ í›„ì—ë„ ì˜ì›í•  ê²ƒì´ë‹¤. ì´ì œì™€ ì˜›ë‚ ì„ íšŒê³ í•˜ë©´ ì–‘í˜¸ì•¼ë§ë¡œ è³¢è€…ë¼ ì´ë¥¼ ë§Œí•˜ë‹¤. ì´ëŠ” ëšœë ·í•œ ì‹¤ìƒì´ ìˆì—ˆê¸°ì— ê°€ëŠ¥í•œ ì¼ì´ë¼, ì²œë…„ í›„ì— ë¬´ë¦ì„ ì¹˜ë©° ì„±ëŒ€í•œ ê¸€ì„ ì§€ì–´ íƒ„ì‹í•œë‹¤.\n",
      "\n",
      "ì¸ë¬¼\n",
      "æç´€å…ƒ(1830ã€œ?)ï¼š ìëŠ” æ˜¥æ•·, í˜¸ëŠ” çœé½‹ì´ë‹¤. é©ªå·ææ° 23ì„¸ë¡œ æ±‚è´å…¬ æµšìœ¼ë¡œë¶€í„° 10ì„¸, æå£½èƒìœ¼ë¡œë¶€í„°ëŠ” 6ì„¸ í›„ì†ì´ë‹¤. æˆå‡é€²å£«ë¡œ æ–‡å­¸ê³¼ å­å‹ë¥¼ ê²¸ë¹„í•˜ì˜€ë‹¤. ë¶€ì¸ì€ ä»åŒ å¼µæ° å¸Œæ—­ì˜ ë”°ë‹˜ì´ë‹¤.ç¾Šç¥œï¼š æ™‰ë‚˜ë¼ æ³°å±± å—åŸì‚¬ëŒ. ìëŠ” å”å­, èŠå·ì˜ éƒ½ç£ì´ ë˜ì—ˆì„ ë•Œ, í•™êµë¥¼ ì—´ì–´ ì›ê·¼ì˜ ë°±ì„±ì„ ì§„ë¬´í•˜ì—¬ ì¸ì‹¬ì„ í¬ê²Œ ì–»ì—ˆë‹¤. è¥„é™½ì„ ë‹¤ìŠ¤ë ¸ì„ ë•Œì—ëŠ” ê·¸ì˜ ê³µë•ì— ê°ê²©í•œ ë°±ì„±ë“¤ì´ å³´å±±ì— ë¹„ì„ì„ ê±´ë¦½í•˜ì˜€ë‹¤. ê²€ì†Œí•˜ì—¬ ëŠ˜ ê°€ë²¼ìš´ ê°€ì£½ ê°–ì˜·ì„ ì…ì—ˆê³ , ì´í›„ ì—¬ëŸ¬ ë²¼ìŠ¬ì„ ì§€ë‚´ë©° ê³µì„ ì„¸ì› ìœ¼ë©´ì„œë„ ê²¸ì†í•œ ë§ˆìŒì„ ì§€ë…€ ë‚´ì™¸ì˜ ëª…ë§ì´ ë†’ì•˜ë‹¤. ìì‹ ì˜ í›„ì„ìœ¼ë¡œ í›Œë¥­í•œ ì¥ìˆ˜ì¸ æœé ë¥¼ ì²œê±°í•˜ì˜€ë‹¤.æœé ï¼š æ™‰ë‚˜ë¼ ì‚¬ëŒ. ìëŠ” å…ƒå‡±, ì‹œí˜¸ëŠ” æˆ. å³ë‚˜ë¼ë¥¼ í‰ì •í•˜ëŠ”ë° í° ê³µì„ ì„¸ì› ë‹¤. ë§ë…„ì—ëŠ” ç¶“ç±ì— ì „ë…í•˜ì—¬ ã€æ˜¥ç§‹å·¦å‚³é›†è§£ã€ë¥¼ ì§€ì–´ í›„ëŒ€ì— ë¼ì¹œ ì˜í–¥ì´ ë§¤ìš° í¬ë‹¤.\n",
      "\n",
      "íŠ¹ì§•\n",
      "ì‹œê¶Œì˜ ì•ë¶€ë¶„ì— â€˜äº”ç„¶(?)â€™ì´ë€ ê¸€ì”¨ê°€ ì í˜€ ìˆê³ , ì¤‘ê°„ ë¶€ë¶„ì— â€˜æ¬¡ä¸Šâ€™ì´ë€ ì„±ì ì´ æœ±å¢¨ìœ¼ë¡œ ì í˜€ ìˆë‹¤.\n",
      "ì§‘í•„ì : ê¹€ì±„ì‹ï¼ì‘ì„±ì¼ï¼š2002-08-16\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# í¬ë¡¬ ì˜µì…˜ ì„¤ì •\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # ë¸Œë¼ìš°ì € ì°½ì„ ë„ìš°ì§€ ì•ŠìŒ\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# ë“œë¼ì´ë²„ ì‹¤í–‰\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# ì ‘ê·¼í•  URL\n",
    "driver.get(links[0])\n",
    "time.sleep(3)  # JavaScript ë¡œë”© ëŒ€ê¸°\n",
    "\n",
    "# ë³¸ë¬¸ ì˜ì—­ ì¶”ì¶œ ì‹œë„\n",
    "try:\n",
    "    element = driver.find_element(By.CSS_SELECTOR, '#content > div.wrap__text__body--info__text > dl:nth-child(3) > dd > div')\n",
    "    print(\"âœ… ë³¸ë¬¸ ì¶”ì¶œ ê²°ê³¼:\\n\", element.text)\n",
    "except Exception as e:\n",
    "    print(\"âŒ ìš”ì†Œ ì¶”ì¶œ ì‹¤íŒ¨:\", e)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4607c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] ì²˜ë¦¬ ì¤‘: http://www.emuseum.go.kr/detail?relicId=PS0100200100106199100000\n",
      "âŒ ì˜¤ë¥˜ ë°œìƒ: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"#content > div.wrap__text__body--info__text > dl:nth-child(3) > dd > div\"}\n",
      "  (Session info: chrome=136.0.7103.114); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001011143e0 cxxbridge1$str$ptr + 2829900\n",
      "1   chromedriver                        0x000000010110c6a8 cxxbridge1$str$ptr + 2797844\n",
      "2   chromedriver                        0x0000000100c49fbc cxxbridge1$string$len + 90140\n",
      "3   chromedriver                        0x0000000100c911bc cxxbridge1$string$len + 381468\n",
      "4   chromedriver                        0x0000000100cd2044 cxxbridge1$string$len + 647332\n",
      "5   chromedriver                        0x0000000100c853f8 cxxbridge1$string$len + 332888\n",
      "6   chromedriver                        0x00000001010d8804 cxxbridge1$str$ptr + 2585200\n",
      "7   chromedriver                        0x00000001010dbad4 cxxbridge1$str$ptr + 2598208\n",
      "8   chromedriver                        0x00000001010b9dd8 cxxbridge1$str$ptr + 2459716\n",
      "9   chromedriver                        0x00000001010dc34c cxxbridge1$str$ptr + 2600376\n",
      "10  chromedriver                        0x00000001010ab664 cxxbridge1$str$ptr + 2400464\n",
      "11  chromedriver                        0x00000001010fc2b0 cxxbridge1$str$ptr + 2731292\n",
      "12  chromedriver                        0x00000001010fc43c cxxbridge1$str$ptr + 2731688\n",
      "13  chromedriver                        0x000000010110c2f4 cxxbridge1$str$ptr + 2796896\n",
      "14  libsystem_pthread.dylib             0x000000019b436c0c _pthread_start + 136\n",
      "15  libsystem_pthread.dylib             0x000000019b431b80 thread_start + 8\n",
      "\n",
      "[2/5] ì²˜ë¦¬ ì¤‘: nan\n",
      "[3/5] ì²˜ë¦¬ ì¤‘: https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1555.0000-20101008.B001a_001_00140_XXX\n",
      "âŒ ì˜¤ë¥˜ ë°œìƒ: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"#content > div.wrap__text__body--info__text > dl:nth-child(3) > dd > div\"}\n",
      "  (Session info: chrome=136.0.7103.114); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001011143e0 cxxbridge1$str$ptr + 2829900\n",
      "1   chromedriver                        0x000000010110c6a8 cxxbridge1$str$ptr + 2797844\n",
      "2   chromedriver                        0x0000000100c49fbc cxxbridge1$string$len + 90140\n",
      "3   chromedriver                        0x0000000100c911bc cxxbridge1$string$len + 381468\n",
      "4   chromedriver                        0x0000000100cd2044 cxxbridge1$string$len + 647332\n",
      "5   chromedriver                        0x0000000100c853f8 cxxbridge1$string$len + 332888\n",
      "6   chromedriver                        0x00000001010d8804 cxxbridge1$str$ptr + 2585200\n",
      "7   chromedriver                        0x00000001010dbad4 cxxbridge1$str$ptr + 2598208\n",
      "8   chromedriver                        0x00000001010b9dd8 cxxbridge1$str$ptr + 2459716\n",
      "9   chromedriver                        0x00000001010dc34c cxxbridge1$str$ptr + 2600376\n",
      "10  chromedriver                        0x00000001010ab664 cxxbridge1$str$ptr + 2400464\n",
      "11  chromedriver                        0x00000001010fc2b0 cxxbridge1$str$ptr + 2731292\n",
      "12  chromedriver                        0x00000001010fc43c cxxbridge1$str$ptr + 2731688\n",
      "13  chromedriver                        0x000000010110c2f4 cxxbridge1$str$ptr + 2796896\n",
      "14  libsystem_pthread.dylib             0x000000019b436c0c _pthread_start + 136\n",
      "15  libsystem_pthread.dylib             0x000000019b431b80 thread_start + 8\n",
      "\n",
      "[4/5] ì²˜ë¦¬ ì¤‘: https://archive.aks.ac.kr/link.do?dataUCI=G002+AKS+KSM-XD.1555.1111-20101008.B001a_001_00143_XXX\n",
      "[5/5] ì²˜ë¦¬ ì¤‘: https://archive.aks.ac.kr/insp/item.do#view.do?itemId=insp&gubun=form&upPath=02%5E0204%5E020451&dataId=G002%2BAKS%2BKSM-XD.1561.0000-20101008.B028a_043_00397_XXX\n",
      "\n",
      "âœ… ëª¨ë“  ì¶”ì¶œ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: ì‹œê¶Œ_ë³¸ë¬¸_ì¶”ì¶œê²°ê³¼.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"./temp.csv\")\n",
    "\n",
    "# Selenium ë“œë¼ì´ë²„ ì„¤ì •\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# ë³¸ë¬¸ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "extracted_texts = []\n",
    "\n",
    "for i, url in enumerate(df['webResourceURL']):\n",
    "    print(f\"[{i+1}/{len(df)}] ì²˜ë¦¬ ì¤‘: {url}\")\n",
    "    if pd.isna(url) or not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "        extracted_texts.append(\"\")  # URLì´ ì—†ìœ¼ë©´ ë¹ˆì¹¸ ì²˜ë¦¬\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° (í•„ìš”ì‹œ ëŠ˜ë¦´ ìˆ˜ ìˆìŒ)\n",
    "        element = driver.find_element(By.CSS_SELECTOR, '#content > div.wrap__text__body--info__text > dl:nth-child(3) > dd > div')\n",
    "        extracted_texts.append(element.text.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        extracted_texts.append(\"\")\n",
    "\n",
    "# í¬ë¡¬ ì¢…ë£Œ\n",
    "driver.quit()\n",
    "\n",
    "# ë³¸ë¬¸ ì»¬ëŸ¼ ì¶”ê°€\n",
    "df['ë³¸ë¬¸'] = extracted_texts\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "output_path = \"ì‹œê¶Œ_ë³¸ë¬¸_ì¶”ì¶œê²°ê³¼.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nâœ… ëª¨ë“  ì¶”ì¶œ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de6ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
