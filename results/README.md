# Results Directory

ëª¨ë“  í‰ê°€ ê²°ê³¼ê°€ ì •ë¦¬ëœ ë””ë ‰í† ë¦¬ì…ë‹ˆë‹¤.

## ğŸ“ Directory Structure

```
results/
â”œâ”€â”€ aggregated/                    # í†µí•©ëœ ê²°ê³¼ (ì£¼ìš” ì‚¬ìš©)
â”‚   â”œâ”€â”€ consolidated_all_results.csv  # ğŸŒŸ ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í†µí•©í•œ ê±°ëŒ€ CSV
â”‚   â”œâ”€â”€ aggregated_summary.csv     # ëª¨ë¸ë³„ ìš”ì•½ í†µê³„
â”‚   â”œâ”€â”€ model_average_performance.csv  # ëª¨ë¸ í‰ê·  ì„±ëŠ¥
â”‚   â””â”€â”€ *.png, *.pdf              # ì‹œê°í™” ê·¸ë˜í”„ë“¤
â”‚
â”œâ”€â”€ confusion_matrices_full/       # Confusion Matrix ê²°ê³¼
â”‚   â”œâ”€â”€ confusion_matrix_*.png    # ê° ëª¨ë¸ë³„ confusion matrix
â”‚   â”œâ”€â”€ *_report.txt              # ë¶„ë¥˜ ì„±ëŠ¥ ë¦¬í¬íŠ¸
â”‚   â””â”€â”€ confusion_matrix_AVERAGE_all_models.png  # í‰ê·  confusion matrix
â”‚
â”œâ”€â”€ full_predictions/              # ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼
â”‚   â””â”€â”€ full_predictions_*.json   # ê° ëª¨ë¸ì˜ ì „ì²´ ì˜ˆì¸¡ê°’
â”‚
â”œâ”€â”€ temperature_ablation/          # Temperature ì‹¤í—˜ ê²°ê³¼
â”‚   â”œâ”€â”€ results_*_temp*.json      # ê° temperatureë³„ ê²°ê³¼
â”‚   â””â”€â”€ summary_*_temp*.csv       # Temperatureë³„ ìš”ì•½
â”‚
â””â”€â”€ legacy/                        # êµ¬ë²„ì „ ê²°ê³¼ (ì°¸ê³ ìš©)
    â”œâ”€â”€ confusion_matrices/       # êµ¬ë²„ì „ confusion matrix
    â”œâ”€â”€ data_processing/          # ë°ì´í„° ì²˜ë¦¬ ì¤‘ê°„ ê²°ê³¼
    â”œâ”€â”€ fewshot/                  # Few-shot ì‹¤í—˜ ê²°ê³¼
    â”œâ”€â”€ figures/                  # êµ¬ë²„ì „ ê·¸ë˜í”„ë“¤
    â”œâ”€â”€ raw_evaluation/           # ì›ë³¸ í‰ê°€ ê²°ê³¼
    â”œâ”€â”€ tables/                   # êµ¬ë²„ì „ í…Œì´ë¸”ë“¤
    â””â”€â”€ temperature_ablation_old/ # êµ¬ë²„ì „ temperature ì‹¤í—˜
```

## ğŸŒŸ Main Files

### 1. **consolidated_all_results.csv** (ê°€ì¥ ì¤‘ìš”!)
- **ìœ„ì¹˜**: `aggregated/consolidated_all_results.csv`
- **ë‚´ìš©**: ëª¨ë“  í‰ê°€ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ CSVë¡œ í†µí•©
- **ì»¬ëŸ¼**:
  - `source`: ê²°ê³¼ ì¶œì²˜ (temperature_ablation, full_predictions, confusion_matrix)
  - `model_name`: ëª¨ë¸ ì´ë¦„
  - `temperature`: Temperature ê°’ (0.0, 0.3, 0.7)
  - `task`: íƒœìŠ¤í¬ ì´ë¦„ (classification, retrieval, punctuation, nli, translation)
  - `timestamp`: ì‹¤í–‰ ì‹œê°
  - `num_samples`: ìƒ˜í”Œ ìˆ˜
  - `metric_*`: ê°ì¢… í‰ê°€ ì§€í‘œ (accuracy, precision, recall, f1, bleu, rouge ë“±)

### 2. **Confusion Matrix ê²°ê³¼**
- **ìœ„ì¹˜**: `confusion_matrices_full/`
- **íŒŒì¼**:
  - `confusion_matrix_*.png`: ì‹œê°í™”ëœ confusion matrix
  - `*_report.txt`: ìƒì„¸ ë¶„ë¥˜ ì„±ëŠ¥ ë¦¬í¬íŠ¸
  - `comparison_report.txt`: ëª¨ë¸ ê°„ ë¹„êµ
  - `confusion_matrix_AVERAGE_all_models.png`: í‰ê·  confusion matrix

### 3. **Full Predictions**
- **ìœ„ì¹˜**: `full_predictions/`
- **ë‚´ìš©**: ê° ëª¨ë¸ì˜ ì „ì²´ ì˜ˆì¸¡ê°’ (808ê°œ ìƒ˜í”Œ)
- **ëª¨ë¸**: GPT-4-Turbo, GPT-3.5-Turbo, Claude 3 Opus, Claude 3 Haiku, Qwen 2.5 7B, Llama 3.1 8B, EXAONE 3.0 7.8B

## ğŸ“Š Data Summary

### Evaluated Models (7)
1. GPT-4-Turbo
2. GPT-3.5-Turbo
3. Claude 3 Opus
4. Claude 3 Haiku
5. Qwen 2.5 7B Instruct
6. Llama 3.1 8B Instruct
7. EXAONE 3.0 7.8B Instruct

### Tasks (5)
1. **Classification**: ê³ ì „ ë¬¸í—Œ ë¬¸ì²´ ë¶„ë¥˜ (ê³¼ë¬¸ìœ¡ì²´ 6ê°œ í´ë˜ìŠ¤)
2. **Retrieval**: ë¬¸í—Œ ê²€ìƒ‰ ë° ë§¤ì¹­
3. **Punctuation**: êµ¬ë‘ì  ë³µì›
4. **NLI**: ìì—°ì–´ ì¶”ë¡ 
5. **Translation**: í•œë¬¸-í•œê¸€ ë²ˆì—­

### Temperature Values
- 0.0 (deterministic)
- 0.3 (balanced)
- 0.7 (creative)

## ğŸ“ Usage

### Pythonì—ì„œ í†µí•© ê²°ê³¼ ë¡œë“œí•˜ê¸°

```python
import pandas as pd

# ëª¨ë“  ê²°ê³¼ ë¡œë“œ
df = pd.read_csv('results/aggregated/consolidated_all_results.csv')

# Classification íƒœìŠ¤í¬ë§Œ í•„í„°ë§
classification_df = df[df['task'] == 'classification']

# Temperature 0.0 ê²°ê³¼ë§Œ í•„í„°ë§
temp0_df = df[df['temperature'] == 0.0]

# íŠ¹ì • ëª¨ë¸ì˜ ê²°ê³¼ ë³´ê¸°
gpt4_df = df[df['model_name'].str.contains('gpt-4', case=False)]
```

### í‰ê°€ ì§€í‘œ í™•ì¸í•˜ê¸°

```python
# Classification ì •í™•ë„
print(df[df['task'] == 'classification']['metric_accuracy'].describe())

# Translation BLEU ì ìˆ˜
print(df[df['task'] == 'translation']['metric_bleu'].describe())

# ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥
model_avg = df.groupby('model_name')['metric_accuracy'].mean()
print(model_avg.sort_values(ascending=False))
```

## ğŸ—‚ï¸ Legacy Files

`legacy/` í´ë”ì—ëŠ” ì´ì „ ë²„ì „ì˜ ê²°ê³¼ì™€ ì¤‘ê°„ ì²˜ë¦¬ íŒŒì¼ë“¤ì´ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
- ë°ì´í„° ì²˜ë¦¬ ì¤‘ê°„ ë‹¨ê³„
- êµ¬ë²„ì „ confusion matrix
- Few-shot ì‹¤í—˜ ê²°ê³¼
- êµ¬ë²„ì „ ê·¸ë˜í”„ ë° í…Œì´ë¸”

**ì£¼ì˜**: Legacy íŒŒì¼ë“¤ì€ ì°¸ê³ ìš©ì´ë©°, ìµœì‹  ë¶„ì„ì—ëŠ” `aggregated/` í´ë”ì˜ íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.

## ğŸ“… Last Updated

- Consolidated results: 2024-11-14
- Temperature ablation: 2024-11-13
- Full predictions: 2024-11-14
- Confusion matrices: 2024-11-14

## ğŸ”— Related Scripts

- `/experiments/exp5/consolidate_all_results.py`: ê²°ê³¼ í†µí•© ìŠ¤í¬ë¦½íŠ¸
- `/experiments/exp5/generate_classification_confusion_matrix.py`: Confusion matrix ìƒì„±
- `/experiments/exp5/exp5_benchmark_evaluation.py`: ë²¤ì¹˜ë§ˆí¬ í‰ê°€

---

**Note**: 10ì›”ì— ìƒì„±ëœ êµ¬ë²„ì „ íŒŒì¼ë“¤ì€ ëª¨ë‘ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì‹  ê²°ê³¼ë§Œ ìœ ì§€ë©ë‹ˆë‹¤.
