{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d404716",
   "metadata": {},
   "source": [
    "# WPC ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b391a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. ì—‘ì…€ íŒŒì¼ ê²½ë¡œ\n",
    "file_path = \".xlsx\"  # í•„ìš”ì‹œ ê²½ë¡œ ìˆ˜ì •\n",
    "\n",
    "# 2. ì‹œíŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_work = pd.read_excel(file_path, sheet_name=\"Work\")\n",
    "df_pub = pd.read_excel(file_path, sheet_name=\"Publication\")\n",
    "df_col = pd.read_excel(file_path, sheet_name=\"Collection\")\n",
    "df_edge_pub_w = pd.read_excel(file_path, sheet_name=\"Edge_(Pub-W)\")\n",
    "df_edge_pub_c = pd.read_excel(file_path, sheet_name=\"Edge_(Pub-C)\")\n",
    "\n",
    "# 3. ë³‘í•©ìš© ì›ë³¸ ID ë³´ì¡´\n",
    "df_work[\"work_id_orig\"] = df_work[\"id\"]\n",
    "df_pub[\"pub_id_orig\"] = df_pub[\"id\"]\n",
    "df_col[\"col_id_orig\"] = df_col[\"id\"]\n",
    "\n",
    "# 4. ì»¬ëŸ¼ prefix ë¶€ì—¬\n",
    "df_work_prefixed = df_work.rename(columns=lambda x: f\"work_{x}\" if x != \"work_id_orig\" else x)\n",
    "df_pub_prefixed = df_pub.rename(columns=lambda x: f\"pub_{x}\" if x != \"pub_id_orig\" else x)\n",
    "df_col_prefixed = df_col.rename(columns=lambda x: f\"col_{x}\" if x != \"col_id_orig\" else x)\n",
    "\n",
    "# 5. ì—£ì§€ ë³‘í•©\n",
    "edge_pub_w = df_edge_pub_w.rename(columns={\"source id\": \"pub_id\", \"target id\": \"work_id\"})\n",
    "edge_pub_c = df_edge_pub_c.rename(columns={\"source id\": \"pub_id\", \"target id\": \"col_id\"})\n",
    "pub_core = pd.merge(edge_pub_c, edge_pub_w, on=\"pub_id\", how=\"outer\")\n",
    "\n",
    "# 6. ì •ë³´ ë³‘í•© (ID ê¸°ì¤€, prefix ì´ì „ ID ì‚¬ìš©)\n",
    "pub_core = pub_core.merge(df_pub_prefixed, left_on=\"pub_id\", right_on=\"pub_id_orig\", how=\"left\")\n",
    "pub_core = pub_core.merge(df_work_prefixed, left_on=\"work_id\", right_on=\"work_id_orig\", how=\"left\")\n",
    "pub_core = pub_core.merge(df_col_prefixed, left_on=\"col_id\", right_on=\"col_id_orig\", how=\"left\")\n",
    "\n",
    "# 7. ì—°ê²°ëœ ID ëª©ë¡ ì¶”ì¶œ\n",
    "linked_work_ids = pub_core['work_id_x'].dropna().unique().tolist()\n",
    "linked_pub_ids = pub_core['pub_id_x'].dropna().unique().tolist()\n",
    "linked_col_ids = pub_core['col_id_x'].dropna().unique().tolist()\n",
    "# 8. ë‹¨ë… í•­ëª© ì¶”ì¶œ\n",
    "solo_work = df_work_prefixed[~df_work_prefixed['work_id_orig'].isin(linked_work_ids)].copy()\n",
    "solo_pub = df_pub_prefixed[~df_pub_prefixed['pub_id_orig'].isin(linked_pub_ids)].copy()\n",
    "solo_col = df_col_prefixed[~df_col_prefixed['col_id_orig'].isin(linked_col_ids)].copy()\n",
    "\n",
    "# 9. ìµœì¢… ì¶œë ¥ ì»¬ëŸ¼ ì •ì˜\n",
    "final_columns = [\n",
    "    'col_id_orig', 'col_name',\n",
    "    'pub_id_orig', 'pub_name',\n",
    "    'work_id_orig', 'work_korname', 'work_chiname',\n",
    "    'work_titleExam', 'work_style', 'work_original', 'work_translation', 'work_url'\n",
    "]\n",
    "\n",
    "# 10. ëˆ„ë½ ì»¬ëŸ¼ ë³´ì™„ ë° ì •ë ¬\n",
    "for df in [solo_work, solo_pub, solo_col]:\n",
    "    for col in final_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    df = df[final_columns]\n",
    "\n",
    "pub_core_final = pub_core[final_columns]\n",
    "\n",
    "# 11. ì „ì²´ ë³‘í•©\n",
    "full_merged = pd.concat([pub_core_final, solo_work, solo_pub, solo_col], ignore_index=True)\n",
    "\n",
    "# 12. ì €ì¥\n",
    "full_merged.to_csv(\"full_merged_with_prefix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e773c9b9",
   "metadata": {},
   "source": [
    "## EPQAìƒì„±\n",
    "### 1. P-Aê²°í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfa105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === ê²½ë¡œ ì„¤ì • ===\n",
    "epqa_path = \"EPQA.xlsx\"\n",
    "\n",
    "# === ì‹œíŠ¸ ë¡œë“œ (ì»¬ëŸ¼ëª… ì •ì • ë°˜ì˜)\n",
    "df_person = pd.read_excel(epqa_path, sheet_name=\"Person\").rename(columns={\"id\": \"person_id\"})\n",
    "df_answer = pd.read_excel(epqa_path, sheet_name=\"Answer\").rename(columns={\"id\": \"answer_id\"})  # writerëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "df_edge_pea = pd.read_excel(epqa_path, sheet_name=\"Edge_(Pe-A)\").rename(\n",
    "    columns={\"source id\": \"person_id\", \"target id\": \"answer_id\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "# === Step 1: PA ë³‘í•© (ë‹¨ë… A, P í¬í•¨)\n",
    "# answer ê¸°ì¤€ ë³‘í•©\n",
    "df_pa_left = df_answer.merge(df_edge_pea, on=\"answer_id\", how=\"left\") \\\n",
    "                      .merge(df_person, on=\"person_id\", how=\"left\")\n",
    "\n",
    "# person ê¸°ì¤€ ë³‘í•©\n",
    "df_pa_right = df_person.merge(df_edge_pea, on=\"person_id\", how=\"left\") \\\n",
    "                       .merge(df_answer, on=\"answer_id\", how=\"left\")\n",
    "\n",
    "# ë³‘í•© ê²°ê³¼ í†µí•© + ì¤‘ë³µ ì œê±°\n",
    "df_pa_all = pd.concat([df_pa_left, df_pa_right], ignore_index=True).drop_duplicates(subset=[\"person_id\", \"answer_id\"])\n",
    "\n",
    "# === ì‘ì„±ì ì¼ì¹˜ ì—¬ë¶€ í”Œë˜ê·¸ ì¶”ê°€ (writer vs fullname)\n",
    "def check_writer_match(row):\n",
    "    try:\n",
    "        return pd.notna(row[\"writer\"]) and pd.notna(row[\"fullname\"]) and row[\"writer\"].strip() in row[\"fullname\"]\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df_pa_all[\"is_writer_match\"] = df_pa_all.apply(check_writer_match, axis=1)\n",
    "\n",
    "# === ì €ì¥: ì „ì²´, ì¼ì¹˜, ë¶ˆì¼ì¹˜ ì‹œíŠ¸ ë¶„ë¦¬\n",
    "with pd.ExcelWriter(\"step1_PA_flagged.xlsx\") as writer:\n",
    "    df_pa_all.to_excel(writer, index=False, sheet_name=\"PA_ALL\")\n",
    "    df_pa_all[df_pa_all[\"is_writer_match\"] == True].to_excel(writer, index=False, sheet_name=\"PA_Match\")\n",
    "    df_pa_all[df_pa_all[\"is_writer_match\"] == False].to_excel(writer, index=False, sheet_name=\"PA_Mismatch\")\n",
    "\n",
    "print(\"âœ… Step 1 (PA) ì €ì¥ ì™„ë£Œ: ì „ì²´ {}, ì¼ì¹˜ {}, ë¶ˆì¼ì¹˜ {}\".format(\n",
    "    len(df_pa_all),\n",
    "    df_pa_all[\"is_writer_match\"].sum(),\n",
    "    len(df_pa_all) - df_pa_all[\"is_writer_match\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0776b",
   "metadata": {},
   "source": [
    "### 2. (P-A)Qê²°í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05eaf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì™„ë£Œ: ì „ì²´ 498, A-Q ì—°ê²° ìˆ˜ (edge_hit2=True): 346\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. íŒŒì¼ ê²½ë¡œ\n",
    "pea_path = \"EPQA_PeA_with_edge_hit.xlsx\"\n",
    "epqa2_path = \"EPQA2.xlsx\"\n",
    "\n",
    "# === 2. Pe-A ê²°í•© ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸° (edge_hit1 í¬í•¨)\n",
    "df_pea = pd.read_excel(pea_path)\n",
    "df_pea = df_pea.rename(columns={\"edge_hit\": \"edge_hit1\"})\n",
    "\n",
    "# === 3. A-Q ì—£ì§€ ë° ì§ˆë¬¸ ì‹œíŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° (name ê¸°ì¤€)\n",
    "df_edge_aq = pd.read_excel(epqa2_path, sheet_name=\"Edge_(A-Q)\").rename(\n",
    "    columns={\"source name\": \"answer_name\", \"target name\": \"question_name\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "df_question = pd.read_excel(epqa2_path, sheet_name=\"Question\").rename(\n",
    "    columns={\"name\": \"question_name\", \"id\": \"question_id\"}\n",
    ")\n",
    "\n",
    "# === 4. ë³‘í•©: A-Q ì—°ê²° ì •ë³´ ë¶™ì´ê¸°\n",
    "df_paq = df_pea.merge(df_edge_aq, how=\"left\", on=\"answer_name\") \\\n",
    "               .merge(df_question, how=\"left\", on=\"question_name\")\n",
    "\n",
    "# === 5. edge_hit2 ì¶”ê°€: ì •ë°€ ë§¤ì¹­ ì—¬ë¶€ íŒë‹¨\n",
    "df_edge_aq[\"key\"] = df_edge_aq[\"answer_name\"].astype(str) + \"|\" + df_edge_aq[\"question_name\"].astype(str)\n",
    "df_paq[\"key\"] = df_paq[\"answer_name\"].astype(str) + \"|\" + df_paq[\"question_name\"].astype(str)\n",
    "df_paq[\"edge_hit2\"] = df_paq[\"key\"].isin(df_edge_aq[\"key\"])\n",
    "df_paq = df_paq.drop(columns=[\"key\"])\n",
    "\n",
    "# === 6. ì €ì¥\n",
    "df_paq.to_excel(\"step2_PeAQ_with_edge_hit2.xlsx\", index=False)\n",
    "\n",
    "print(\"âœ… ì™„ë£Œ: ì „ì²´ {}, A-Q ì—°ê²° ìˆ˜ (edge_hit2=True): {}\".format(\n",
    "    len(df_paq),\n",
    "    df_paq[\"edge_hit2\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c275b09",
   "metadata": {},
   "source": [
    "### 3. (P-A-Q)E ê²°í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22897f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì™„ë£Œ: ì „ì²´ 1734, Q-E ì—°ê²° ìˆ˜ (edge_hit3=True): 1428\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. ê²½ë¡œ ì„¤ì •\n",
    "step2_path = \"step2_PeAQ_with_edge_hit2.xlsx\"\n",
    "epqa2_path = \"EPQA2.xlsx\"\n",
    "\n",
    "# === 2. ì´ì „ ë³‘í•© íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (edge_hit1, edge_hit2 í¬í•¨)\n",
    "df_paq = pd.read_excel(step2_path)\n",
    "\n",
    "# === 3. Q-E ì—£ì§€ ë° Exam ì‹œíŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_edge_qe = pd.read_excel(epqa2_path, sheet_name=\"Edge_(Q-E)\").rename(\n",
    "    columns={\"source name\": \"question_name\", \"target name\": \"exam_name\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "df_exam = pd.read_excel(epqa2_path, sheet_name=\"Exam\").rename(\n",
    "    columns={\"name\": \"exam_name\", \"id\": \"exam_id\"}\n",
    ")\n",
    "\n",
    "# === 4. ë³‘í•©: Q-E ì—°ê²° ë° Exam ì •ë³´\n",
    "df_paqe = df_paq.merge(df_edge_qe, how=\"left\", on=\"question_name\") \\\n",
    "                .merge(df_exam, how=\"left\", on=\"exam_name\")\n",
    "\n",
    "# === 5. edge_hit3 ê³„ì‚° (ì •í™•íˆ ì—°ê²°ëœ Q-E ìŒì— ëŒ€í•´ì„œ)\n",
    "df_edge_qe[\"key\"] = df_edge_qe[\"question_name\"].astype(str) + \"|\" + df_edge_qe[\"exam_name\"].astype(str)\n",
    "df_paqe[\"key\"] = df_paqe[\"question_name\"].astype(str) + \"|\" + df_paqe[\"exam_name\"].astype(str)\n",
    "df_paqe[\"edge_hit3\"] = df_paqe[\"key\"].isin(df_edge_qe[\"key\"])\n",
    "df_paqe = df_paqe.drop(columns=[\"key\"])\n",
    "\n",
    "# === 6. ì €ì¥\n",
    "df_paqe.to_excel(\"step3_PeAQE_with_edge_hit3.xlsx\", index=False)\n",
    "\n",
    "print(\"âœ… ì™„ë£Œ: ì „ì²´ {}, Q-E ì—°ê²° ìˆ˜ (edge_hit3=True): {}\".format(\n",
    "    len(df_paqe),\n",
    "    df_paqe[\"edge_hit3\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bed1be",
   "metadata": {},
   "source": [
    "### 4. CPW-EPQA ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be3ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… df_peaqe loaded. Columns: ['person_name', 'person_fullname', 'person_korname', 'person_chiname', 'person_middleName', 'person_courtesyName', 'person_alias', 'person_birthYear', 'person_deathYear', 'person_origin', 'person_clan', 'person_residence', 'answer_name', 'answer_writer', 'answer_year', 'answer_sort', 'answer_contents', 'edge_hit1', 'source id_x', 'target id_x', 'question_name', 'question_id', 'category', 'category2', 'abstract', 'contents', 'source', 'source URL', 'edge_hit2', 'source id_y', 'target id_y', 'exam_name', 'exam_id', 'sortA', 'sortB', 'sortC', 'sortD', 'sortE', 'ì •ë³´ ì¶œì²˜', 'year', 'edge_hit3']\n",
      "âœ… df_edge_aw loaded. Columns: ['answer_id', 'answer_name', 'work_id', 'work_name']\n",
      "âœ… df_work loaded. Columns: ['col_id_orig', 'col_name', 'pub_id_orig', 'pub_name', 'work_id', 'work_korname', 'work_chiname', 'work_titleExam', 'work_style', 'work_original', 'work_translation', 'work_url', 'work_id', 'pub_id', 'pub_period', 'pub_type', 'pub_institution', 'pub_provider', 'col_id', 'col_korname', 'col_chiname', 'col_author', 'col_type']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === íŒŒì¼ ê²½ë¡œ\n",
    "step3_path = \"step3_PeAQE_with_edge_hit3.xlsx\"\n",
    "cpw_path = \"CPW.xlsx\"\n",
    "\n",
    "# === 1. step3 íŒŒì¼ ë¡œë“œ\n",
    "df_peaqe = pd.read_excel(step3_path, sheet_name=0)\n",
    "print(\"âœ… df_peaqe loaded. Columns:\", df_peaqe.columns.tolist())\n",
    "\n",
    "# === 2. A-W ì—£ì§€ ì‹œíŠ¸ ë¡œë“œ\n",
    "df_edge_aw = pd.read_excel(cpw_path, sheet_name=\"Edge_(A-W)\").rename(\n",
    "    columns={\n",
    "        \"source id\": \"answer_id\", \n",
    "        \"source name\": \"answer_name\", \n",
    "        \"target id\": \"work_id\", \n",
    "        \"target name\": \"work_name\"\n",
    "    }\n",
    ").dropna().drop_duplicates()\n",
    "print(\"âœ… df_edge_aw loaded. Columns:\", df_edge_aw.columns.tolist())\n",
    "\n",
    "# === 3. Work ì‹œíŠ¸ ë¡œë“œ\n",
    "df_work = pd.read_excel(cpw_path, sheet_name=\"Sheet2\").rename(\n",
    "    columns={\"work_id_orig\": \"work_id\"}\n",
    ")\n",
    "print(\"âœ… df_work loaded. Columns:\", df_work.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87959810",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\n# === íŒŒì¼ ë¡œë“œ\nstep3_path = \"step3_PeAQE_with_edge_hit3.xlsx\"\ncpw_path = \"CPW.xlsx\"\n\ndf_peaqe = pd.read_excel(step3_path, sheet_name=\"Sheet1\")\ndf_edge_aw = pd.read_excel(cpw_path, sheet_name=\"Edge_(A-W)\").rename(\n    columns={\"source id\": \"answer_id\", \"source name\": \"answer_name\", \"target id\": \"work_id\"}\n)\ndf_work_raw = pd.read_excel(cpw_path, sheet_name=\"Sheet2\")\n\n# work ë°ì´í„° ì •ë¦¬\nif \"work_id\" not in df_work_raw.columns:\n    df_work_raw = df_work_raw.rename(columns={\"work_id_orig\": \"work_id\"})\ndf_work = df_work_raw.loc[:, ~df_work_raw.columns.duplicated()].copy()\ndf_work = df_work.drop_duplicates(subset=[\"work_id\"], keep=\"first\")\n\n# ë³‘í•© í‚¤ ìƒì„±\ndf_peaqe[\"answer_id\"] = df_peaqe[\"source id_x\"]\ndf_peaqe[\"merge_key\"] = df_peaqe[\"answer_id\"].astype(str) + \"|\" + df_peaqe[\"answer_name\"].astype(str)\ndf_edge_aw[\"merge_key\"] = df_edge_aw[\"answer_id\"].astype(str) + \"|\" + df_edge_aw[\"answer_name\"].astype(str)\n\nprint(f\"Edge_(A-W) ê°œìˆ˜: {len(df_edge_aw)}ê°œ\")\nprint(f\"step3 ê°œìˆ˜: {len(df_peaqe)}ê°œ\")\n\n# === íŒŒì¼ 1: Edge ê¸°ì¤€ìœ¼ë¡œ ë§¤í•‘ (ì •í™•íˆ 291ê°œ)\n# Edge ê° í–‰ì— ëŒ€í•´ step3 ì •ë³´ ì¶”ê°€ (left join)\nmapped_from_edge = df_edge_aw.merge(df_peaqe, how=\"left\", on=\"merge_key\")\n# work ì •ë³´ ì¶”ê°€\nmapped_complete = mapped_from_edge.merge(df_work, how=\"left\", on=\"work_id\")\nmapped_complete[\"edge_hit4\"] = True\n\nprint(f\"ë§¤í•‘ íŒŒì¼: {len(mapped_complete)}ê°œ (Edgeì™€ ë™ì¼í•´ì•¼ í•¨)\")\n\n# === íŒŒì¼ 2: step3ì—ë§Œ ìˆê³  Edgeì— ì—†ëŠ” ë°ì´í„°\nstep3_only = df_peaqe[~df_peaqe[\"merge_key\"].isin(df_edge_aw[\"merge_key\"])]\nprint(f\"step3 ë‹¨ë…: {len(step3_only)}ê°œ\")\n\n# === íŒŒì¼ 3: CPW workì—ë§Œ ìˆê³  Edgeì— ì—°ê²°ì•ˆëœ ë°ì´í„°\nconnected_work_ids = df_edge_aw[\"work_id\"].unique()\ncpw_work_only = df_work[~df_work[\"work_id\"].isin(connected_work_ids)]\nprint(f\"CPW work ë‹¨ë…: {len(cpw_work_only)}ê°œ\")\n\n# ì €ì¥\nmapped_complete.to_excel(\"mapped_edge_291.xlsx\", index=False)\nstep3_only.to_excel(\"step3_only_unmapped.xlsx\", index=False)\ncpw_work_only.to_excel(\"cpw_work_only_unmapped.xlsx\", index=False)\n\nprint(f\"\\nâœ… 3ê°œ íŒŒì¼ ì €ì¥:\")\nprint(f\"1. mapped_edge_291.xlsx: {len(mapped_complete)}ê°œ (Edge ê¸°ì¤€ ë§¤í•‘)\")\nprint(f\"2. step3_only_unmapped.xlsx: {len(step3_only)}ê°œ (step3 ë‹¨ë…)\")\nprint(f\"3. cpw_work_only_unmapped.xlsx: {len(cpw_work_only)}ê°œ (CPW work ë‹¨ë…)\")\nprint(f\"ğŸ“Š ì´í•©: {len(mapped_complete) + len(step3_only) + len(cpw_work_only)}ê°œ\")\n\n# ê²€ì¦\nprint(f\"\\nğŸ” ê²€ì¦:\")\nprint(f\"Edge_(A-W) ì›ë³¸: {len(df_edge_aw)}ê°œ\")\nprint(f\"ë§¤í•‘ íŒŒì¼: {len(mapped_complete)}ê°œ\") \nprint(f\"ì¼ì¹˜ ì—¬ë¶€: {'âœ… ì™„ë²½!' if len(mapped_complete) == len(df_edge_aw) else 'âŒ'}\")\n\n# step3 ì •ë³´ê°€ ìˆëŠ” í–‰ê³¼ ì—†ëŠ” í–‰ í™•ì¸\nstep3_matched = mapped_complete[mapped_complete['person_name'].notna()]\nstep3_unmatched = mapped_complete[mapped_complete['person_name'].isna()]\nprint(f\"ë§¤í•‘íŒŒì¼ ì¤‘ step3 ì •ë³´ ìˆìŒ: {len(step3_matched)}ê°œ\")\nprint(f\"ë§¤í•‘íŒŒì¼ ì¤‘ step3 ì •ë³´ ì—†ìŒ: {len(step3_unmatched)}ê°œ\")"
  },
  {
   "cell_type": "markdown",
   "id": "40aff934",
   "metadata": {},
   "source": [
    "## flat ì—´ í•¸ë“œí¬ë˜í”„íŠ¸ë¡œ ì •ë¦¬, ë³µë¶™ì—´ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22484176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ì—‘ì…€ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_excel('EPQA_flat_revised.xlsx')  # íŒŒì¼ëª… ë³€ê²½\n",
    "\n",
    "# ì •ê·œì‹ íŒ¨í„´: ë¬¸ì 1 + ìˆ«ì 3 + _ + ìˆ«ì 3 + ë¬¸ì 1\n",
    "pattern = r'[A-Za-z]\\d{3}_\\d{3}[A-Za-z]'\n",
    "\n",
    "# Q_abstract ì—´ì—ì„œ í•´ë‹¹ íŒ¨í„´ì„ ì œê±°\n",
    "df['Q_abstract'] = df['Q_abstract'].astype(str).apply(lambda x: re.sub(pattern, '', x))\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ (ì„ íƒì‚¬í•­)\n",
    "df.to_excel('EPQA_cleaned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_excel('EPQA_cleaned.xlsx')  # ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½\n",
    "duplicated_rows = df[df.duplicated()]\n",
    "print(f\"ì¤‘ë³µ í–‰ ê°œìˆ˜: {len(duplicated_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1db6a",
   "metadata": {},
   "source": [
    "## EPQA flattening\n",
    "- person-answer ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "728024ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. íŒŒì¼ ë¡œë”©\n",
    "file_path = \"EPQA2.xlsx\"\n",
    "df_person = pd.read_excel(file_path, sheet_name=\"Person\")\n",
    "df_answer = pd.read_excel(file_path, sheet_name=\"Answer\")\n",
    "df_edge_pea = pd.read_excel(file_path, sheet_name=\"Edge_(Pe-A)\")\n",
    "\n",
    "# 2. ì»¬ëŸ¼ëª… ì •ë¦¬\n",
    "df_edge_pea = df_edge_pea.rename(columns={\n",
    "    \"source id\": \"edge_person_id\",\n",
    "    \"target id\": \"edge_answer_id\",\n",
    "    \"source name\": \"person_name\",\n",
    "    \"target name\": \"answer_name\"\n",
    "})\n",
    "df_person = df_person.rename(columns={\n",
    "    \"fullname\": \"person_fullname\",\n",
    "    \"korname\": \"person_korname\",\n",
    "    \"chiname\": \"person_chiname\",\n",
    "    \"middleName\": \"person_middleName\",\n",
    "    \"courtesyName\": \"person_courtesyName\",\n",
    "    \"alias\": \"person_alias\",\n",
    "    \"birthYear\": \"person_birthYear\",\n",
    "    \"deathYear\": \"person_deathYear\",\n",
    "    \"origin\": \"person_origin\",\n",
    "    \"clan\": \"person_clan\",\n",
    "    \"Residence(ë°©ëª©)\": \"person_residence\"\n",
    "})\n",
    "df_answer = df_answer.rename(columns={\n",
    "    \"name\": \"answer_name\",\n",
    "    \"writer\": \"answer_writer\",\n",
    "    \"year\": \"answer_year\",\n",
    "    \"sort\": \"answer_sort\",\n",
    "    \"contents\": \"answer_contents\"\n",
    "})\n",
    "\n",
    "# 3. ë³‘í•©: edge ê¸°ë°˜ ë³‘í•© (edge_hit=True)\n",
    "df_edge_merged = df_edge_pea \\\n",
    "    .merge(df_person, how=\"left\", left_on=\"person_name\", right_on=\"person_fullname\") \\\n",
    "    .merge(df_answer, how=\"left\", on=\"answer_name\")\n",
    "df_edge_merged[\"edge_hit\"] = True  # ì´ê±´ í™•ì‹¤íˆ edgeì—ì„œ ì—°ê²°ëœ ê²ƒ\n",
    "\n",
    "# 4. ë³‘í•©: person-answer ì „ì²´ ì¡°í•© (edgeì™€ ê´€ê³„ì—†ì´)\n",
    "df_all = df_person.merge(df_answer, how=\"outer\", left_on=\"person_fullname\", right_on=\"answer_writer\")\n",
    "\n",
    "# 5. edgeì— í•´ë‹¹í•˜ëŠ” ê²ƒë§Œ Trueë¡œ, ë‚˜ë¨¸ì§€ëŠ” False\n",
    "df_all[\"key\"] = df_all[\"person_fullname\"].astype(str) + \"|\" + df_all[\"answer_name\"].astype(str)\n",
    "df_edge_merged[\"key\"] = df_edge_merged[\"person_fullname\"].astype(str) + \"|\" + df_edge_merged[\"answer_name\"].astype(str)\n",
    "\n",
    "df_all[\"edge_hit\"] = df_all[\"key\"].isin(df_edge_merged[\"key\"])\n",
    "df_all = df_all.drop(columns=[\"key\"])\n",
    "\n",
    "# ğŸ”§ ì¤‘ë³µ ì œê±° í›„ ì•ˆì „í•œ ë§¤í•‘\n",
    "person_name_map = df_edge_pea[[\"answer_name\", \"person_name\"]].drop_duplicates(subset=\"answer_name\") \\\n",
    "                                                             .set_index(\"answer_name\")[\"person_name\"]\n",
    "df_all[\"person_name\"] = df_all[\"answer_name\"].map(person_name_map)\n",
    "# 6. ìµœì¢… ì„ íƒ ì»¬ëŸ¼ (ì•ˆì „í•˜ê²Œ í™•ì¸)\n",
    "columns_to_keep = [col for col in [\n",
    "    \"person_name\", \"person_fullname\", \"person_korname\", \"person_chiname\",\n",
    "    \"person_middleName\", \"person_courtesyName\", \"person_alias\",\n",
    "    \"person_birthYear\", \"person_deathYear\", \"person_origin\", \"person_clan\", \"person_residence\",\n",
    "    \"answer_name\", \"answer_writer\", \"answer_year\", \"answer_sort\", \"answer_contents\",\n",
    "    \"edge_hit\"\n",
    "] if col in df_all.columns]\n",
    "\n",
    "df_result = df_all[columns_to_keep]\n",
    "df_result.to_excel(\"EPQA_PeA_with_edge_hit.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ee619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â— person_name â‰  person_fullname\n",
      "      person_name person_fullname\n",
      "0             NaN             NaN\n",
      "30848    í™©ì„±í•œ(é»ƒè–æ¼¢)             NaN\n"
     ]
    }
   ],
   "source": [
    "df_mismatch = df_complete[df_complete['person_name'] != df_complete['person_fullname']]\n",
    "print(\"â— person_name â‰  person_fullname\")\n",
    "print(df_mismatch[['person_name', 'person_fullname']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c317be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â— person_name â‰  answer_writer\n",
      "      person_name answer_writer        answer_name\n",
      "0             NaN        ê¹€ë‹´(é‡‘æ·¡)  1446ë…„_ì¤‘ì‹œ_ë¬¸ê³¼_â– ì‹œ_ë‹µì•ˆ\n",
      "20            NaN      ì„±ì‚¼ë¬¸(æˆä¸‰å•)  1446ë…„_ì¤‘ì‹œ_ë¬¸ê³¼_â– ì‹œ_ë‹µì•ˆ\n",
      "40         ê¹€ë‹´(é‡‘æ·¡)           NaN  1446ë…„_ì¤‘ì‹œ_ë¬¸ê³¼_â– ì‹œ_ë¬¸ì œ\n",
      "48       ì„±ì‚¼ë¬¸(æˆä¸‰å•)           NaN  1446ë…„_ì¤‘ì‹œ_ë¬¸ê³¼_â– ì‹œ_ë¬¸ì œ\n",
      "56            NaN        ê¹€í”(é‡‘è¨¢)  1471ë…„_ë³„ì‹œ_ë¬¸ê³¼_â– ì‹œ_ë‹µì•ˆ\n",
      "...           ...           ...                ...\n",
      "32862      í•œì¶©(éŸ“å¿ )      ì´ê±´ëª…(æå¥å‘½)                NaN\n",
      "32902      í•œì¶©(éŸ“å¿ )      ì†ëª…ë˜(å­«å‘½ä¾†)                NaN\n",
      "32942      í•œì¶©(éŸ“å¿ )        ì´ë§Œ(ææ§¾)                NaN\n",
      "33022      í•œì¶©(éŸ“å¿ )      ìµœì°½ëŒ€(å´”æ˜Œå¤§)                NaN\n",
      "33062      í•œì¶©(éŸ“å¿ )      ì‹ ì •í•˜(ç”³é–å¤)                NaN\n",
      "\n",
      "[119 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_mismatch = df_complete[df_complete['person_name'] != df_complete['answer_writer']]\n",
    "print(\"â— person_name â‰  answer_writer\")\n",
    "print(df_mismatch[['person_name', 'answer_writer', 'answer_name']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cbe3f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_name</th>\n",
       "      <th>answer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ìœ¤ëŒ€ìˆœ(å°¹å¤§æ·³)</td>\n",
       "      <td>1813ë…„_ì¦ê´‘ì‹œ_ë¬¸ê³¼_ë³µì‹œ_ì¢…ì¥_ë‹µì•ˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë‚˜ì„¸ì°¬(ç¾…ä¸–çº˜)</td>\n",
       "      <td>1527ë…„_ì •ì‹œ_ë¬¸ê³¼_ì´ˆì‹œ_ë‹µì•ˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì˜¤ìƒ(å³ç¥¥)</td>\n",
       "      <td>1531ë…„_ì‹ë…„ì‹œ_ì§„ì‚¬ì‹œ_ë³µì‹œ_ì´ˆì¥_ë‹µì•ˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì •ì² (é„­æ¾ˆ)</td>\n",
       "      <td>1562ë…„_ë³„ì‹œ_ë¬¸ê³¼_ì „ì‹œ_ë‹µì•ˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>í™ì„±ë¯¼(æ´ªè–æ°‘)</td>\n",
       "      <td>1564ë…„_ì‹ë…„ì‹œ_ë¬¸ê³¼_ì „ì‹œ_ë‹µì•ˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>ê³ ë¶€ì²œ(é«˜å‚…å·)</td>\n",
       "      <td>ê³½ìì˜ê¶ì‚¬ê·¹ì¹˜ì§€ë¡ (éƒ­å­å„€çª®å¥¢æ¥µä¾ˆä¹‹è«–)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>ì•ˆí—Œì§•(å®‰ç»å¾µ)</td>\n",
       "      <td>ìš©í¥ì¹˜ìš´ì´ì‹­ìš´(é¾èˆˆè‡´é›²äºŒåéŸ»)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>ìœ¤ì„ ë„(å°¹å–„é“)</td>\n",
       "      <td>ì í™”ì¼ì§€ë¡ (ç°ªèŠ±ä¸€æè«–)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>í™ì„œë´‰(æ´ªç‘é³³)</td>\n",
       "      <td>ì˜ë‹¹ê³½ìì˜ì‚¬ë´‰ë¶„ì–‘ì™•í‘œ(æ“¬å”éƒ­å­å„€è¬å°æ±¾é™½ç‹è¡¨)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>ì´ê²½ì„(ææ™¯å¥­)</td>\n",
       "      <td>ê¸°ì¶•ë³„ì‹œì „ì‹œì±…ë¬¸(å·±ä¸‘åˆ¥è©¦æ®¿è©¦ç­–å•)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    person_name               answer_name\n",
       "0      ìœ¤ëŒ€ìˆœ(å°¹å¤§æ·³)     1813ë…„_ì¦ê´‘ì‹œ_ë¬¸ê³¼_ë³µì‹œ_ì¢…ì¥_ë‹µì•ˆ\n",
       "1      ë‚˜ì„¸ì°¬(ç¾…ä¸–çº˜)         1527ë…„_ì •ì‹œ_ë¬¸ê³¼_ì´ˆì‹œ_ë‹µì•ˆ\n",
       "2        ì˜¤ìƒ(å³ç¥¥)    1531ë…„_ì‹ë…„ì‹œ_ì§„ì‚¬ì‹œ_ë³µì‹œ_ì´ˆì¥_ë‹µì•ˆ\n",
       "3        ì •ì² (é„­æ¾ˆ)         1562ë…„_ë³„ì‹œ_ë¬¸ê³¼_ì „ì‹œ_ë‹µì•ˆ\n",
       "4      í™ì„±ë¯¼(æ´ªè–æ°‘)        1564ë…„_ì‹ë…„ì‹œ_ë¬¸ê³¼_ì „ì‹œ_ë‹µì•ˆ\n",
       "..          ...                       ...\n",
       "256    ê³ ë¶€ì²œ(é«˜å‚…å·)      ê³½ìì˜ê¶ì‚¬ê·¹ì¹˜ì§€ë¡ (éƒ­å­å„€çª®å¥¢æ¥µä¾ˆä¹‹è«–)\n",
       "257    ì•ˆí—Œì§•(å®‰ç»å¾µ)          ìš©í¥ì¹˜ìš´ì´ì‹­ìš´(é¾èˆˆè‡´é›²äºŒåéŸ»)\n",
       "258    ìœ¤ì„ ë„(å°¹å–„é“)              ì í™”ì¼ì§€ë¡ (ç°ªèŠ±ä¸€æè«–)\n",
       "259    í™ì„œë´‰(æ´ªç‘é³³)  ì˜ë‹¹ê³½ìì˜ì‚¬ë´‰ë¶„ì–‘ì™•í‘œ(æ“¬å”éƒ­å­å„€è¬å°æ±¾é™½ç‹è¡¨)\n",
       "260    ì´ê²½ì„(ææ™¯å¥­)        ê¸°ì¶•ë³„ì‹œì „ì‹œì±…ë¬¸(å·±ä¸‘åˆ¥è©¦æ®¿è©¦ç­–å•)\n",
       "\n",
       "[246 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edge_pea[['person_name', 'answer_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a236950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}