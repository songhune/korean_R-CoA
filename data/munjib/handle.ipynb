{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d404716",
   "metadata": {},
   "source": [
    "# WPC 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b391a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 엑셀 파일 경로\n",
    "file_path = \".xlsx\"  # 필요시 경로 수정\n",
    "\n",
    "# 2. 시트 불러오기\n",
    "df_work = pd.read_excel(file_path, sheet_name=\"Work\")\n",
    "df_pub = pd.read_excel(file_path, sheet_name=\"Publication\")\n",
    "df_col = pd.read_excel(file_path, sheet_name=\"Collection\")\n",
    "df_edge_pub_w = pd.read_excel(file_path, sheet_name=\"Edge_(Pub-W)\")\n",
    "df_edge_pub_c = pd.read_excel(file_path, sheet_name=\"Edge_(Pub-C)\")\n",
    "\n",
    "# 3. 병합용 원본 ID 보존\n",
    "df_work[\"work_id_orig\"] = df_work[\"id\"]\n",
    "df_pub[\"pub_id_orig\"] = df_pub[\"id\"]\n",
    "df_col[\"col_id_orig\"] = df_col[\"id\"]\n",
    "\n",
    "# 4. 컬럼 prefix 부여\n",
    "df_work_prefixed = df_work.rename(columns=lambda x: f\"work_{x}\" if x != \"work_id_orig\" else x)\n",
    "df_pub_prefixed = df_pub.rename(columns=lambda x: f\"pub_{x}\" if x != \"pub_id_orig\" else x)\n",
    "df_col_prefixed = df_col.rename(columns=lambda x: f\"col_{x}\" if x != \"col_id_orig\" else x)\n",
    "\n",
    "# 5. 엣지 병합\n",
    "edge_pub_w = df_edge_pub_w.rename(columns={\"source id\": \"pub_id\", \"target id\": \"work_id\"})\n",
    "edge_pub_c = df_edge_pub_c.rename(columns={\"source id\": \"pub_id\", \"target id\": \"col_id\"})\n",
    "pub_core = pd.merge(edge_pub_c, edge_pub_w, on=\"pub_id\", how=\"outer\")\n",
    "\n",
    "# 6. 정보 병합 (ID 기준, prefix 이전 ID 사용)\n",
    "pub_core = pub_core.merge(df_pub_prefixed, left_on=\"pub_id\", right_on=\"pub_id_orig\", how=\"left\")\n",
    "pub_core = pub_core.merge(df_work_prefixed, left_on=\"work_id\", right_on=\"work_id_orig\", how=\"left\")\n",
    "pub_core = pub_core.merge(df_col_prefixed, left_on=\"col_id\", right_on=\"col_id_orig\", how=\"left\")\n",
    "\n",
    "# 7. 연결된 ID 목록 추출\n",
    "linked_work_ids = pub_core['work_id_x'].dropna().unique().tolist()\n",
    "linked_pub_ids = pub_core['pub_id_x'].dropna().unique().tolist()\n",
    "linked_col_ids = pub_core['col_id_x'].dropna().unique().tolist()\n",
    "# 8. 단독 항목 추출\n",
    "solo_work = df_work_prefixed[~df_work_prefixed['work_id_orig'].isin(linked_work_ids)].copy()\n",
    "solo_pub = df_pub_prefixed[~df_pub_prefixed['pub_id_orig'].isin(linked_pub_ids)].copy()\n",
    "solo_col = df_col_prefixed[~df_col_prefixed['col_id_orig'].isin(linked_col_ids)].copy()\n",
    "\n",
    "# 9. 최종 출력 컬럼 정의\n",
    "final_columns = [\n",
    "    'col_id_orig', 'col_name',\n",
    "    'pub_id_orig', 'pub_name',\n",
    "    'work_id_orig', 'work_korname', 'work_chiname',\n",
    "    'work_titleExam', 'work_style', 'work_original', 'work_translation', 'work_url'\n",
    "]\n",
    "\n",
    "# 10. 누락 컬럼 보완 및 정렬\n",
    "for df in [solo_work, solo_pub, solo_col]:\n",
    "    for col in final_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    df = df[final_columns]\n",
    "\n",
    "pub_core_final = pub_core[final_columns]\n",
    "\n",
    "# 11. 전체 병합\n",
    "full_merged = pd.concat([pub_core_final, solo_work, solo_pub, solo_col], ignore_index=True)\n",
    "\n",
    "# 12. 저장\n",
    "full_merged.to_csv(\"full_merged_with_prefix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e773c9b9",
   "metadata": {},
   "source": [
    "## EPQA생성\n",
    "### 1. P-A결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfa105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 경로 설정 ===\n",
    "epqa_path = \"EPQA.xlsx\"\n",
    "\n",
    "# === 시트 로드 (컬럼명 정정 반영)\n",
    "df_person = pd.read_excel(epqa_path, sheet_name=\"Person\").rename(columns={\"id\": \"person_id\"})\n",
    "df_answer = pd.read_excel(epqa_path, sheet_name=\"Answer\").rename(columns={\"id\": \"answer_id\"})  # writer는 그대로 사용\n",
    "df_edge_pea = pd.read_excel(epqa_path, sheet_name=\"Edge_(Pe-A)\").rename(\n",
    "    columns={\"source id\": \"person_id\", \"target id\": \"answer_id\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "# === Step 1: PA 병합 (단독 A, P 포함)\n",
    "# answer 기준 병합\n",
    "df_pa_left = df_answer.merge(df_edge_pea, on=\"answer_id\", how=\"left\") \\\n",
    "                      .merge(df_person, on=\"person_id\", how=\"left\")\n",
    "\n",
    "# person 기준 병합\n",
    "df_pa_right = df_person.merge(df_edge_pea, on=\"person_id\", how=\"left\") \\\n",
    "                       .merge(df_answer, on=\"answer_id\", how=\"left\")\n",
    "\n",
    "# 병합 결과 통합 + 중복 제거\n",
    "df_pa_all = pd.concat([df_pa_left, df_pa_right], ignore_index=True).drop_duplicates(subset=[\"person_id\", \"answer_id\"])\n",
    "\n",
    "# === 작성자 일치 여부 플래그 추가 (writer vs fullname)\n",
    "def check_writer_match(row):\n",
    "    try:\n",
    "        return pd.notna(row[\"writer\"]) and pd.notna(row[\"fullname\"]) and row[\"writer\"].strip() in row[\"fullname\"]\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df_pa_all[\"is_writer_match\"] = df_pa_all.apply(check_writer_match, axis=1)\n",
    "\n",
    "# === 저장: 전체, 일치, 불일치 시트 분리\n",
    "with pd.ExcelWriter(\"step1_PA_flagged.xlsx\") as writer:\n",
    "    df_pa_all.to_excel(writer, index=False, sheet_name=\"PA_ALL\")\n",
    "    df_pa_all[df_pa_all[\"is_writer_match\"] == True].to_excel(writer, index=False, sheet_name=\"PA_Match\")\n",
    "    df_pa_all[df_pa_all[\"is_writer_match\"] == False].to_excel(writer, index=False, sheet_name=\"PA_Mismatch\")\n",
    "\n",
    "print(\"✅ Step 1 (PA) 저장 완료: 전체 {}, 일치 {}, 불일치 {}\".format(\n",
    "    len(df_pa_all),\n",
    "    df_pa_all[\"is_writer_match\"].sum(),\n",
    "    len(df_pa_all) - df_pa_all[\"is_writer_match\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0776b",
   "metadata": {},
   "source": [
    "### 2. (P-A)Q결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05eaf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: 전체 498, A-Q 연결 수 (edge_hit2=True): 346\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. 파일 경로\n",
    "pea_path = \"EPQA_PeA_with_edge_hit.xlsx\"\n",
    "epqa2_path = \"EPQA2.xlsx\"\n",
    "\n",
    "# === 2. Pe-A 결합 결과 불러오기 (edge_hit1 포함)\n",
    "df_pea = pd.read_excel(pea_path)\n",
    "df_pea = df_pea.rename(columns={\"edge_hit\": \"edge_hit1\"})\n",
    "\n",
    "# === 3. A-Q 엣지 및 질문 시트 불러오기 (name 기준)\n",
    "df_edge_aq = pd.read_excel(epqa2_path, sheet_name=\"Edge_(A-Q)\").rename(\n",
    "    columns={\"source name\": \"answer_name\", \"target name\": \"question_name\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "df_question = pd.read_excel(epqa2_path, sheet_name=\"Question\").rename(\n",
    "    columns={\"name\": \"question_name\", \"id\": \"question_id\"}\n",
    ")\n",
    "\n",
    "# === 4. 병합: A-Q 연결 정보 붙이기\n",
    "df_paq = df_pea.merge(df_edge_aq, how=\"left\", on=\"answer_name\") \\\n",
    "               .merge(df_question, how=\"left\", on=\"question_name\")\n",
    "\n",
    "# === 5. edge_hit2 추가: 정밀 매칭 여부 판단\n",
    "df_edge_aq[\"key\"] = df_edge_aq[\"answer_name\"].astype(str) + \"|\" + df_edge_aq[\"question_name\"].astype(str)\n",
    "df_paq[\"key\"] = df_paq[\"answer_name\"].astype(str) + \"|\" + df_paq[\"question_name\"].astype(str)\n",
    "df_paq[\"edge_hit2\"] = df_paq[\"key\"].isin(df_edge_aq[\"key\"])\n",
    "df_paq = df_paq.drop(columns=[\"key\"])\n",
    "\n",
    "# === 6. 저장\n",
    "df_paq.to_excel(\"step2_PeAQ_with_edge_hit2.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ 완료: 전체 {}, A-Q 연결 수 (edge_hit2=True): {}\".format(\n",
    "    len(df_paq),\n",
    "    df_paq[\"edge_hit2\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c275b09",
   "metadata": {},
   "source": [
    "### 3. (P-A-Q)E 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22897f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 4: Answer-Work 합집합 병합 시작 ===\n",
      "원본 PeAQE 데이터: 1734 행\n",
      "유효한 A-W 엣지: 272 개\n",
      "Work 데이터: 865 개\n",
      "\\n=== 합집합 병합 수행 ===\n",
      "Step 4-1: PeAQE + Edge = 10443 행\n",
      "  - Edge 매칭됨: 10193 행\n",
      "  - Edge 없음: 250 행\n",
      "Step 4-2: 최종 병합 = 52901 행\n",
      "  - Work 매칭됨: 42924 행\n",
      "  - Work 없음: 9977 행\n",
      "\\n=== edge_hit4 플래그 결과 ===\n",
      "edge_hit4=True (A∩W): 424 행\n",
      "edge_hit4=False (A-W): 52477 행\n",
      "총합: 52901 행\n",
      "\\n=== 최종 데이터 품질 검증 ===\n",
      "Answer 데이터 보존: 1598 → 29781\n",
      "Work 데이터 추가: 424 행\n",
      "Work 없는 Answer: 52477 행\n",
      "✅ 모든 Answer 데이터 보존됨\n",
      "\\n=== 중복 제거 ===\n",
      "중복 제거: 52901 → 224 행 (-52677)\n",
      "\\n결과 저장: step4_PeAQEW_union_with_edge_hit4.xlsx\n",
      "\\n==================================================\n",
      "합집합 병합 완료!\n",
      "- 전체 데이터: 224 행\n",
      "- Answer+Work: 4 행 (교집합)\n",
      "- Answer만: 220 행 (차집합)\n",
      "- 매칭률: 1.8%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. 경로 설정\n",
    "step2_path = \"step2_PeAQ_with_edge_hit2.xlsx\"\n",
    "epqa2_path = \"EPQA2.xlsx\"\n",
    "\n",
    "# === 2. 이전 병합 파일 불러오기 (edge_hit1, edge_hit2 포함)\n",
    "df_paq = pd.read_excel(step2_path)\n",
    "\n",
    "# === 3. Q-E 엣지 및 Exam 시트 불러오기\n",
    "df_edge_qe = pd.read_excel(epqa2_path, sheet_name=\"Edge_(Q-E)\").rename(\n",
    "    columns={\"source name\": \"question_name\", \"target name\": \"exam_name\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "df_exam = pd.read_excel(epqa2_path, sheet_name=\"Exam\").rename(\n",
    "    columns={\"name\": \"exam_name\", \"id\": \"exam_id\"}\n",
    ")\n",
    "\n",
    "# === 4. 병합: Q-E 연결 및 Exam 정보\n",
    "df_paqe = df_paq.merge(df_edge_qe, how=\"left\", on=\"question_name\") \\\n",
    "                .merge(df_exam, how=\"left\", on=\"exam_name\")\n",
    "\n",
    "# === 5. edge_hit3 계산 (정확히 연결된 Q-E 쌍에 대해서)\n",
    "df_edge_qe[\"key\"] = df_edge_qe[\"question_name\"].astype(str) + \"|\" + df_edge_qe[\"exam_name\"].astype(str)\n",
    "df_paqe[\"key\"] = df_paqe[\"question_name\"].astype(str) + \"|\" + df_paqe[\"exam_name\"].astype(str)\n",
    "df_paqe[\"edge_hit3\"] = df_paqe[\"key\"].isin(df_edge_qe[\"key\"])\n",
    "df_paqe = df_paqe.drop(columns=[\"key\"])\n",
    "\n",
    "# === 6. 저장\n",
    "df_paqe.to_excel(\"step3_PeAQE_with_edge_hit3.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ 완료: 전체 {}, Q-E 연결 수 (edge_hit3=True): {}\".format(\n",
    "    len(df_paqe),\n",
    "    df_paqe[\"edge_hit3\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bed1be",
   "metadata": {},
   "source": [
    "### 4. CPW-EPQA 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c4be74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Edge 매칭 추출 및 플래그 생성 ===\n",
      "📁 Step3: 243 행\n",
      "📁 Edge 원본: 291 행\n",
      "📁 Work 원본: 865 행\n",
      "\\n=== Step 2: Edge 데이터 정제 ===\n",
      "🧹 Edge 정제: 291 → 279 행\n",
      "🧹 Work 정제: 865 → 274 행\n",
      "\\n=== Step 3: 매칭 가능한 Edge 필터링 ===\n",
      "🔗 Step3 매칭 가능: 228/279\n",
      "🔗 양쪽 모두 매칭 가능: 228\n",
      "\\n=== Step 4: Edge 매칭 데이터 추출 ===\n",
      "🔍 Edge 중복 키 확인...\n",
      "⚠️  중복 source id 발견: 23개\n",
      "예시: {'AS16790917': 6, 'AS16330000B': 4, 'AS15550301': 3}\n",
      "🧹 중복 제거: 228 → 193\n",
      "📊 Step3 매칭 추출: 229 행\n",
      "📊 완전 매칭 추출: 229 행\n",
      "\\n=== Step 5: 원본 파일에 플래그 추가 ===\n",
      "📌 Step3 플래그: 229/243 행이 매칭됨\n",
      "📌 Work 플래그: 190/274 행이 매칭됨\n",
      "\\n=== Step 6: 파일 저장 ===\n",
      "💾 Edge 매칭만: edge_matched_only.xlsx (229 행)\n",
      "💾 Step3 + 플래그: step3_with_edge_flag.xlsx (243 행)\n",
      "💾 Work + 플래그: cpw_work_with_edge_flag.xlsx (274 행)\n",
      "\\n============================================================\n",
      "🎉 Edge 매칭 추출 완료!\n",
      "\n",
      "📁 생성된 파일들:\n",
      "   1. edge_matched_only.xlsx: Edge 매칭 데이터만 (229 행)\n",
      "   2. step3_with_edge_flag.xlsx: 원본 Step3 + 플래그 (243 행)\n",
      "   3. cpw_work_with_edge_flag.xlsx: 원본 Work + 플래그 (274 행)\n",
      "\n",
      "📊 매칭 통계:\n",
      "   - Step3 매칭률: 229/243 (94.2%)\n",
      "   - Work 매칭률: 190/274 (69.3%)\n",
      "   - 완전 매칭: 229 행\n",
      "============================================================\n",
      "\\n🔍 Edge 매칭 샘플:\n",
      "   answer_name: 1507년_식년시_복시_답안\n",
      "   work_korname: 과진부\n",
      "   work_style: 賦\n",
      "   source id: AS15070907B\n",
      "   target id: WO1507KK00\n",
      "\\n==================================================\n",
      "📋 상세 분석 보고서\n",
      "==================================================\n",
      "\\n1. Edge 매칭 데이터 분석:\n",
      "   총 매칭: 229 행\n",
      "   주요 문체:\n",
      "     賦: 40개\n",
      "     詩: 38개\n",
      "     策: 36개\n",
      "     表: 25개\n",
      "     疑: 15개\n",
      "   주요 연도:\n",
      "     16■■: 14개\n",
      "     1633: 6개\n",
      "     1605: 5개\n",
      "     1675: 4개\n",
      "     1673: 4개\n",
      "\\n2. 플래그 분석:\n",
      "   Step3: 229/243 매칭\n",
      "   Work: 190/274 매칭\n",
      "\\n✅ 작업 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_edge_matches_only():\n",
    "    \"\"\"\n",
    "    Edge_(A-W) 매칭만 추출 + 원본 파일들에 hit 플래그 추가\n",
    "    \n",
    "    출력:\n",
    "    1. edge_matched_only.xlsx - 292개 매칭 데이터만\n",
    "    2. step3_with_flag.xlsx - 원본 + edge_hit_flag 컬럼\n",
    "    3. cpw_work_with_flag.xlsx - 원본 + edge_hit_flag 컬럼\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== Edge 매칭 추출 및 플래그 생성 ===\")\n",
    "    \n",
    "    # === Step 1: 파일 로드 ===\n",
    "    step3_path = \"step3_PeAQE_with_edge_hit3.xlsx\"\n",
    "    cpw_path = \"CPW.xlsx\"\n",
    "    \n",
    "    df_step3 = pd.read_excel(step3_path, sheet_name=\"Sheet1\")\n",
    "    df_edge_raw = pd.read_excel(cpw_path, sheet_name=\"Edge_(A-W)\")\n",
    "    df_work_raw = pd.read_excel(cpw_path, sheet_name=\"Sheet2\")\n",
    "    \n",
    "    print(f\"📁 Step3: {len(df_step3)} 행\")\n",
    "    print(f\"📁 Edge 원본: {len(df_edge_raw)} 행\")\n",
    "    print(f\"📁 Work 원본: {len(df_work_raw)} 행\")\n",
    "    \n",
    "    # === Step 2: Edge 데이터 정제 ===\n",
    "    print(\"\\\\n=== Step 2: Edge 데이터 정제 ===\")\n",
    "    \n",
    "    # 헤더 행 제거 및 유효 데이터만 필터링\n",
    "    df_edge = df_edge_raw[\n",
    "        (df_edge_raw['source id'] != '소스 식별자') &\n",
    "        (df_edge_raw['source id'].notna()) &\n",
    "        (df_edge_raw['target id'].notna())\n",
    "    ].copy()\n",
    "    \n",
    "    # 중복 제거\n",
    "    df_edge = df_edge.drop_duplicates(\n",
    "        subset=['source id', 'target id']\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"🧹 Edge 정제: {len(df_edge_raw)} → {len(df_edge)} 행\")\n",
    "    \n",
    "    # Work 데이터 정제\n",
    "    df_work = df_work_raw[\n",
    "        df_work_raw['work_id_orig'].notna()\n",
    "    ].drop_duplicates(\n",
    "        subset=['work_id_orig'], keep='first'\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"🧹 Work 정제: {len(df_work_raw)} → {len(df_work)} 행\")\n",
    "    \n",
    "    # === Step 3: 매칭 가능한 Edge만 필터링 ===\n",
    "    print(\"\\\\n=== Step 3: 매칭 가능한 Edge 필터링 ===\")\n",
    "    \n",
    "    # Step3와 매칭 가능한 source id\n",
    "    step3_source_ids = set(df_step3['source id_x'].dropna())\n",
    "    edge_matchable_step3 = df_edge[\n",
    "        df_edge['source id'].isin(step3_source_ids)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"🔗 Step3 매칭 가능: {len(edge_matchable_step3)}/{len(df_edge)}\")\n",
    "    \n",
    "    # Work와 매칭 가능한 target id\n",
    "    work_ids = set(df_work['work_id_orig'])\n",
    "    edge_matchable_both = edge_matchable_step3[\n",
    "        edge_matchable_step3['target id'].isin(work_ids)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"🔗 양쪽 모두 매칭 가능: {len(edge_matchable_both)}\")\n",
    "    \n",
    "    # === Step 4: Edge 매칭 데이터만 추출 ===\n",
    "    print(\"\\\\n=== Step 4: Edge 매칭 데이터 추출 ===\")\n",
    "    \n",
    "    # 4-0: Edge 중복 키 문제 해결\n",
    "    print(\"🔍 Edge 중복 키 확인...\")\n",
    "    edge_dup_check = edge_matchable_both['source id'].value_counts()\n",
    "    duplicated_sources = edge_dup_check[edge_dup_check > 1]\n",
    "    \n",
    "    if len(duplicated_sources) > 0:\n",
    "        print(f\"⚠️  중복 source id 발견: {len(duplicated_sources)}개\")\n",
    "        print(\"예시:\", duplicated_sources.head(3).to_dict())\n",
    "        \n",
    "        # 중복 제거: source id별로 첫 번째만 유지\n",
    "        edge_dedup = edge_matchable_both.drop_duplicates(\n",
    "            subset=['source id'], keep='first'\n",
    "        ).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"🧹 중복 제거: {len(edge_matchable_both)} → {len(edge_dedup)}\")\n",
    "        edge_for_merge = edge_dedup\n",
    "    else:\n",
    "        print(\"✅ 중복 없음\")\n",
    "        edge_for_merge = edge_matchable_both\n",
    "    \n",
    "    # 4-1: Step3 데이터 추출 (Edge와 매칭되는 것만)\n",
    "    df_step3_matched = df_step3.merge(\n",
    "        edge_for_merge[['source id', 'target id', 'source name', 'target name']],\n",
    "        left_on='source id_x',\n",
    "        right_on='source id',\n",
    "        how='inner',  # 매칭되는 것만\n",
    "        validate='m:1'  # 이제 안전해야 함\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Step3 매칭 추출: {len(df_step3_matched)} 행\")\n",
    "    \n",
    "    # 4-2: Work 중복 키 확인 및 해결\n",
    "    work_dup_check = df_work['work_id_orig'].value_counts()\n",
    "    duplicated_works = work_dup_check[work_dup_check > 1]\n",
    "    \n",
    "    if len(duplicated_works) > 0:\n",
    "        print(f\"⚠️  중복 work_id_orig 발견: {len(duplicated_works)}개\")\n",
    "        df_work = df_work.drop_duplicates(\n",
    "            subset=['work_id_orig'], keep='first'\n",
    "        ).reset_index(drop=True)\n",
    "        print(f\"🧹 Work 중복 제거 완료\")\n",
    "    \n",
    "    # 4-3: Work 데이터 추가\n",
    "    df_edge_complete = df_step3_matched.merge(\n",
    "        df_work,\n",
    "        left_on='target id',\n",
    "        right_on='work_id_orig',\n",
    "        how='inner',  # 완전 매칭만\n",
    "        validate='m:1',\n",
    "        suffixes=('', '_work')\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 완전 매칭 추출: {len(df_edge_complete)} 행\")\n",
    "    \n",
    "    # edge_hit4 플래그 (모두 True)\n",
    "    df_edge_complete['edge_hit4'] = True\n",
    "    \n",
    "    # === Step 5: 원본 파일들에 플래그 추가 ===\n",
    "    print(\"\\\\n=== Step 5: 원본 파일에 플래그 추가 ===\")\n",
    "    \n",
    "    # 5-1: Step3에 플래그 추가\n",
    "    df_step3_flagged = df_step3.copy()\n",
    "    \n",
    "    # step3의 각 행이 edge에 매칭되는지 확인 (중복 제거된 edge 사용)\n",
    "    matched_source_ids = set(edge_for_merge['source id'])\n",
    "    df_step3_flagged['edge_hit_flag'] = df_step3_flagged['source id_x'].isin(matched_source_ids)\n",
    "    \n",
    "    step3_hit_count = df_step3_flagged['edge_hit_flag'].sum()\n",
    "    print(f\"📌 Step3 플래그: {step3_hit_count}/{len(df_step3_flagged)} 행이 매칭됨\")\n",
    "    \n",
    "    # 5-2: Work에 플래그 추가\n",
    "    df_work_flagged = df_work.copy()\n",
    "    \n",
    "    # work의 각 행이 edge에 매칭되는지 확인 (중복 제거된 edge 사용)\n",
    "    matched_target_ids = set(edge_for_merge['target id'])\n",
    "    df_work_flagged['edge_hit_flag'] = df_work_flagged['work_id_orig'].isin(matched_target_ids)\n",
    "    \n",
    "    work_hit_count = df_work_flagged['edge_hit_flag'].sum()\n",
    "    print(f\"📌 Work 플래그: {work_hit_count}/{len(df_work_flagged)} 행이 매칭됨\")\n",
    "    \n",
    "    # === Step 6: 저장 ===\n",
    "    print(\"\\\\n=== Step 6: 파일 저장 ===\")\n",
    "    \n",
    "    # 6-1: Edge 매칭만 저장\n",
    "    edge_output = \"edge_matched_only.xlsx\"\n",
    "    df_edge_complete.to_excel(edge_output, index=False)\n",
    "    print(f\"💾 Edge 매칭만: {edge_output} ({len(df_edge_complete)} 행)\")\n",
    "    \n",
    "    # 6-2: Step3 + 플래그 저장\n",
    "    step3_output = \"step3_with_edge_flag.xlsx\"\n",
    "    df_step3_flagged.to_excel(step3_output, index=False)\n",
    "    print(f\"💾 Step3 + 플래그: {step3_output} ({len(df_step3_flagged)} 행)\")\n",
    "    \n",
    "    # 6-3: Work + 플래그 저장\n",
    "    work_output = \"cpw_work_with_edge_flag.xlsx\"\n",
    "    df_work_flagged.to_excel(work_output, index=False)\n",
    "    print(f\"💾 Work + 플래그: {work_output} ({len(df_work_flagged)} 행)\")\n",
    "    \n",
    "    # === Step 7: 결과 요약 ===\n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"🎉 Edge 매칭 추출 완료!\")\n",
    "    print()\n",
    "    print(\"📁 생성된 파일들:\")\n",
    "    print(f\"   1. {edge_output}: Edge 매칭 데이터만 ({len(df_edge_complete)} 행)\")\n",
    "    print(f\"   2. {step3_output}: 원본 Step3 + 플래그 ({len(df_step3_flagged)} 행)\")\n",
    "    print(f\"   3. {work_output}: 원본 Work + 플래그 ({len(df_work_flagged)} 행)\")\n",
    "    print()\n",
    "    print(\"📊 매칭 통계:\")\n",
    "    print(f\"   - Step3 매칭률: {step3_hit_count}/{len(df_step3_flagged)} ({step3_hit_count/len(df_step3_flagged)*100:.1f}%)\")\n",
    "    print(f\"   - Work 매칭률: {work_hit_count}/{len(df_work_flagged)} ({work_hit_count/len(df_work_flagged)*100:.1f}%)\")\n",
    "    print(f\"   - 완전 매칭: {len(df_edge_complete)} 행\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # === Step 8: 샘플 데이터 확인 ===\n",
    "    print(\"\\\\n🔍 Edge 매칭 샘플:\")\n",
    "    if len(df_edge_complete) > 0:\n",
    "        sample = df_edge_complete.iloc[0]\n",
    "        print(f\"   answer_name: {sample.get('answer_name', 'N/A')}\")\n",
    "        print(f\"   work_korname: {sample.get('work_korname', 'N/A')}\")\n",
    "        print(f\"   work_style: {sample.get('work_style', 'N/A')}\")\n",
    "        print(f\"   source id: {sample.get('source id', 'N/A')}\")\n",
    "        print(f\"   target id: {sample.get('target id', 'N/A')}\")\n",
    "    \n",
    "    return {\n",
    "        'edge_matched': df_edge_complete,\n",
    "        'step3_flagged': df_step3_flagged, \n",
    "        'work_flagged': df_work_flagged\n",
    "    }\n",
    "\n",
    "def create_summary_report(results):\n",
    "    \"\"\"\n",
    "    결과 요약 보고서 생성\n",
    "    \"\"\"\n",
    "    if results is None:\n",
    "        return\n",
    "    \n",
    "    edge_df = results['edge_matched']\n",
    "    step3_df = results['step3_flagged']\n",
    "    work_df = results['work_flagged']\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"📋 상세 분석 보고서\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Edge 매칭 분석\n",
    "    print(\"\\\\n1. Edge 매칭 데이터 분석:\")\n",
    "    print(f\"   총 매칭: {len(edge_df)} 행\")\n",
    "    \n",
    "    if len(edge_df) > 0:\n",
    "        # 문체별 분포\n",
    "        if 'work_style' in edge_df.columns:\n",
    "            style_dist = edge_df['work_style'].value_counts().head(5)\n",
    "            print(\"   주요 문체:\")\n",
    "            for style, count in style_dist.items():\n",
    "                print(f\"     {style}: {count}개\")\n",
    "        \n",
    "        # 연도별 분포\n",
    "        if 'year' in edge_df.columns:\n",
    "            year_dist = edge_df['year'].value_counts().head(5)\n",
    "            print(\"   주요 연도:\")\n",
    "            for year, count in year_dist.items():\n",
    "                print(f\"     {year}: {count}개\")\n",
    "    \n",
    "    # 플래그 분석\n",
    "    print(\"\\\\n2. 플래그 분석:\")\n",
    "    step3_true = step3_df['edge_hit_flag'].sum()\n",
    "    work_true = work_df['edge_hit_flag'].sum()\n",
    "    \n",
    "    print(f\"   Step3: {step3_true}/{len(step3_df)} 매칭\")\n",
    "    print(f\"   Work: {work_true}/{len(work_df)} 매칭\")\n",
    "    \n",
    "    print(\"\\\\n✅ 작업 완료!\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    results = extract_edge_matches_only()\n",
    "    create_summary_report(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236964e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
