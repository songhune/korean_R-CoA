{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d404716",
   "metadata": {},
   "source": [
    "# WPC 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b391a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 엑셀 파일 경로\n",
    "file_path = \".xlsx\"  # 필요시 경로 수정\n",
    "\n",
    "# 2. 시트 불러오기\n",
    "df_work = pd.read_excel(file_path, sheet_name=\"Work\")\n",
    "df_pub = pd.read_excel(file_path, sheet_name=\"Publication\")\n",
    "df_col = pd.read_excel(file_path, sheet_name=\"Collection\")\n",
    "df_edge_pub_w = pd.read_excel(file_path, sheet_name=\"Edge_(Pub-W)\")\n",
    "df_edge_pub_c = pd.read_excel(file_path, sheet_name=\"Edge_(Pub-C)\")\n",
    "\n",
    "# 3. 병합용 원본 ID 보존\n",
    "df_work[\"work_id_orig\"] = df_work[\"id\"]\n",
    "df_pub[\"pub_id_orig\"] = df_pub[\"id\"]\n",
    "df_col[\"col_id_orig\"] = df_col[\"id\"]\n",
    "\n",
    "# 4. 컬럼 prefix 부여\n",
    "df_work_prefixed = df_work.rename(columns=lambda x: f\"work_{x}\" if x != \"work_id_orig\" else x)\n",
    "df_pub_prefixed = df_pub.rename(columns=lambda x: f\"pub_{x}\" if x != \"pub_id_orig\" else x)\n",
    "df_col_prefixed = df_col.rename(columns=lambda x: f\"col_{x}\" if x != \"col_id_orig\" else x)\n",
    "\n",
    "# 5. 엣지 병합\n",
    "edge_pub_w = df_edge_pub_w.rename(columns={\"source id\": \"pub_id\", \"target id\": \"work_id\"})\n",
    "edge_pub_c = df_edge_pub_c.rename(columns={\"source id\": \"pub_id\", \"target id\": \"col_id\"})\n",
    "pub_core = pd.merge(edge_pub_c, edge_pub_w, on=\"pub_id\", how=\"outer\")\n",
    "\n",
    "# 6. 정보 병합 (ID 기준, prefix 이전 ID 사용)\n",
    "pub_core = pub_core.merge(df_pub_prefixed, left_on=\"pub_id\", right_on=\"pub_id_orig\", how=\"left\")\n",
    "pub_core = pub_core.merge(df_work_prefixed, left_on=\"work_id\", right_on=\"work_id_orig\", how=\"left\")\n",
    "pub_core = pub_core.merge(df_col_prefixed, left_on=\"col_id\", right_on=\"col_id_orig\", how=\"left\")\n",
    "\n",
    "# 7. 연결된 ID 목록 추출\n",
    "linked_work_ids = pub_core['work_id_x'].dropna().unique().tolist()\n",
    "linked_pub_ids = pub_core['pub_id_x'].dropna().unique().tolist()\n",
    "linked_col_ids = pub_core['col_id_x'].dropna().unique().tolist()\n",
    "# 8. 단독 항목 추출\n",
    "solo_work = df_work_prefixed[~df_work_prefixed['work_id_orig'].isin(linked_work_ids)].copy()\n",
    "solo_pub = df_pub_prefixed[~df_pub_prefixed['pub_id_orig'].isin(linked_pub_ids)].copy()\n",
    "solo_col = df_col_prefixed[~df_col_prefixed['col_id_orig'].isin(linked_col_ids)].copy()\n",
    "\n",
    "# 9. 최종 출력 컬럼 정의\n",
    "final_columns = [\n",
    "    'col_id_orig', 'col_name',\n",
    "    'pub_id_orig', 'pub_name',\n",
    "    'work_id_orig', 'work_korname', 'work_chiname',\n",
    "    'work_titleExam', 'work_style', 'work_original', 'work_translation', 'work_url'\n",
    "]\n",
    "\n",
    "# 10. 누락 컬럼 보완 및 정렬\n",
    "for df in [solo_work, solo_pub, solo_col]:\n",
    "    for col in final_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    df = df[final_columns]\n",
    "\n",
    "pub_core_final = pub_core[final_columns]\n",
    "\n",
    "# 11. 전체 병합\n",
    "full_merged = pd.concat([pub_core_final, solo_work, solo_pub, solo_col], ignore_index=True)\n",
    "\n",
    "# 12. 저장\n",
    "full_merged.to_csv(\"full_merged_with_prefix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e773c9b9",
   "metadata": {},
   "source": [
    "## EPQA생성\n",
    "### 1. P-A결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfa105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 경로 설정 ===\n",
    "epqa_path = \"EPQA.xlsx\"\n",
    "\n",
    "# === 시트 로드 (컬럼명 정정 반영)\n",
    "df_person = pd.read_excel(epqa_path, sheet_name=\"Person\").rename(columns={\"id\": \"person_id\"})\n",
    "df_answer = pd.read_excel(epqa_path, sheet_name=\"Answer\").rename(columns={\"id\": \"answer_id\"})  # writer는 그대로 사용\n",
    "df_edge_pea = pd.read_excel(epqa_path, sheet_name=\"Edge_(Pe-A)\").rename(\n",
    "    columns={\"source id\": \"person_id\", \"target id\": \"answer_id\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "# === Step 1: PA 병합 (단독 A, P 포함)\n",
    "# answer 기준 병합\n",
    "df_pa_left = df_answer.merge(df_edge_pea, on=\"answer_id\", how=\"left\") \\\n",
    "                      .merge(df_person, on=\"person_id\", how=\"left\")\n",
    "\n",
    "# person 기준 병합\n",
    "df_pa_right = df_person.merge(df_edge_pea, on=\"person_id\", how=\"left\") \\\n",
    "                       .merge(df_answer, on=\"answer_id\", how=\"left\")\n",
    "\n",
    "# 병합 결과 통합 + 중복 제거\n",
    "df_pa_all = pd.concat([df_pa_left, df_pa_right], ignore_index=True).drop_duplicates(subset=[\"person_id\", \"answer_id\"])\n",
    "\n",
    "# === 작성자 일치 여부 플래그 추가 (writer vs fullname)\n",
    "def check_writer_match(row):\n",
    "    try:\n",
    "        return pd.notna(row[\"writer\"]) and pd.notna(row[\"fullname\"]) and row[\"writer\"].strip() in row[\"fullname\"]\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df_pa_all[\"is_writer_match\"] = df_pa_all.apply(check_writer_match, axis=1)\n",
    "\n",
    "# === 저장: 전체, 일치, 불일치 시트 분리\n",
    "with pd.ExcelWriter(\"step1_PA_flagged.xlsx\") as writer:\n",
    "    df_pa_all.to_excel(writer, index=False, sheet_name=\"PA_ALL\")\n",
    "    df_pa_all[df_pa_all[\"is_writer_match\"] == True].to_excel(writer, index=False, sheet_name=\"PA_Match\")\n",
    "    df_pa_all[df_pa_all[\"is_writer_match\"] == False].to_excel(writer, index=False, sheet_name=\"PA_Mismatch\")\n",
    "\n",
    "print(\"✅ Step 1 (PA) 저장 완료: 전체 {}, 일치 {}, 불일치 {}\".format(\n",
    "    len(df_pa_all),\n",
    "    df_pa_all[\"is_writer_match\"].sum(),\n",
    "    len(df_pa_all) - df_pa_all[\"is_writer_match\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0776b",
   "metadata": {},
   "source": [
    "### 2. (P-A)Q결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05eaf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: 전체 498, A-Q 연결 수 (edge_hit2=True): 346\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. 파일 경로\n",
    "pea_path = \"EPQA_PeA_with_edge_hit.xlsx\"\n",
    "epqa2_path = \"EPQA2.xlsx\"\n",
    "\n",
    "# === 2. Pe-A 결합 결과 불러오기 (edge_hit1 포함)\n",
    "df_pea = pd.read_excel(pea_path)\n",
    "df_pea = df_pea.rename(columns={\"edge_hit\": \"edge_hit1\"})\n",
    "\n",
    "# === 3. A-Q 엣지 및 질문 시트 불러오기 (name 기준)\n",
    "df_edge_aq = pd.read_excel(epqa2_path, sheet_name=\"Edge_(A-Q)\").rename(\n",
    "    columns={\"source name\": \"answer_name\", \"target name\": \"question_name\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "df_question = pd.read_excel(epqa2_path, sheet_name=\"Question\").rename(\n",
    "    columns={\"name\": \"question_name\", \"id\": \"question_id\"}\n",
    ")\n",
    "\n",
    "# === 4. 병합: A-Q 연결 정보 붙이기\n",
    "df_paq = df_pea.merge(df_edge_aq, how=\"left\", on=\"answer_name\") \\\n",
    "               .merge(df_question, how=\"left\", on=\"question_name\")\n",
    "\n",
    "# === 5. edge_hit2 추가: 정밀 매칭 여부 판단\n",
    "df_edge_aq[\"key\"] = df_edge_aq[\"answer_name\"].astype(str) + \"|\" + df_edge_aq[\"question_name\"].astype(str)\n",
    "df_paq[\"key\"] = df_paq[\"answer_name\"].astype(str) + \"|\" + df_paq[\"question_name\"].astype(str)\n",
    "df_paq[\"edge_hit2\"] = df_paq[\"key\"].isin(df_edge_aq[\"key\"])\n",
    "df_paq = df_paq.drop(columns=[\"key\"])\n",
    "\n",
    "# === 6. 저장\n",
    "df_paq.to_excel(\"step2_PeAQ_with_edge_hit2.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ 완료: 전체 {}, A-Q 연결 수 (edge_hit2=True): {}\".format(\n",
    "    len(df_paq),\n",
    "    df_paq[\"edge_hit2\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c275b09",
   "metadata": {},
   "source": [
    "### 3. (P-A-Q)E 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22897f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: 전체 1734, Q-E 연결 수 (edge_hit3=True): 1428\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. 경로 설정\n",
    "step2_path = \"step2_PeAQ_with_edge_hit2.xlsx\"\n",
    "epqa2_path = \"EPQA2.xlsx\"\n",
    "\n",
    "# === 2. 이전 병합 파일 불러오기 (edge_hit1, edge_hit2 포함)\n",
    "df_paq = pd.read_excel(step2_path)\n",
    "\n",
    "# === 3. Q-E 엣지 및 Exam 시트 불러오기\n",
    "df_edge_qe = pd.read_excel(epqa2_path, sheet_name=\"Edge_(Q-E)\").rename(\n",
    "    columns={\"source name\": \"question_name\", \"target name\": \"exam_name\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "df_exam = pd.read_excel(epqa2_path, sheet_name=\"Exam\").rename(\n",
    "    columns={\"name\": \"exam_name\", \"id\": \"exam_id\"}\n",
    ")\n",
    "\n",
    "# === 4. 병합: Q-E 연결 및 Exam 정보\n",
    "df_paqe = df_paq.merge(df_edge_qe, how=\"left\", on=\"question_name\") \\\n",
    "                .merge(df_exam, how=\"left\", on=\"exam_name\")\n",
    "\n",
    "# === 5. edge_hit3 계산 (정확히 연결된 Q-E 쌍에 대해서)\n",
    "df_edge_qe[\"key\"] = df_edge_qe[\"question_name\"].astype(str) + \"|\" + df_edge_qe[\"exam_name\"].astype(str)\n",
    "df_paqe[\"key\"] = df_paqe[\"question_name\"].astype(str) + \"|\" + df_paqe[\"exam_name\"].astype(str)\n",
    "df_paqe[\"edge_hit3\"] = df_paqe[\"key\"].isin(df_edge_qe[\"key\"])\n",
    "df_paqe = df_paqe.drop(columns=[\"key\"])\n",
    "\n",
    "# === 6. 저장\n",
    "df_paqe.to_excel(\"step3_PeAQE_with_edge_hit3.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ 완료: 전체 {}, Q-E 연결 수 (edge_hit3=True): {}\".format(\n",
    "    len(df_paqe),\n",
    "    df_paqe[\"edge_hit3\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bed1be",
   "metadata": {},
   "source": [
    "### 4. CPW-EPQA 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be3ba1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'Work' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# === 3. A-W 연결 시트 및 Work 시트 불러오기\u001b[39;00m\n\u001b[1;32m     11\u001b[0m df_edge_aw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(cpw_path, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdge_(A-W)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(\n\u001b[1;32m     12\u001b[0m     columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwork_name\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     13\u001b[0m )\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m---> 15\u001b[0m df_work \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpw_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrename(\n\u001b[1;32m     16\u001b[0m     columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwork_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwork_name\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# === 4. A-W 병합: answer_name → work_name → work 정보\u001b[39;00m\n\u001b[1;32m     20\u001b[0m df_peaqew \u001b[38;5;241m=\u001b[39m df_peaqe\u001b[38;5;241m.\u001b[39mmerge(df_edge_aw, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     21\u001b[0m                     \u001b[38;5;241m.\u001b[39mmerge(df_work, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwork_name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/excel/_base.py:508\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/excel/_base.py:1616\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1578\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[1;32m   1597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/excel/_base.py:773\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masheetname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asheetname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 773\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43masheetname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume an integer if not a string\u001b[39;00m\n\u001b[1;32m    775\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py:582\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_if_bad_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook[name]\n",
      "File \u001b[0;32m~/.pyenv/versions/llm/lib/python3.10/site-packages/pandas/io/excel/_base.py:624\u001b[0m, in \u001b[0;36mBaseExcelReader.raise_if_bad_sheet_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_if_bad_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msheet_names:\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorksheet named \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Worksheet named 'Work' not found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 1. 파일 경로\n",
    "step3_path = \"step3_PeAQE_with_edge_hit3.xlsx\"\n",
    "cpw_path = \"CPW.xlsx\"\n",
    "\n",
    "# === 2. 이전 파일 불러오기\n",
    "df_peaqe = pd.read_excel(step3_path)\n",
    "\n",
    "# === 3. A-W 연결 시트 및 Work 시트 불러오기\n",
    "df_edge_aw = pd.read_excel(cpw_path, sheet_name=\"Edge_(A-W)\").rename(\n",
    "    columns={\"source name\": \"answer_name\", \"target name\": \"work_name\"}\n",
    ").dropna().drop_duplicates()\n",
    "\n",
    "df_work = pd.read_excel(cpw_path, sheet_name=\"Work\").rename(\n",
    "    columns={\"id\": \"work_id\", \"name\": \"work_name\"}\n",
    ")\n",
    "\n",
    "# === 4. A-W 병합: answer_name → work_name → work 정보\n",
    "df_peaqew = df_peaqe.merge(df_edge_aw, how=\"left\", on=\"answer_name\") \\\n",
    "                    .merge(df_work, how=\"left\", on=\"work_name\")\n",
    "\n",
    "# === 5. edge_hit4: 정확하게 연결된 answer ↔ work 존재 여부\n",
    "df_edge_aw[\"key\"] = df_edge_aw[\"answer_name\"].astype(str) + \"|\" + df_edge_aw[\"work_name\"].astype(str)\n",
    "df_peaqew[\"key\"] = df_peaqew[\"answer_name\"].astype(str) + \"|\" + df_peaqew[\"work_name\"].astype(str)\n",
    "df_peaqew[\"edge_hit4\"] = df_peaqew[\"key\"].isin(df_edge_aw[\"key\"])\n",
    "df_peaqew = df_peaqew.drop(columns=[\"key\"])\n",
    "\n",
    "# === 6. 저장\n",
    "df_peaqew.to_excel(\"step4_PeAQEW_with_edge_hit4.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ 완료: 전체 {}, A-W 연결 수 (edge_hit4=True): {}\".format(\n",
    "    len(df_peaqew),\n",
    "    df_peaqew[\"edge_hit4\"].sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aff934",
   "metadata": {},
   "source": [
    "## flat 열 핸드크래프트로 정리, 복붙열 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22484176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 엑셀 파일 불러오기\n",
    "df = pd.read_excel('EPQA_flat_revised.xlsx')  # 파일명 변경\n",
    "\n",
    "# 정규식 패턴: 문자 1 + 숫자 3 + _ + 숫자 3 + 문자 1\n",
    "pattern = r'[A-Za-z]\\d{3}_\\d{3}[A-Za-z]'\n",
    "\n",
    "# Q_abstract 열에서 해당 패턴을 제거\n",
    "df['Q_abstract'] = df['Q_abstract'].astype(str).apply(lambda x: re.sub(pattern, '', x))\n",
    "\n",
    "# 결과 저장 (선택사항)\n",
    "df.to_excel('EPQA_cleaned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_excel('EPQA_cleaned.xlsx')  # 실제 파일명으로 변경\n",
    "duplicated_rows = df[df.duplicated()]\n",
    "print(f\"중복 행 개수: {len(duplicated_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1db6a",
   "metadata": {},
   "source": [
    "## EPQA flattening\n",
    "- person-answer 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "728024ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 파일 로딩\n",
    "file_path = \"EPQA2.xlsx\"\n",
    "df_person = pd.read_excel(file_path, sheet_name=\"Person\")\n",
    "df_answer = pd.read_excel(file_path, sheet_name=\"Answer\")\n",
    "df_edge_pea = pd.read_excel(file_path, sheet_name=\"Edge_(Pe-A)\")\n",
    "\n",
    "# 2. 컬럼명 정리\n",
    "df_edge_pea = df_edge_pea.rename(columns={\n",
    "    \"source id\": \"edge_person_id\",\n",
    "    \"target id\": \"edge_answer_id\",\n",
    "    \"source name\": \"person_name\",\n",
    "    \"target name\": \"answer_name\"\n",
    "})\n",
    "df_person = df_person.rename(columns={\n",
    "    \"fullname\": \"person_fullname\",\n",
    "    \"korname\": \"person_korname\",\n",
    "    \"chiname\": \"person_chiname\",\n",
    "    \"middleName\": \"person_middleName\",\n",
    "    \"courtesyName\": \"person_courtesyName\",\n",
    "    \"alias\": \"person_alias\",\n",
    "    \"birthYear\": \"person_birthYear\",\n",
    "    \"deathYear\": \"person_deathYear\",\n",
    "    \"origin\": \"person_origin\",\n",
    "    \"clan\": \"person_clan\",\n",
    "    \"Residence(방목)\": \"person_residence\"\n",
    "})\n",
    "df_answer = df_answer.rename(columns={\n",
    "    \"name\": \"answer_name\",\n",
    "    \"writer\": \"answer_writer\",\n",
    "    \"year\": \"answer_year\",\n",
    "    \"sort\": \"answer_sort\",\n",
    "    \"contents\": \"answer_contents\"\n",
    "})\n",
    "\n",
    "# 3. 병합: edge 기반 병합 (edge_hit=True)\n",
    "df_edge_merged = df_edge_pea \\\n",
    "    .merge(df_person, how=\"left\", left_on=\"person_name\", right_on=\"person_fullname\") \\\n",
    "    .merge(df_answer, how=\"left\", on=\"answer_name\")\n",
    "df_edge_merged[\"edge_hit\"] = True  # 이건 확실히 edge에서 연결된 것\n",
    "\n",
    "# 4. 병합: person-answer 전체 조합 (edge와 관계없이)\n",
    "df_all = df_person.merge(df_answer, how=\"outer\", left_on=\"person_fullname\", right_on=\"answer_writer\")\n",
    "\n",
    "# 5. edge에 해당하는 것만 True로, 나머지는 False\n",
    "df_all[\"key\"] = df_all[\"person_fullname\"].astype(str) + \"|\" + df_all[\"answer_name\"].astype(str)\n",
    "df_edge_merged[\"key\"] = df_edge_merged[\"person_fullname\"].astype(str) + \"|\" + df_edge_merged[\"answer_name\"].astype(str)\n",
    "\n",
    "df_all[\"edge_hit\"] = df_all[\"key\"].isin(df_edge_merged[\"key\"])\n",
    "df_all = df_all.drop(columns=[\"key\"])\n",
    "\n",
    "# 🔧 중복 제거 후 안전한 매핑\n",
    "person_name_map = df_edge_pea[[\"answer_name\", \"person_name\"]].drop_duplicates(subset=\"answer_name\") \\\n",
    "                                                             .set_index(\"answer_name\")[\"person_name\"]\n",
    "df_all[\"person_name\"] = df_all[\"answer_name\"].map(person_name_map)\n",
    "# 6. 최종 선택 컬럼 (안전하게 확인)\n",
    "columns_to_keep = [col for col in [\n",
    "    \"person_name\", \"person_fullname\", \"person_korname\", \"person_chiname\",\n",
    "    \"person_middleName\", \"person_courtesyName\", \"person_alias\",\n",
    "    \"person_birthYear\", \"person_deathYear\", \"person_origin\", \"person_clan\", \"person_residence\",\n",
    "    \"answer_name\", \"answer_writer\", \"answer_year\", \"answer_sort\", \"answer_contents\",\n",
    "    \"edge_hit\"\n",
    "] if col in df_all.columns]\n",
    "\n",
    "df_result = df_all[columns_to_keep]\n",
    "df_result.to_excel(\"EPQA_PeA_with_edge_hit.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ee619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ person_name ≠ person_fullname\n",
      "      person_name person_fullname\n",
      "0             NaN             NaN\n",
      "30848    황성한(黃聖漢)             NaN\n"
     ]
    }
   ],
   "source": [
    "df_mismatch = df_complete[df_complete['person_name'] != df_complete['person_fullname']]\n",
    "print(\"❗ person_name ≠ person_fullname\")\n",
    "print(df_mismatch[['person_name', 'person_fullname']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c317be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ person_name ≠ answer_writer\n",
      "      person_name answer_writer        answer_name\n",
      "0             NaN        김담(金淡)  1446년_중시_문과_■시_답안\n",
      "20            NaN      성삼문(成三問)  1446년_중시_문과_■시_답안\n",
      "40         김담(金淡)           NaN  1446년_중시_문과_■시_문제\n",
      "48       성삼문(成三問)           NaN  1446년_중시_문과_■시_문제\n",
      "56            NaN        김흔(金訢)  1471년_별시_문과_■시_답안\n",
      "...           ...           ...                ...\n",
      "32862      한충(韓忠)      이건명(李健命)                NaN\n",
      "32902      한충(韓忠)      손명래(孫命來)                NaN\n",
      "32942      한충(韓忠)        이만(李槾)                NaN\n",
      "33022      한충(韓忠)      최창대(崔昌大)                NaN\n",
      "33062      한충(韓忠)      신정하(申靖夏)                NaN\n",
      "\n",
      "[119 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_mismatch = df_complete[df_complete['person_name'] != df_complete['answer_writer']]\n",
    "print(\"❗ person_name ≠ answer_writer\")\n",
    "print(df_mismatch[['person_name', 'answer_writer', 'answer_name']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cbe3f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_name</th>\n",
       "      <th>answer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>윤대순(尹大淳)</td>\n",
       "      <td>1813년_증광시_문과_복시_종장_답안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>나세찬(羅世纘)</td>\n",
       "      <td>1527년_정시_문과_초시_답안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>오상(吳祥)</td>\n",
       "      <td>1531년_식년시_진사시_복시_초장_답안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>정철(鄭澈)</td>\n",
       "      <td>1562년_별시_문과_전시_답안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>홍성민(洪聖民)</td>\n",
       "      <td>1564년_식년시_문과_전시_답안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>고부천(高傅川)</td>\n",
       "      <td>곽자의궁사극치지론(郭子儀窮奢極侈之論)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>안헌징(安獻徵)</td>\n",
       "      <td>용흥치운이십운(龍興致雲二十韻)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>윤선도(尹善道)</td>\n",
       "      <td>잠화일지론(簪花一枝論)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>홍서봉(洪瑞鳳)</td>\n",
       "      <td>의당곽자의사봉분양왕표(擬唐郭子儀謝封汾陽王表)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>이경석(李景奭)</td>\n",
       "      <td>기축별시전시책문(己丑別試殿試策問)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    person_name               answer_name\n",
       "0      윤대순(尹大淳)     1813년_증광시_문과_복시_종장_답안\n",
       "1      나세찬(羅世纘)         1527년_정시_문과_초시_답안\n",
       "2        오상(吳祥)    1531년_식년시_진사시_복시_초장_답안\n",
       "3        정철(鄭澈)         1562년_별시_문과_전시_답안\n",
       "4      홍성민(洪聖民)        1564년_식년시_문과_전시_답안\n",
       "..          ...                       ...\n",
       "256    고부천(高傅川)      곽자의궁사극치지론(郭子儀窮奢極侈之論)\n",
       "257    안헌징(安獻徵)          용흥치운이십운(龍興致雲二十韻)\n",
       "258    윤선도(尹善道)              잠화일지론(簪花一枝論)\n",
       "259    홍서봉(洪瑞鳳)  의당곽자의사봉분양왕표(擬唐郭子儀謝封汾陽王表)\n",
       "260    이경석(李景奭)        기축별시전시책문(己丑別試殿試策問)\n",
       "\n",
       "[246 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edge_pea[['person_name', 'answer_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a236950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
