"""
Tongu - Korean Translation System (Clean Version)
ì™„ì „íˆ ì •ë¦¬ëœ í•œêµ­ì–´ ë²ˆì—­ ì‹œìŠ¤í…œ
"""

import asyncio
import sys
import subprocess
import time
import logging
import json
import aiohttp
import pickle
from pathlib import Path
from collections import defaultdict, deque
from datetime import datetime
from typing import List


# =============================================================================
# Configuration
# =============================================================================

class TonguConfig:
    """Tongu ì„¤ì •"""
    
    def __init__(self):
        # Ollama ì„¤ì •
        self.ollama_base_url = "http://localhost:11434"
        self.korean_model = "jinbora/deepseek-r1-Bllossom:70b"
        self.english_model = "winkefinger/alma-13b:Q4_K_M"
        
        # ë²ˆì—­ ì„¤ì • - ìµœì í™”ë¨
        self.batch_size = 15  # 5 â†’ 15 (3ë°° í–¥ìƒ)
        self.max_concurrent = 8  # 3 â†’ 8 (2.7ë°° í–¥ìƒ)
        self.delay_between_batches = 0.5  # 2 â†’ 0.5ì´ˆ (4ë°° í–¥ìƒ)
        self.chunk_size = 100
        
        # ì¬ì‹œë„ ì„¤ì •
        self.max_retries = 3
        self.retry_delay = 30


# =============================================================================
# Error Handler
# =============================================================================

class ErrorHandler:
    """í†µí•© ì—ëŸ¬ ì²˜ë¦¬"""
    
    def __init__(self, email: str = "songhune@jou.ac.kr", threshold: int = 5):
        self.email = email
        self.threshold = threshold
        self.error_counts = defaultdict(lambda: deque())
        self.time_window = 300  # 5ë¶„
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('tongu.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('Tongu')
    
    def track_error(self, error_type: str, message: str, **context):
        """ì—ëŸ¬ ì¶”ì """
        current_time = time.time()
        self.error_counts[error_type].append(current_time)
        
        # ì˜¤ë˜ëœ ì—ëŸ¬ ì œê±°
        cutoff_time = current_time - self.time_window
        while (self.error_counts[error_type] and 
               self.error_counts[error_type][0] < cutoff_time):
            self.error_counts[error_type].popleft()
        
        self.logger.error(f"{error_type}: {message} | {context}")
        
        # ì•Œë¦¼ ì²´í¬
        if len(self.error_counts[error_type]) >= self.threshold:
            self._send_alert(error_type, message, len(self.error_counts[error_type]))
    
    def _send_alert(self, error_type: str, message: str, count: int):
        """ì—ëŸ¬ ì•Œë¦¼ (ì½˜ì†”)"""
        alert = f"""
ğŸš¨ TONGU ERROR ALERT
==================
Type: {error_type}  
Count: {count} errors in 5 minutes
Message: {message}
Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Email: {self.email}
==================
        """
        print(alert)
        self.logger.error(f"ALERT SENT: {error_type} ({count} errors)")


# =============================================================================
# API Client
# =============================================================================

class OllamaClient:
    """Ollama API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, config: TonguConfig, error_handler: ErrorHandler):
        self.config = config
        self.error_handler = error_handler
    
    def _parse_korean_response(self, content: str) -> List[str]:
        """í•œêµ­ì–´ ëª¨ë¸ ì‘ë‹µ íŒŒì‹± (deepseek-r1 ê³„ì—´)"""
        # <think> íƒœê·¸ê°€ ìˆìœ¼ë©´ ì œê±°í•˜ê³  ì‹¤ì œ ë‹µë³€ë§Œ ì¶”ì¶œ
        if '<think>' in content:
            # <think>...</think> ì´í›„ì˜ ì‹¤ì œ ë‹µë³€ ì°¾ê¸°
            parts = content.split('</think>')
            if len(parts) > 1:
                actual_response = parts[-1].strip()
            else:
                # </think>ê°€ ì—†ëŠ” ê²½ìš° <think> ì´í›„ ëª¨ë“  ë‚´ìš©
                actual_response = content.split('<think>')[-1].strip()
        else:
            actual_response = content.strip()
        
        # ì‹¤ì œ ë²ˆì—­ ê²°ê³¼ íŒŒì‹±
        lines = actual_response.split('\n')
        translations = []
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('<') and not line.startswith('å¥½çš„') and not line.startswith('æˆ‘'):
                # ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš° ë²ˆí˜¸ ì œê±°
                if line and line[0].isdigit() and '.' in line[:5]:
                    line = line.split('.', 1)[1].strip()
                if line:
                    translations.append(line)
        
        return translations
    
    def _parse_english_response(self, content: str) -> List[str]:
        """ì˜ì–´ ëª¨ë¸ ì‘ë‹µ íŒŒì‹±"""
        # ë¬¸ì¥ ê¸°ë°˜ìœ¼ë¡œ ë¶„í•  ì‹œë„
        translations = []
        
        # ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš° ë²ˆí˜¸ë³„ë¡œ ë¶„í• 
        if content.count('1.') >= 1 or content.count('2.') >= 1:
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line and not line.lower().startswith('here') and not line.lower().startswith('i'):
                    translations.append(line)
        else:
            # ë‹¨ì¼ ë¸”ë¡ì¸ ê²½ìš° ë¬¸ì¥ìœ¼ë¡œ ë¶„í• 
            sentences = content.split('. ')
            for i, sentence in enumerate(sentences):
                sentence = sentence.strip()
                if sentence:
                    # ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ì•„ë‹ˆë©´ ë§ˆì¹¨í‘œ ì¶”ê°€
                    if i < len(sentences) - 1 and not sentence.endswith('.'):
                        sentence += '.'
                    translations.append(sentence)
        
        return translations
    
    async def translate_batch(self, texts: List[str], target_lang: str, session: aiohttp.ClientSession) -> List[str]:
        """ë°°ì¹˜ ë²ˆì—­"""
        if not texts:
            return []
        
        # ëª¨ë¸ ì„ íƒ
        if target_lang == "korean":
            model = self.config.korean_model
            prompt_template = """ë‹¤ìŒ ê³ ì „ ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í˜„ëŒ€ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. ë²ˆì—­ë¬¸ë§Œ ì œì‹œí•˜ì„¸ìš”:

{texts}

ë²ˆì—­:"""
        else:
            model = self.config.english_model
            prompt_template = """Please translate from Chinese to English:

{texts}

English:"""
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        numbered_texts = "\n".join(f"{i+1}. {text}" for i, text in enumerate(texts))
        prompt = prompt_template.format(texts=numbered_texts)
        
        # ëª¨ë¸ë³„ ì˜µì…˜ ì„¤ì •
        if target_lang == "english":
            options = {
                "temperature": 0.3,
                "top_p": 0.9,
                "max_tokens": 200,
                "stop": ["\n\n", "Chinese:", "Original:"]
            }
        else:
            options = {"temperature": 0.2, "top_p": 0.9}
            
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": False,
            "options": options
        }
        
        try:
            # ê¸´ íƒ€ì„ì•„ì›ƒ ì„¤ì •
            timeout = aiohttp.ClientTimeout(total=300)
            
            async with session.post(f"{self.config.ollama_base_url}/api/generate", 
                                  json=payload, timeout=timeout) as response:
                if response.status == 200:
                    result = await response.json()
                    content = result.get("response", "").strip()
                    
                    if not content:
                        self.error_handler.track_error("Empty Response", f"Model: {model}")
                        return [f"[Error: Empty response]" for _ in texts]
                    
                    # ì‘ë‹µ íŒŒì‹± - ëª¨ë¸ë³„ ì²˜ë¦¬
                    translations = []
                    if target_lang == "korean":
                        # í•œêµ­ì–´ ëª¨ë¸: <think> íƒœê·¸ ì œê±° ë° ì‹¤ì œ ë²ˆì—­ë§Œ ì¶”ì¶œ
                        translations = self._parse_korean_response(content)
                    else:
                        # ì˜ì–´ ëª¨ë¸: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ íŒŒì‹±
                        translations = self._parse_english_response(content)
                    
                    cleaned = []
                    for trans in translations:
                        trans = trans.strip()
                        # ë²ˆí˜¸ ì œê±°
                        if trans and trans[0].isdigit() and '.' in trans[:5]:
                            trans = trans.split('.', 1)[1].strip()
                        if trans:
                            cleaned.append(trans)
                    
                    # ê¸¸ì´ ë§ì¶”ê¸°
                    while len(cleaned) < len(texts):
                        cleaned.append("[Error: Missing translation]")
                    
                    return cleaned[:len(texts)]
                else:
                    error_msg = f"API Error {response.status}"
                    self.error_handler.track_error("API Error", error_msg, model=model)
                    return [f"[Error: {error_msg}]" for _ in texts]
                    
        except (aiohttp.ClientConnectorError, ConnectionResetError, BrokenPipeError) as e:
            self.error_handler.track_error("Connection Error", str(e), model=model)
            return [f"[Error: Connection failed]" for _ in texts]
            
        except asyncio.TimeoutError:
            self.error_handler.track_error("Timeout Error", "Request timeout", model=model)
            return [f"[Error: Timeout]" for _ in texts]
            
        except Exception as e:
            self.error_handler.track_error("Unexpected Error", str(e), model=model)
            return [f"[Error: {str(e)}]" for _ in texts]


# =============================================================================
# Main Translator
# =============================================================================

class TonguTranslator:
    """ë©”ì¸ ë²ˆì—­ê¸°"""
    
    def __init__(self):
        self.config = TonguConfig()
        self.error_handler = ErrorHandler()
        self.client = OllamaClient(self.config, self.error_handler)
        
        # ê°„ë‹¨í•œ ìºì‹œ
        self.cache = {}
        self.cache_file = "tongu_cache.pkl"
        self.load_cache()
        
        # ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
        self.checkpoint_file = "checkpoints/tongu_checkpoint.json"
        self.checkpoint_dir = Path("checkpoints")
        self.checkpoint_dir.mkdir(exist_ok=True)
    
    def load_cache(self):
        """ìºì‹œ ë¡œë“œ"""
        try:
            if Path(self.cache_file).exists():
                with open(self.cache_file, 'rb') as f:
                    self.cache = pickle.load(f)
        except:
            self.cache = {}
    
    def save_cache(self):
        """ìºì‹œ ì €ì¥"""
        try:
            with open(self.cache_file, 'wb') as f:
                pickle.dump(self.cache, f)
        except:
            pass
    
    def save_checkpoint(self, input_file: str, output_file: str, current_batch: int, total_batches: int, processed_count: int):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint_data = {
            "input_file": input_file,
            "output_file": output_file,
            "current_batch": current_batch,
            "total_batches": total_batches,
            "processed_count": processed_count,
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_checkpoint(self) -> dict:
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        try:
            if Path(self.checkpoint_file).exists():
                with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    def get_cache_key(self, text: str, target_lang: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        return f"{target_lang}:{hash(text)}"
    
    async def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.config.ollama_base_url}/api/tags") as response:
                    if response.status == 200:
                        models = await response.json()
                        print("âœ… Ollama ì„œë²„ ì—°ê²° ì„±ê³µ!")
                        print("ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
                        for model in models.get('models', []):
                            print(f"   - {model['name']}")
                        return True
                    else:
                        print("âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
                        return False
        except Exception as e:
            print(f"âŒ ì—°ê²° ì˜¤ë¥˜: {e}")
            self.error_handler.track_error("Connection Test Failed", str(e))
            return False
    
    async def translate_texts(self, texts: List[str], target_lang: str) -> List[str]:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ë²ˆì—­"""
        if not texts:
            return []
        
        # ìºì‹œ í™•ì¸
        cached_results = []
        uncached_texts = []
        uncached_indices = []
        
        for i, text in enumerate(texts):
            cache_key = self.get_cache_key(text, target_lang)
            if cache_key in self.cache:
                cached_results.append((i, self.cache[cache_key]))
            else:
                uncached_texts.append(text)
                uncached_indices.append(i)
        
        # ìƒˆë¡œ ë²ˆì—­í•  í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ API í˜¸ì¶œ
        new_translations = []
        if uncached_texts:
            async with aiohttp.ClientSession() as session:
                new_translations = await self.client.translate_batch(
                    uncached_texts, target_lang, session
                )
            
            # ìƒˆ ë²ˆì—­ì„ ìºì‹œì— ì €ì¥ (ì—ëŸ¬ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
            for text, translation in zip(uncached_texts, new_translations):
                if not translation.startswith("[Error"):
                    cache_key = self.get_cache_key(text, target_lang)
                    self.cache[cache_key] = translation
        
        # ê²°ê³¼ í•©ì¹˜ê¸°
        final_results = [''] * len(texts)
        
        # ìºì‹œëœ ê²°ê³¼ ë°°ì¹˜
        for i, translation in cached_results:
            final_results[i] = translation
        
        # ìƒˆ ë²ˆì—­ ë°°ì¹˜
        for i, translation_idx in enumerate(uncached_indices):
            if i < len(new_translations):
                final_results[translation_idx] = new_translations[i]
        
        return final_results
    
    async def translate_sample(self):
        """ìƒ˜í”Œ ë²ˆì—­"""
        sample_texts = [
            "åˆå‡ä»»éª‘éƒ½å°‰å…‰ç¦„å¤§å¤«ä¾ä¸­ã€‚ç‹è½åœ¨å®«ä¸­å€¼å®¿è­¦å«ï¼Œè°¨æ…è®¤çœŸï¼Œåœ°ä½è¶Šæ˜¯å°Šè´µï¼Œ",
            "åº„ç¨¼ä¸°æ”¶ï¼Œä¹æœˆåæœˆç¦¾ç¨¼ç™»åœºã€‚åˆ¶æˆæ˜¥é…’é£˜æµ“é¦™ï¼Œ"
        ]
        
        print("=== ìƒ˜í”Œ ë²ˆì—­ ì‹œì‘ ===")
        
        # í•œêµ­ì–´ ë²ˆì—­
        korean_translations = await self.translate_texts(sample_texts, "korean")
        print("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ë²ˆì—­:")
        for i, (original, korean) in enumerate(zip(sample_texts, korean_translations)):
            print(f"{i+1}. ì›ë¬¸: {original}")
            print(f"   í•œê¸€: {korean}")
        
        # ì˜ì–´ ë²ˆì—­  
        english_translations = await self.translate_texts(sample_texts, "english")
        print("\nğŸ‡ºğŸ‡¸ ì˜ì–´ ë²ˆì—­:")
        for i, (original, english) in enumerate(zip(sample_texts, english_translations)):
            print(f"{i+1}. ì›ë¬¸: {original}")
            print(f"   ì˜ì–´: {english}")
        
        self.save_cache()
        print("\nâœ… ìƒ˜í”Œ ë²ˆì—­ ì™„ë£Œ!")
    
    async def translate_file(self, input_file: str, output_file: str, resume: bool = False):
        """íŒŒì¼ ë²ˆì—­"""
        if not Path(input_file).exists():
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
            return False
        
        print(f"ğŸ“ íŒŒì¼ ë²ˆì—­: {input_file} -> {output_file}")
        
        # íŒŒì¼ ì½ê¸°
        try:
            with open(input_file, 'r', encoding='utf-8') as f:
                if input_file.endswith('.jsonl'):
                    data = [json.loads(line) for line in f if line.strip()]
                else:
                    data = json.load(f)
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return False
        
        # ì²´í¬í¬ì¸íŠ¸ ì¬ê°œ ì²˜ë¦¬
        start_batch = 0
        processed_items = []
        total_batches = (len(data) - 1) // self.config.batch_size + 1
        
        if resume:
            checkpoint = self.load_checkpoint()
            
            # ì²´í¬í¬ì¸íŠ¸ì˜ input_file ê²½ë¡œ ì •ê·œí™”
            checkpoint_input = checkpoint.get('input_file', '') if checkpoint else ''
            if checkpoint_input.startswith('../../'):
                # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                checkpoint_input_abs = str(Path(input_file).parent.parent / checkpoint_input[6:])
            else:
                checkpoint_input_abs = checkpoint_input
            
            print(f"ğŸ” ê²½ë¡œ ë¹„êµ:")
            print(f"   ì²´í¬í¬ì¸íŠ¸: {checkpoint_input} â†’ {checkpoint_input_abs}")
            print(f"   í˜„ì¬ íŒŒì¼: {input_file}")
            
            # ê²½ë¡œ ë¹„êµ (íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„)
            paths_match = False
            try:
                print(f"ğŸ” ë¬¸ìì—´ ë¹„êµ: {checkpoint_input_abs == input_file}")
                if checkpoint_input_abs == input_file:
                    paths_match = True
                    print("âœ… ë¬¸ìì—´ ê²½ë¡œ ì¼ì¹˜")
                elif Path(checkpoint_input_abs).exists() and Path(input_file).exists():
                    paths_match = Path(checkpoint_input_abs).samefile(Path(input_file))
                    print(f"âœ… íŒŒì¼ ì‹œìŠ¤í…œ ë¹„êµ: {paths_match}")
                else:
                    print(f"âŒ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: checkpoint={Path(checkpoint_input_abs).exists()}, current={Path(input_file).exists()}")
            except Exception as e:
                print(f"âš ï¸ ê²½ë¡œ ë¹„êµ ì˜¤ë¥˜: {e}")
            
            print(f"ğŸ¯ ìµœì¢… ë§¤ì¹­ ê²°ê³¼: {paths_match}")
            
            if checkpoint and paths_match:
                start_batch = checkpoint.get('current_batch', 0)
                processed_count = checkpoint.get('processed_count', 0)
                
                # ê¸°ì¡´ ì¶œë ¥ íŒŒì¼ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©ë“¤ ë¡œë“œ
                if Path(output_file).exists():
                    try:
                        with open(output_file, 'r', encoding='utf-8') as f:
                            for line in f:
                                if line.strip():
                                    processed_items.append(json.loads(line.strip()))
                        print(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ: ë°°ì¹˜ {start_batch}/{total_batches}, ì´ë¯¸ ì²˜ë¦¬ëœ í•­ëª©: {len(processed_items)}ê°œ")
                    except Exception as e:
                        print(f"âš ï¸ ê¸°ì¡´ ì¶œë ¥ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}, ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤")
                        start_batch = 0
                        processed_items = []
            else:
                print("âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì •ë³´ê°€ í˜„ì¬ íŒŒì¼ê³¼ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
        
        print(f"ğŸ“Š ì´ {len(data)}ê°œ í•­ëª© ì²˜ë¦¬ (ë°°ì¹˜ {start_batch + 1}ë¶€í„° ì‹œì‘)")
        
        # ë°°ì¹˜ ì²˜ë¦¬
        for batch_idx in range(start_batch, total_batches):
            start_idx = batch_idx * self.config.batch_size
            end_idx = min(start_idx + self.config.batch_size, len(data))
            batch = data[start_idx:end_idx]
            
            print(f"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ {batch_idx + 1}/{total_batches} (í•­ëª© {start_idx + 1}-{end_idx})")
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            texts = []
            for item in batch:
                if isinstance(item, dict):
                    # ACCN í˜•ì‹ ì²˜ë¦¬
                    if 'data' in item and 'output' in item['data']:
                        texts.append(item['data']['output'])
                    else:
                        texts.append(str(item))
                else:
                    texts.append(str(item))
            
            # ë²ˆì—­
            korean_translations = await self.translate_texts(texts, "korean")
            await asyncio.sleep(self.config.delay_between_batches)
            
            english_translations = await self.translate_texts(texts, "english") 
            await asyncio.sleep(self.config.delay_between_batches)
            
            # ê²°ê³¼ í†µí•©
            batch_results = []
            for original_item, korean, english in zip(batch, korean_translations, english_translations):
                enhanced_item = original_item.copy() if isinstance(original_item, dict) else {"original": original_item}
                enhanced_item.update({
                    "korean_translation": korean,
                    "english_translation": english,
                    "translated_at": datetime.now().isoformat()
                })
                batch_results.append(enhanced_item)
                processed_items.append(enhanced_item)
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ë§¤ ë°°ì¹˜ë§ˆë‹¤)
            self.save_checkpoint(input_file, output_file, batch_idx + 1, total_batches, len(processed_items))
            
            # ì¤‘ê°„ ì €ì¥ (ë§¤ 10ë°°ì¹˜ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ ë°°ì¹˜)
            if (batch_idx + 1) % 10 == 0 or batch_idx + 1 == total_batches:
                try:
                    # ì „ì²´ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì €ì¥
                    with open(output_file, 'w', encoding='utf-8') as f:
                        for item in processed_items:
                            f.write(json.dumps(item, ensure_ascii=False) + '\n')
                    print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {len(processed_items)}ê°œ í•­ëª©")
                except Exception as e:
                    print(f"âš ï¸ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}")
                
                self.save_cache()
        
        # ê²°ê³¼ ì €ì¥
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                for item in processed_items:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
            
            self.save_cache()
            print(f"âœ… ë²ˆì—­ ì™„ë£Œ: {len(processed_items)}ê°œ í•­ëª© ì €ì¥ë¨")
            return True
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    
    async def resume_translation(self):
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë²ˆì—­ ì¬ê°œ"""
        checkpoint = self.load_checkpoint()
        if not checkpoint:
            print("âŒ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
            
        input_path = checkpoint['input_file']
        output_path = checkpoint['output_file']
        current_batch = checkpoint.get('current_batch', 0)
        
        print(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ:")
        print(f"   - ì…ë ¥: {input_path}")
        print(f"   - ì¶œë ¥: {output_path}")
        print(f"   - í˜„ì¬ ë°°ì¹˜: {current_batch}/{checkpoint['total_batches']}")
        print(f"   - ì²˜ë¦¬ëœ í•­ëª©: {checkpoint['processed_count']}ê°œ")
        print(f"   - ë§ˆì§€ë§‰ ì €ì¥: {checkpoint.get('timestamp', 'Unknown')}")
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        if not Path(input_path).is_absolute():
            input_path = str(Path.cwd() / input_path)
        if not Path(output_path).is_absolute():
            output_path = str(Path.cwd() / output_path)
            
        # ì›ë³¸ íŒŒì¼ ê²½ë¡œ ì •ê·œí™” (ìƒëŒ€ ê²½ë¡œ í•´ê²°)
        if input_path.startswith("../../"):
            input_path = str(Path.cwd().parent.parent / input_path[6:])
        
        print(f"   - ì •ê·œí™”ëœ ì…ë ¥: {input_path}")
        
        # ì…ë ¥ì´ ì‹¤ì œ íŒŒì¼ì¸ì§€ ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸
        if Path(input_path).is_file():
            # ì¼ë°˜ íŒŒì¼ ê¸°ë°˜ ì¬ê°œ (ëŒ€ìš©ëŸ‰ íŒŒì¼)
            print(f"ğŸ“„ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ")
            if output_path.endswith("/") or Path(output_path).is_dir():
                # ì¶œë ¥ì´ ë””ë ‰í† ë¦¬ì¸ ê²½ìš° íŒŒì¼ëª… ìƒì„±
                output_path = str(Path(output_path) / "translated_ACCN-INS.jsonl")
            print(f"   - ì¶œë ¥ íŒŒì¼: {output_path}")
            return await self.translate_file(input_path, output_path, resume=True)
        elif Path(input_path).is_dir() or "checkpoints" in output_path:
            # ì²­í¬ ê¸°ë°˜ ì¬ê°œ
            print(f"ğŸ§© ì²­í¬ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ")
            chunks_dir = "checkpoints" if "checkpoints" in output_path else input_path
            output_dir = "translated_chunks"  # ë²ˆì—­ëœ ì²­í¬ ì €ì¥ ë””ë ‰í† ë¦¬
            return await self.translate_chunks(chunks_dir, output_dir, start_chunk=current_batch)
        else:
            print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
            return False
    
    async def translate_chunks(self, chunks_dir: str, output_dir: str, start_chunk: int = 0):
        """ì²­í¬ íŒŒì¼ë“¤ì„ ì—°ì†ìœ¼ë¡œ ì²˜ë¦¬"""
        chunks_path = Path(chunks_dir)
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # ì²­í¬ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì •ë ¬ëœ ìˆœì„œ)
        chunk_files = sorted(chunks_path.glob("ACCN-INS_chunk_*.jsonl"))
        
        if not chunk_files:
            print(f"âŒ {chunks_dir}ì—ì„œ ì²­í¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        total_chunks = len(chunk_files)
        print(f"ğŸ“ ì´ {total_chunks}ê°œ ì²­í¬ íŒŒì¼ ë°œê²¬")
        
        # ì‹œì‘ ì²­í¬ ë²”ìœ„ í™•ì¸
        if start_chunk >= total_chunks:
            print(f"âœ… ëª¨ë“  ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ! (ìš”ì²­: {start_chunk}, ì´: {total_chunks})")
            return True
        
        print(f"ğŸ”„ ì²­í¬ {start_chunk}ë¶€í„° ì²˜ë¦¬ ì‹œì‘")
        
        success_count = 0
        
        for i, chunk_file in enumerate(chunk_files[start_chunk:], start_chunk):
            chunk_name = chunk_file.name
            output_file = output_path / f"translated_{chunk_name}"
            
            # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ìŠ¤í‚µ
            if output_file.exists():
                print(f"â­ï¸ ìŠ¤í‚µ: {chunk_name} (ì´ë¯¸ ì²˜ë¦¬ë¨)")
                success_count += 1
                continue
                
            print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘ [{i+1}/{total_chunks}]: {chunk_name}")
            
            try:
                # ê°œë³„ ì²­í¬ íŒŒì¼ ë²ˆì—­
                success = await self.translate_file(str(chunk_file), str(output_file))
                
                if success:
                    success_count += 1
                    # ì²­í¬ ë‹¨ìœ„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                    self.save_checkpoint(
                        input_file=str(chunks_dir),
                        output_file=str(output_dir), 
                        current_batch=i + 1,
                        total_batches=total_chunks,
                        processed_count=success_count
                    )
                    print(f"âœ… ì™„ë£Œ: {chunk_name}")
                else:
                    print(f"âŒ ì‹¤íŒ¨: {chunk_name}")
                    
            except Exception as e:
                print(f"âŒ ì—ëŸ¬ [{chunk_name}]: {e}")
                self.error_handler.track_error("Chunk Processing Error", str(e), chunk=chunk_name)
        
        print(f"ğŸ‰ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ: {success_count}/{total_chunks}")
        return success_count == total_chunks
    
    def check_ollama_status(self) -> bool:
        """Ollama ìƒíƒœ í™•ì¸"""
        try:
            result = subprocess.run(
                ['curl', '-s', f'{self.config.ollama_base_url}/api/tags'],
                capture_output=True, timeout=10
            )
            return result.returncode == 0
        except:
            return False
    
    def restart_ollama(self) -> bool:
        """Ollama ì¬ì‹œì‘"""
        try:
            print("ğŸ”„ Ollama ì¬ì‹œì‘ ì¤‘...")
            subprocess.run(['pkill', '-f', 'ollama serve'], capture_output=True)
            time.sleep(5)
            
            subprocess.Popen(['ollama', 'serve'], 
                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            time.sleep(15)
            
            return self.check_ollama_status()
        except Exception as e:
            self.error_handler.track_error("Restart Failed", str(e))
            return False


# =============================================================================
# Main Function  
# =============================================================================

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    if len(sys.argv) < 2:
        print("""
ğŸ² Tongu - Korean Translation System (Clean)
============================================

ì‚¬ìš©ë²•:
  python main.py test                    # Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
  python main.py sample                  # ìƒ˜í”Œ ë²ˆì—­
  python main.py translate <input> <output>  # íŒŒì¼ ë²ˆì—­
  python main.py chunks <chunks_dir> <output_dir>  # ì²­í¬ íŒŒì¼ë“¤ ë²ˆì—­
  python main.py resume                  # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
  python main.py restart <command>       # ìë™ ì¬ì‹œì‘ê³¼ í•¨ê»˜

íŠ¹ì§•:
  ğŸ”§ Broken pipe ë¬¸ì œ í•´ê²°
  ğŸš¨ ìë™ ì—ëŸ¬ ì•Œë¦¼ (songhune@jou.ac.kr)
  ğŸ’¾ ë²ˆì—­ ìºì‹±ìœ¼ë¡œ ì†ë„ í–¥ìƒ
  ğŸ“Š ì‹¤ì‹œê°„ ì—ëŸ¬ ëª¨ë‹ˆí„°ë§
  ğŸ§© ì²­í¬ ê¸°ë°˜ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬

ì˜ˆì‹œ:
  python main.py test
  python main.py sample
  python main.py translate input.jsonl output.jsonl
  python main.py chunks checkpoints translated_chunks
  python main.py resume  # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë°”ë¡œ ì¬ê°œ
        """)
        return
    
    command = sys.argv[1]
    translator = TonguTranslator()
    
    try:
        if command == "test":
            success = await translator.test_connection()
            
        elif command == "sample":
            await translator.translate_sample()
            success = True
            
        elif command == "translate":
            if len(sys.argv) != 4:
                print("ì‚¬ìš©ë²•: python main.py translate <input_file> <output_file>")
                return
            success = await translator.translate_file(sys.argv[2], sys.argv[3])
            
        elif command == "chunks":
            if len(sys.argv) != 4:
                print("ì‚¬ìš©ë²•: python main.py chunks <chunks_dir> <output_dir>")
                print("ì˜ˆì‹œ: python main.py chunks checkpoints translated_chunks")
                return
            success = await translator.translate_chunks(sys.argv[2], sys.argv[3])
            
        elif command == "resume":
            # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë‹¨ìˆœ ì¬ê°œ (Ollama ì¬ì‹œì‘ ì—†ìŒ)
            success = await translator.resume_translation()
            
        elif command == "restart":
            # ìë™ ì¬ì‹œì‘ ëª¨ë“œ
            if len(sys.argv) < 3:
                print("ì‚¬ìš©ë²•: python main.py restart <command>")
                print("  sample: ìƒ˜í”Œ ë²ˆì—­ ì‹¤í–‰")
                print("  test: ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
                print("  resume: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë²ˆì—­ ì¬ê°œ")
                return
            
            restart_command = sys.argv[2]
            max_retries = 3
            
            for attempt in range(1, max_retries + 1):
                print(f"ğŸ“‹ ì‹œë„ {attempt}/{max_retries}")
                
                # Ollama ìƒíƒœ í™•ì¸
                if not translator.check_ollama_status():
                    if not translator.restart_ollama():
                        continue
                
                try:
                    if restart_command == "sample":
                        await translator.translate_sample()
                        success = True
                        break
                    elif restart_command == "test":
                        success = await translator.test_connection()
                        break
                    elif restart_command == "resume":
                        success = await translator.resume_translation()
                        break
                    else:
                        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì¬ì‹œì‘ ëª…ë ¹: {restart_command}")
                        success = False
                        break
                        
                except Exception as e:
                    print(f"âŒ ì‹œë„ {attempt} ì‹¤íŒ¨: {e}")
                    translator.error_handler.track_error("Execution Failed", str(e))
                    if attempt < max_retries:
                        time.sleep(30)
                    else:
                        success = False
            
        else:
            print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹: {command}")
            success = False
        
        # ê²°ê³¼ ì¶œë ¥
        if success:
            print("ğŸ‰ ì™„ë£Œ!")
        else:
            print("ğŸ’¥ ì‹¤íŒ¨!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì¤‘ë‹¨ë¨")
        sys.exit(130)
        
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        translator.error_handler.track_error("Unexpected Error", str(e))
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())