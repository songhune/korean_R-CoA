"""ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸"""

import asyncio
import json
from pathlib import Path

from config import TranslationConfig
from translator import LargeScaleTranslator
from cost_tracker import estimate_translation_cost
import aiohttp


async def process_accn_ins_dataset():
    """ACCN-INS ë°ì´í„°ì…‹ ì²˜ë¦¬ í•¨ìˆ˜"""
    
    config = TranslationConfig(
        api_provider="ollama",
        model="winkefinger/alma-13b:Q4_K_M",  # ì˜ì–´ìš© ê¸°ë³¸ ëª¨ë¸
        korean_model="jinbora/deepseek-r1-Bllossom:70b",  # í•œê¸€ ì „ìš© ê³ í’ˆì§ˆ ëª¨ë¸
        english_model="winkefinger/alma-13b:Q4_K_M",  # ì˜ì–´ ì „ìš© ëª¨ë¸
        batch_size=1,      # ë°°ì¹˜ ì‚¬ì´ì¦ˆ 1ë¡œ ì„¤ì • (100% ì„±ê³µë¥ )
        max_concurrent=1,  # ë¡œì»¬ ì²˜ë¦¬ì´ë¯€ë¡œ ë™ì‹œì„± 1ë¡œ ì„¤ì •
        delay_between_batches=0.5,  # ê°œë³„ ì²˜ë¦¬ì´ë¯€ë¡œ ì•½ê°„ì˜ ë”œë ˆì´
        chunk_size=50,     # ì²­í¬ ì‚¬ì´ì¦ˆë„ ì¤„ì„
        checkpoint_interval=25,
        budget_limit=0.0,  # ë¬´ë£Œ
        ollama_base_url="http://localhost:11434"  # ê¸°ë³¸ Ollama URL
    )
    
    translator = LargeScaleTranslator(config)
    
    # ACCN-INS ë°ì´í„°ì…‹ ì²˜ë¦¬
    await translator.process_large_dataset(
        input_file="/home/work/songhune/ACCN-INS.json",  # ì›ë³¸ ACCN-INS íŒŒì¼
        output_file="accn_ins_multilingual.jsonl"  # í•œê¸€/ì˜ì–´ ë²ˆì—­ ì¶”ê°€ëœ íŒŒì¼
    )


async def test_ollama_connection():
    """Ollama ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("http://localhost:11434/api/tags") as response:
                if response.status == 200:
                    models = await response.json()
                    print("âœ… Ollama ì„œë²„ ì—°ê²° ì„±ê³µ!")
                    print("ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
                    for model in models.get('models', []):
                        print(f"   - {model['name']}")
                    return True
                else:
                    print("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return False
    except Exception as e:
        print(f"âŒ Ollama ì—°ê²° ì˜¤ë¥˜: {e}")
        print("\nğŸ”§ í•´ê²° ë°©ë²•:")
        print("1. Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸:")
        print("   curl -fsSL https://ollama.ai/install.sh | sh")
        print("\n2. Ollama ì„œë²„ ì‹œì‘:")
        print("   ollama serve")
        print("\n3. í•„ìš”í•œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ:")
        print("   ollama pull jinbora/deepseek-r1-Bllossom:70b  # í•œê¸€ ë²ˆì—­ìš©")
        print("   ollama pull winkefinger/alma-13b:Q4_K_M      # ì˜ì–´ ë²ˆì—­ìš©")
        return False


async def test_with_sample():
    """ì‘ì€ ìƒ˜í”Œë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸"""
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    sample_data = [
        {
            "task": "Classical Chinese to Modern Chinese",
            "data": {
                "instruction": "è¯·å°†è¿éª‘éƒ½å°‰ã€å…‰ç¦„å¤§å¤«ã€ä¾ä¸­ã€‚å®¿å«è°¨æ••ï¼Œçˆµä½ç›Šå°Šï¼Œç¿»è¯‘ä¸ºç°ä»£æ±‰è¯­ã€‚",
                "input": "",
                "output": "åˆå‡ä»»éª‘éƒ½å°‰å…‰ç¦„å¤§å¤«ä¾ä¸­ã€‚ç‹è½åœ¨å®«ä¸­å€¼å®¿è­¦å«ï¼Œè°¨æ…è®¤çœŸï¼Œåœ°ä½è¶Šæ˜¯å°Šè´µï¼Œ",
                "history": []
            }
        },
        {
            "task": "Classical Chinese to Modern Chinese", 
            "data": {
                "instruction": "å²å¹´ä¸°ç©°ï¼Œä¹åæœˆç¦¾é»ç™»åœºã€‚ä¸ºæ˜¥é…’ç“®æµ®æ–°é…¿ï¼Œ",
                "input": "",
                "output": "åº„ç¨¼ä¸°æ”¶ï¼Œä¹æœˆåæœˆç¦¾ç¨¼ç™»åœºã€‚åˆ¶æˆæ˜¥é…’é£˜æµ“é¦™ï¼Œ",
                "history": []
            }
        }
    ]
    
    # ìƒ˜í”Œ íŒŒì¼ ì €ì¥
    with open("accn_sample.jsonl", "w", encoding="utf-8") as f:
        for item in sample_data:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    config = TranslationConfig(
        api_provider="ollama",
        model="winkefinger/alma-13b:Q4_K_M",
        korean_model="jinbora/deepseek-r1-Bllossom:70b",
        english_model="winkefinger/alma-13b:Q4_K_M",
        batch_size=1,
        max_concurrent=1,
        delay_between_batches=1.0,
        budget_limit=0.0,  # ë¬´ë£Œ ëª¨ë¸
        ollama_base_url="http://localhost:11434"
    )
    
    translator = LargeScaleTranslator(config)
    
    await translator.process_large_dataset(
        input_file="accn_sample.jsonl",
        output_file="accn_sample_translated.jsonl"
    )


async def process_custom_dataset(input_file: str, output_file: str):
    """ì‚¬ìš©ì ì§€ì • ë°ì´í„°ì…‹ ì²˜ë¦¬"""
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(input_file).exists():
        print(f"Error: Input file '{input_file}' not found.")
        return
    
    # Ollamaë¡œ ì²˜ë¦¬ (ë¬´ë£Œ)
    print("=== Ollamaë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ë¬´ë£Œ) ===")
    
    # ì„¤ì •
    config = TranslationConfig(
        api_provider="ollama",
        model="winkefinger/alma-13b:Q4_K_M",
        korean_model="jinbora/deepseek-r1-Bllossom:70b",
        english_model="winkefinger/alma-13b:Q4_K_M",
        batch_size=1,
        max_concurrent=1,
        delay_between_batches=0.5,
        chunk_size=50,
        checkpoint_interval=25,
        budget_limit=0.0,
        ollama_base_url="http://localhost:11434"
    )
    
    translator = LargeScaleTranslator(config)
    
    await translator.process_large_dataset(
        input_file=input_file,
        output_file=output_file
    )


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys
    
    if len(sys.argv) == 1:
        print("KEadapter - ëŒ€ìš©ëŸ‰ ê³ ì „ ì¤‘êµ­ì–´ ë²ˆì—­ê¸°")
        print()
        print("ì‚¬ìš©ë²•:")
        print("  python main.py test                      # Ollama ì—°ê²° í…ŒìŠ¤íŠ¸")
        print("  python main.py sample                    # ìƒ˜í”Œ í…ŒìŠ¤íŠ¸")
        print("  python main.py accn                      # ACCN-INS ë°ì´í„°ì…‹ ì²˜ë¦¬")
        print("  python main.py process <input> <output>  # ì‚¬ìš©ì íŒŒì¼ ì²˜ë¦¬")
        print("  python main.py estimate <file>           # ë¹„ìš© ì¶”ì •")
        print()
        return
    
    command = sys.argv[1]
    
    if command == "test":
        print("=== Ollama ì—°ê²° í…ŒìŠ¤íŠ¸ ===")
        result = asyncio.run(test_ollama_connection())
        if result:
            print("\nâœ… ì¤€ë¹„ ì™„ë£Œ! 'python main.py accn'ìœ¼ë¡œ ë²ˆì—­ì„ ì‹œì‘í•˜ì„¸ìš”.")
    
    elif command == "sample":
        print("=== ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ===")
        asyncio.run(test_with_sample())
    
    elif command == "accn":
        print("=== ACCN-INS ë°ì´í„°ì…‹ ì²˜ë¦¬ ===")
        asyncio.run(process_accn_ins_dataset())
    
    elif command == "process":
        if len(sys.argv) != 4:
            print("ì‚¬ìš©ë²•: python main.py process <input_file> <output_file>")
            return
        
        input_file = sys.argv[2]
        output_file = sys.argv[3]
        
        print(f"=== íŒŒì¼ ì²˜ë¦¬: {input_file} -> {output_file} ===")
        asyncio.run(process_custom_dataset(input_file, output_file))
    
    elif command == "estimate":
        if len(sys.argv) != 3:
            print("ì‚¬ìš©ë²•: python main.py estimate <input_file>")
            return
        
        input_file = sys.argv[2]
        print("Ollama ì‚¬ìš© ì‹œ ë²ˆì—­ ë¹„ìš©: $0.00 (ë¬´ë£Œ)")
    
    else:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {command}")
        print("python main.py ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‚¬ìš©ë²•ì„ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()