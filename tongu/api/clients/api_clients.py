"""API í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ"""

import aiohttp
import backoff
import asyncio
from typing import List, Dict, Any, Tuple
import logging

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from core.config.config import TranslationConfig, APIConfig
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from error_handler import track_broken_pipe_error, track_connection_error, track_model_error


class BaseAPIClient:
    """ê¸°ë³¸ API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, config: TranslationConfig, session: aiohttp.ClientSession):
        self.config = config
        self.session = session
        self.logger = logging.getLogger(self.__class__.__name__)
    
    async def translate_batch(self, texts: List[str], target_lang: str) -> Tuple[List[str], Dict[str, int]]:
        """ë°°ì¹˜ ë²ˆì—­ - ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„"""
        raise NotImplementedError


class OpenAIClient(BaseAPIClient):
    """OpenAI API í´ë¼ì´ì–¸íŠ¸"""
    
    @backoff.on_exception(backoff.expo, Exception, max_tries=3)
    async def translate_batch(self, texts: List[str], target_lang: str) -> Tuple[List[str], Dict[str, int]]:
        """OpenAI APIë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ ë²ˆì—­"""
        target_language = APIConfig.LANGUAGE_MAP.get(target_lang, target_lang)
        
        batch_prompt = f"""
Translate the following Modern Chinese texts to {target_language}. 
These texts are already translated from Classical Chinese to Modern Chinese.
Return ONLY the translations, one per line, maintaining the same order.
Do not include any explanations or numbering.

Texts to translate:
{chr(10).join(f"{i+1}. {text}" for i, text in enumerate(texts))}
"""
        
        headers = {
            "Authorization": f"Bearer {self.config.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.config.model,
            "messages": [
                {"role": "system", "content": f"You are a professional translator specializing in Modern Chinese to {target_language} translation. Focus on preserving the contextual meaning and cultural nuances."},
                {"role": "user", "content": batch_prompt}
            ],
            "temperature": 0.3,
            "max_tokens": len(' '.join(texts)) * 3
        }
        
        endpoint = APIConfig.get_endpoint("openai")
        
        async with self.session.post(endpoint, headers=headers, json=payload) as response:
            if response.status == 200:
                result = await response.json()
                translations = result["choices"][0]["message"]["content"].strip().split('\n')
                
                # ê²°ê³¼ ì •ì œ
                cleaned_translations = self._clean_translations(translations)
                
                # ì‚¬ìš©ëŸ‰ ì •ë³´ (OpenAIëŠ” í† í° ì •ë³´ë¥¼ ì œê³µí•˜ì§€ë§Œ ì¼ë‹¨ ì¶”ì •ê°’ ì‚¬ìš©)
                usage_info = {
                    "input_tokens": len(batch_prompt) // 4,
                    "output_tokens": len(result["choices"][0]["message"]["content"]) // 4
                }
                
                return cleaned_translations[:len(texts)], usage_info
            else:
                error_text = await response.text()
                error_msg = f"OpenAI API Error {response.status}: {error_text}"
                print(f"\nâŒ {error_msg}")
                self.logger.error(error_msg)
                raise Exception(error_msg)
    
    def _clean_translations(self, translations: List[str]) -> List[str]:
        """ë²ˆì—­ ê²°ê³¼ ì •ì œ"""
        cleaned = []
        for trans in translations:
            trans = trans.strip()
            # ë²ˆí˜¸ ì œê±° (1., 2. ë“±)
            if trans and trans[0].isdigit() and '.' in trans[:5]:
                trans = trans.split('.', 1)[1].strip()
            cleaned.append(trans)
        return cleaned


class AnthropicClient(BaseAPIClient):
    """Anthropic Claude API í´ë¼ì´ì–¸íŠ¸"""
    
    @backoff.on_exception(backoff.expo, Exception, max_tries=3)
    async def translate_batch(self, texts: List[str], target_lang: str) -> Tuple[List[str], Dict[str, int]]:
        """Anthropic APIë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ ë²ˆì—­ (ì‚¬ìš©ëŸ‰ ì •ë³´ í¬í•¨)"""
        target_language = APIConfig.LANGUAGE_MAP.get(target_lang, target_lang)
        
        headers = {
            "x-api-key": self.config.api_key,
            "Content-Type": "application/json",
            "anthropic-version": "2023-06-01"
        }
        
        prompt = f"""Translate the following Modern Chinese texts to {target_language}. 
These texts have been translated from Classical Chinese and contain rich contextual information.
Provide accurate, natural translations that preserve the original meaning and cultural context.
Return only the translations, one per line, in the same order:

{chr(10).join(f"{i+1}. {text}" for i, text in enumerate(texts))}"""
        
        payload = {
            "model": self.config.model,
            "max_tokens": len(' '.join(texts)) * 4,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.2
        }
        
        endpoint = APIConfig.get_endpoint("anthropic")
        
        async with self.session.post(endpoint, headers=headers, json=payload) as response:
            if response.status == 200:
                result = await response.json()
                content = result["content"][0]["text"].strip()
                translations = content.split('\n')
                
                # ì‚¬ìš©ëŸ‰ ì •ë³´ ì¶”ì¶œ
                usage = result.get("usage", {})
                usage_info = {
                    "input_tokens": usage.get("input_tokens", len(prompt) // 4),
                    "output_tokens": usage.get("output_tokens", len(content) // 4)
                }
                
                # ê²°ê³¼ ì •ì œ
                cleaned_translations = self._clean_translations(translations, len(texts))
                return cleaned_translations, usage_info
            else:
                error_text = await response.text()
                error_msg = f"Anthropic API Error {response.status}: {error_text}"
                print(f"\nâŒ {error_msg}")
                self.logger.error(error_msg)
                raise Exception(error_msg)
    
    def _clean_translations(self, translations: List[str], expected_count: int) -> List[str]:
        """ë²ˆì—­ ê²°ê³¼ ì •ì œ"""
        cleaned = []
        for trans in translations:
            trans = trans.strip()
            # ë²ˆí˜¸ ì œê±°
            if trans and trans[0].isdigit() and '.' in trans[:5]:
                trans = trans.split('.', 1)[1].strip()
            if trans:  # ë¹ˆ ë²ˆì—­ ë°©ì§€
                cleaned.append(trans)
        
        # ì›ë³¸ê³¼ ê°™ì€ ìˆ˜ê°€ ë˜ë„ë¡ ì¡°ì •
        while len(cleaned) < expected_count:
            cleaned.append("[Translation Error: Missing translation]")
        
        return cleaned[:expected_count]


class OllamaClient(BaseAPIClient):
    """Ollama API í´ë¼ì´ì–¸íŠ¸ - ë¡œì»¬ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸"""
    
    def __init__(self, config: TranslationConfig, session: aiohttp.ClientSession):
        super().__init__(config, session)
        self.base_url = getattr(config, 'ollama_base_url', 'http://localhost:11434')
    
    @backoff.on_exception(backoff.expo, Exception, max_tries=3)
    async def translate_batch(self, texts: List[str], target_lang: str) -> Tuple[List[str], Dict[str, int]]:
        """Ollama APIë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ ë²ˆì—­"""
        target_language = APIConfig.LANGUAGE_MAP.get(target_lang, target_lang)
        
        # ì–¸ì–´ë³„ ëª¨ë¸ ì„ íƒ
        if target_language == "Korean" and hasattr(self.config, 'korean_model') and self.config.korean_model:
            model_to_use = self.config.korean_model
            print(f"ğŸ‡°ğŸ‡· í•œê¸€ ë²ˆì—­ìš© ëª¨ë¸ ì‚¬ìš©: {model_to_use}")
        elif target_language == "English" and hasattr(self.config, 'english_model') and self.config.english_model:
            model_to_use = self.config.english_model
            print(f"ğŸ‡ºğŸ‡¸ ì˜ì–´ ë²ˆì—­ìš© ëª¨ë¸ ì‚¬ìš©: {model_to_use}")
        else:
            model_to_use = self.config.model
        
        if target_language == "Korean":
            prompt = f"""ë‹¤ìŒ í˜„ëŒ€ ì¤‘êµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. ê° í…ìŠ¤íŠ¸ë¥¼ í•œ ì¤„ì”© ë²ˆì—­í•˜ì—¬ ê°™ì€ ìˆœì„œë¡œ ì œê³µí•˜ì„¸ìš”:

{chr(10).join(f"{i+1}. {text}" for i, text in enumerate(texts))}

í•œêµ­ì–´ ë²ˆì—­:"""
        else:
            prompt = f"""Please translate the following Modern Chinese texts to {target_language}:

{chr(10).join(f"{i+1}. {text}" for i, text in enumerate(texts))}

{target_language} translations:
"""
        
        payload = {
            "model": model_to_use,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.2,
                "top_p": 0.9,
                "top_k": 40
            }
        }
        
        endpoint = f"{self.base_url}/api/generate"
        
        try:
            # Set longer timeout for model processing
            timeout = aiohttp.ClientTimeout(total=300, connect=30)  # 5 minutes total, 30s connect
            
            async with self.session.post(endpoint, json=payload, timeout=timeout) as response:
                if response.status == 200:
                    result = await response.json()
                    content = result.get("response", "").strip()
                    
                    # ë¹ˆ ì‘ë‹µ ì²˜ë¦¬
                    if not content:
                        if target_language == "English":
                            # ì´ ëª¨ë¸ì€ ì˜ì–´ ë²ˆì—­ì— ì í•©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
                            print(f"\nâš ï¸ {self.config.model}ì€ ì˜ì–´ ë²ˆì—­ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê±´ë„ˆë›°ëŠ” ì¤‘...")
                            skip_translations = ["[Skip: Model does not support English translation]" for _ in texts]
                            usage_info = {"input_tokens": 0, "output_tokens": 0}
                            return skip_translations, usage_info
                        else:
                            print(f"\nâš ï¸ Ollamaì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤")
                            error_msg = "Empty response from Ollama"
                            track_model_error(error_msg, model=model_to_use, target_lang=target_language)
                            error_translations = ["[Translation Error: Empty response from Ollama]" for _ in texts]
                            usage_info = {"input_tokens": 0, "output_tokens": 0}
                            return error_translations, usage_info
                    
                    translations = content.split('\n')
                    
                    # ì‚¬ìš©ëŸ‰ ì •ë³´ (OllamaëŠ” í† í° ì¹´ìš´íŠ¸ë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¶”ì •)
                    usage_info = {
                        "input_tokens": len(prompt) // 4,  # ëŒ€ëµì  ì¶”ì •
                        "output_tokens": len(content) // 4
                    }
                    
                    # ê²°ê³¼ ì •ì œ
                    cleaned_translations = self._clean_translations(translations, len(texts))
                    return cleaned_translations, usage_info
                else:
                    error_text = await response.text()
                    error_msg = f"Ollama API Error {response.status}: {error_text}"
                    print(f"\nâŒ {error_msg}")
                    raise Exception(error_msg)
        except aiohttp.ClientConnectorError as e:
            error_msg = f"âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨ ({self.base_url}): {str(e)}"
            print(f"\n{error_msg}")
            print("   í•´ê²°ë°©ë²•:")
            print("   1. ollama serve ëª…ë ¹ìœ¼ë¡œ ì„œë²„ ì‹œì‘")
            print(f"   2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ollama pull {self.config.model}")
            print(f"   3. ì„œë²„ URL í™•ì¸: {self.base_url}")
            self.logger.error(error_msg)
            
            # Track connection error for monitoring
            track_connection_error(error_msg, 
                                        model=getattr(self, 'config', {}).get('model', 'unknown'),
                                        base_url=self.base_url,
                                        target_lang=target_lang)
            
            # [Translation Error] í† í°ìœ¼ë¡œ ëª…ì‹œì  í‘œì‹œ
            error_translations = ["[Translation Error: Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨]" for _ in texts]
            usage_info = {"input_tokens": 0, "output_tokens": 0}
            return error_translations, usage_info
            
        except (ConnectionResetError, BrokenPipeError) as e:
            error_msg = f"âŒ ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤ (Broken Pipe): {str(e)}"
            print(f"\n{error_msg}")
            print("   ëŒ€ìš©ëŸ‰ ëª¨ë¸ ì²˜ë¦¬ ì¤‘ ì—°ê²°ì´ ëŠì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("   ì ì‹œ í›„ ì¬ì‹œë„í•˜ê±°ë‚˜ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
            self.logger.error(error_msg)
            
            # Track broken pipe error for monitoring
            track_broken_pipe_error(error_msg,
                                  model=getattr(self, 'config', {}).get('model', 'unknown'),
                                  base_url=self.base_url,
                                  target_lang=target_lang,
                                  batch_size=len(texts))
            
            error_translations = [f"[Translation Error: Connection broken - {str(e)}]" for _ in texts]
            usage_info = {"input_tokens": 0, "output_tokens": 0}
            return error_translations, usage_info
            
        except aiohttp.ServerTimeoutError as e:
            error_msg = f"âŒ ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {str(e)}"
            print(f"\n{error_msg}")
            print("   ëŒ€ìš©ëŸ‰ ëª¨ë¸ì´ ì‘ë‹µí•˜ëŠ”ë° ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            self.logger.error(error_msg)
            
            track_model_error(error_msg,
                                     model=getattr(self, 'config', {}).get('model', 'unknown'),
                                     target_lang=target_lang,
                                     timeout=True)
            
            error_translations = [f"[Translation Error: Timeout - {str(e)}]" for _ in texts]
            usage_info = {"input_tokens": 0, "output_tokens": 0}
            return error_translations, usage_info
            
        except Exception as e:
            error_msg = f"âŒ Ollama API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"
            print(f"\n{error_msg}")
            self.logger.error(error_msg)
            
            # Track general API errors
            track_model_error(error_msg,
                                     model=getattr(self, 'config', {}).get('model', 'unknown'),
                                     target_lang=target_lang,
                                     error_type=type(e).__name__)
            
            # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì •ë³´ì™€ í•¨ê»˜ ì—ëŸ¬ í† í° ë°˜í™˜
            error_translations = [f"[Translation Error: {str(e)}]" for _ in texts]
            usage_info = {"input_tokens": 0, "output_tokens": 0}
            return error_translations, usage_info
    
    def _clean_translations(self, translations: List[str], expected_count: int) -> List[str]:
        """ë²ˆì—­ ê²°ê³¼ ì •ì œ"""
        cleaned = []
        for trans in translations:
            trans = trans.strip()
            # ë²ˆí˜¸ ì œê±°
            if trans and trans[0].isdigit() and '.' in trans[:5]:
                trans = trans.split('.', 1)[1].strip()
            if trans:  # ë¹ˆ ë²ˆì—­ë§Œ ì¶”ê°€
                cleaned.append(trans)
        
        # ì›ë³¸ê³¼ ê°™ì€ ìˆ˜ê°€ ë˜ë„ë¡ ì¡°ì • - ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ë¡œ íŒ¨ë”©
        while len(cleaned) < expected_count:
            cleaned.append("[Translation Error: Empty response]")
        
        return cleaned[:expected_count]


class APIClientFactory:
    """API í´ë¼ì´ì–¸íŠ¸ íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_client(config: TranslationConfig, session: aiohttp.ClientSession) -> BaseAPIClient:
        """ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ API í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        if config.api_provider == "openai":
            return OpenAIClient(config, session)
        elif config.api_provider == "anthropic":
            return AnthropicClient(config, session)
        elif config.api_provider == "ollama":
            return OllamaClient(config, session)
        else:
            raise ValueError(f"Unsupported API provider: {config.api_provider}")