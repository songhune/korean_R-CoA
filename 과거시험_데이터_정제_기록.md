
# 조선시대 과거시험 데이터 정제 및 평탄화(Flattening) 과정

## 작업 목적

초기 데이터는 RDF 구조 기반의 **엣지 중심 데이터셋**으로, 여러 개체(Question, Exam 등)가 `id`를 통해 연결된 구조로 구성되어 있었다.  
그러나 아래와 같은 한계가 존재하였다:

1. **그래프 설계는 이상적이나, 데이터 수집은 초기 단계**
   - 구조상 완비된 knowledge graph처럼 보이지만,
   - 실제로는 `Question`, `Exam`, `Time` 외에는 실질 정보가 없거나 대부분 비어 있었음

2. **RAG/LLM 실용 측면에서 활용 가능한 정보량이 제한됨**
   - 그래프 탐색이나 복잡한 관계 기반 질의에는 한계
   - 결국 실질적으로 사용 가능한 정보는:
     → 시험 정보 (연도/유형/단계) + 문제 텍스트 + 간헐적인 출처

이러한 현실적 한계를 반영하여, 관계 기반 구조를 유지하기보다는 **self-contained flat table 구조로 재편**하는 것이  
LLM 학습이나 QA corpus 구축에 훨씬 적합하다고 판단하였다.

---

## 1. Raw 데이터의 구성

| 시트명 | 설명 |
|--------|------|
| `Question` | 문제 원문과 유형 분류 등이 포함된 주된 질문 데이터 |
| `Exam(소대과)` / `Exam2(기타과거포함)` | 시험 메타정보 (연도, 시험종류, 단계, 출처 등) |
| `Edge(Q-E)` | Question과 Exam 간의 관계 연결 (`source id`, `target id`) |
| 그 외 (`Time`, `Place`, `Person`, `Edge(E)`, `Record` 등) | 실제 값이 거의 없거나, 분석에 불필요하여 제외됨 |

---

## 2. 구조 변환 과정

### 2.1 시험 정보 병합
- `Exam(소대과)`와 `Exam2(기타과거포함)`는 서로를 포함하는 부분집합 관계
- 두 시트를 `id` 기준으로 outer join, `Exam2`의 값을 우선시하여 `merged_exam` 생성
- 시트 내에

### 2.2 핵심 시트만 유지
- 보존: `Question`, `merged_exam`, `Edge(Q-E)`
- 제거: `Exam(소대과)`, `Exam2`, `Time`, `Place`, `Edge(E)`, `Person`, `Record`, `Bangmok` 등

### 2.3 관계 병합
- `Edge(Q-E)`의 `source id` → `Question.id`, `target id` → `merged_exam.id`를 기준으로 병합
- 최종적으로 `question_id`, `question_text`, `exam_year`, `exam_class`, `exam_stage`, `source` 등 메타가 통합된 flat 테이블 생성

---

## 3. 간지 및 윤달 정보 추가

- `question_id`에서 `yyyymmdd` 날짜 추출 (예: `Q17950819SF111` → 1795년 8월 19일)
- `korean_lunar_calendar` 라이브러리를 활용해 다음 정보 추가:
  - `lunar_date`: ISO 포맷 음력
  - `ganji_kr`: 한국식 간지 (예: `기해년 정축월 기축일`)
  - `ganji_cn`: 중국식 간지 (예: `己亥年 丁丑月 己丑日 (閏月)`)
  - `is_leap_month`: `ganji_cn`에 `(閏月)` 포함 여부

### 간지 문자열 정제
- `ganji_kr` / `ganji_cn` 문자열에서 연/월/일 항목을 분리하여 각각 저장
- `(閏月)` 여부를 boolean flag로 추출 (`True` / `False`)

---

## 4. 최종 산출물 컬럼 구조

| 컬럼명 | 설명 |
|--------|------|
| `question_id` | 문제 식별자 |
| `contents` | 문제 본문 |
| `exam_year`, `exam_class`, `exam_stage` | 시험 메타정보 |
| `source`, `source_url` | 출처 및 참고 링크 |
| `lunar_date` | 음력 ISO 형식 (예: `1795-07-12`) |
| `ganji_kr_year`, `ganji_kr_month`, `ganji_kr_day` | 한국식 간지 분리 |
| `ganji_cn_year`, `ganji_cn_month`, `ganji_cn_day` | 중국식 간지 분리 |
| `is_leap_month` | 윤달 여부 (`True` / `False`) |

---

## 기대 효과

- 구조만 존재하던 RDF 데이터를 실질적인 QA corpus로 정제
- 시험 정보 + 문제 텍스트가 결합된 self-contained corpus 구성
- 연·월·일 단위 분석, 간지 필터링, 윤달 특이사항 등의 시간 기반 질의 가능
- 향후 instruction-finetuning, RAG 구축, QA 평가 등에서 직접 사용 가능

---

# 데이터 검증 및 분석 실험

## 실험 1: 데이터 유효성 검증 (EDA)

### 목적
스키마 구조, 결측치, 중복, 분포 등 기본 품질 지표를 산출하고, **Answer 엔티티가 없음**을 명시적으로 확인

### 핵심 작업

#### 1. SPO 트리플 재구축
- **Answer 엔티티 제거**: 원본 데이터에 Answer가 없음을 확인하고 제거된 버전으로 재구축
- **Question 텍스트 3종 속성 매핑**:
  - `hasAbstract`: 짧은 요약/제목
  - `hasContent`: 문제 본문
  - `hasDescription`: 추가 설명
- **엔티티 관계 정의**:
  - `Exam → isHeldOn → Time`
  - `Question → isPartOf → Exam`
  - Exam/Question/Time 각각에 리터럴 속성 추가

#### 2. 해시 기반 ID 생성
- SHA-1 해시 12자리를 사용한 안정적 ID 생성
- 접두사 구분: `E`(Exam), `Q`(Question), `T`(Time)
- 재현성 100% 검증 완료

#### 3. 관계 그래프 시각화
- **스키마 그래프**: 엔티티 타입 간 관계 (Exam-Question-Time)
- **인스턴스 그래프**: 실제 데이터 샘플 (1393-1410년 구간)
- 생성 결과:
  - `schema_graph.png`: 타입 레벨 관계도
  - `instance_graph_rows0_300.png`: 샘플 300개 네트워크
  - `instance_graph_rows0_300.html`: 인터랙티브 버전 (pyvis)

#### 4. 산출물

| 파일명 | 설명 |
|--------|------|
| `triples_no_answer.jsonl` | Answer 제거된 트리플 데이터 (3,348행) |
| `schema_graph.png` | 스키마 레벨 관계도 |
| `instance_graph_*.png/html` | 인스턴스 샘플 네트워크 |
| `edge_density.csv` | 술어별 엣지 밀도 통계 |
| `temporal_flow_base.csv` | 시간 흐름 분석용 기본 테이블 |

---

## 실험 2: 시계열 흐름 및 속성 커버리지 분석

### 목적
과거시험 데이터의 시간적 분포와 엔티티별 속성 완성도를 정량적으로 분석

### 핵심 분석

#### 1. 시계열 흐름 분석
- **연도별 문제 수 변화**: 1393년~1900년대 전 기간 문제 출제 추이
- **단계별(Stage) 시간 변화**: 초시/회시/전시 등 단계별 적층 그래프
- **범주별(Category) 시간 변화**: 賦/表/詩/疑/義/策 등 장르별 추이

#### 2. 엔티티 그래프 분석
- **전체 규모**: 노드 5,469개, 엣지 6,696개
- **트리파르타이트 네트워크**: Time-Exam-Question 3계층 구조
- **노드 크기**: 연결도(degree)에 비례
- **엣지 스타일**:
  - `isHeldOn` (Exam→Time): 굵은 선
  - `isPartOf` (Question→Exam): 얇은 선

#### 3. 링크 완성도 분석
- **Question→Exam 연결**: 완성도 측정
- **Exam→Time 연결**: 완성도 측정
- **Q→E→T 체인**: 전체 체인 완성도 측정

#### 4. 속성 커버리지 히트맵
각 엔티티별 속성 입력 완성도를 %로 시각화:

**Question 속성**:
- Category, Subcategory, Abstract, Content, Source, SourceURL

**Exam 속성**:
- TypeA, TypeB, ExamKind, Stage, Round, RecordTitle, RecordURL

**Time 속성**:
- Year, Month, Day, KR Sexagenary(한국식 간지), CN Sexagenary(중국식 간지)

#### 5. 산출물

| 파일명 | 설명 |
|--------|------|
| `A_schema_small_1393_1410.png` | 1393-1410년 구간 스키마 |
| `B_edge_density.png` | 술어별 엣지 밀도 막대그래프 |
| `C1_questions_per_year.png` | 연도별 문제 수 라인 차트 |
| `C2_stage_over_time.png` | 단계별 시간 변화 (적층) |
| `C3_category_over_time.png` | 범주별 시간 변화 (적층) |
| `A_prime_tripartite_1393_1410.png` | 트리파르타이트 네트워크 (고급) |
| `B_prime_link_completeness.png` | 링크 완성도 퍼널 |
| `B_double_prime_attr_coverage.png` | 속성 커버리지 히트맵 |

---

## 실험 3: Abstract/Content 입력 규칙 검증

### 목적
과시 데이터의 `abstract`와 `content` 필드 입력 규칙을 정량적으로 검증하고, Anthropic Claude API를 활용한 번역 가능성 탐색

### 데이터 규칙 가설
- **규칙 1**: 시/부 등 짧은 운문 → `abstract = content` (동일 입력)
- **규칙 2**: 疑/義/策 등 긴 산문 → `abstract` 비어있고 `content`에 전문

### 핵심 분석

#### 1. 입력 패턴 분류
전체 3,348개 문제를 5가지 패턴으로 분류:

| 패턴 | 개수 | 비율 | 설명 |
|------|------|------|------|
| `Content_Only` | 2,204 | 65.8% | Abstract 미입력, Content에 전문 (긴 내용) |
| `Both_Same` | 533 | 15.9% | Abstract=Content (짧은 원문 그대로) |
| `Neither` | 478 | 14.3% | 둘 다 없음 (데이터 누락) |
| `Abstract_Only` | 94 | 2.8% | Content 누락 (예외 패턴) |
| `Both_Diff` | 39 | 1.2% | Abstract=제목, Content=전문 (주로 策) |

#### 2. 카테고리별 주요 패턴

| 카테고리 | 주요 패턴 | 비율 | Content 평균 길이 | 특징 |
|----------|-----------|------|-------------------|------|
| **賦** | Content_Only | 74.4% | 7.4글자 | 제목만 입력 |
| **表** | Content_Only | 77.0% | 19.0글자 | 비교적 짧음 |
| **詩** | Content_Only | 71.7% | 20.2글자 | 시구 위주 |
| **疑** | Content_Only | 97.6% | 100.5글자 | **거의 모두 긴 내용** |
| **義** | Content_Only | 68.8% | 8.9글자 | 제목/주제어 위주 |
| **策** | Content_Only | 55.5% | 180.1글자 | **가장 긴 산문** |

#### 3. 규칙 검증 결과

**규칙 1 검증**: 짧은 문제는 `Both_Same` 패턴
- 해당 문제: 533개 (15.9%)
- 평균 길이: 22.1글자
- 주요 카테고리: 詩, 義, 賦 등 짧은 형식

**규칙 2 검증**: 긴 내용은 `Content_Only` 패턴
- 해당 문제: 2,204개 (65.8%)
- 평균 길이: 37.3글자 (Both_Same의 **1.7배**)
- 주요 카테고리: 疑 (97.6%), 策 (55.5%) 등 긴 산문

**특이 패턴 발견**: `Both_Diff` (1.2%)
- 주로 **策** 카테고리에서 발생
- Abstract = 짧은 제목/주제어
- Content = 전문
- 예: Abstract="王政之道", Content="王若曰: 帝王之治..."

#### 4. 번역 실험 (Anthropic Claude 3.5 Sonnet)

**샘플 번역 테스트** (5개 문제):
- 한문 원문 → 한국어/영어 번역
- API: `claude-3-5-sonnet-20241022`
- 번역 품질: 양호

**전체 번역 비용 예측**:
- 총 토큰: 약 2.87M (입력 1.42M + 출력 1.46M)
- 예상 비용: **$26.11** (약 ₩35,243)
- 예상 시간: 약 **1시간**
- API 요청 수: 6,884회

*실제 번역은 비용 고려하여 보류 (TRANSLATE_ALL=False)*

#### 5. 산출물

| 파일명 | 설명 |
|--------|------|
| `C1_category_length_comparison.png` | 카테고리별 Abstract/Content 평균 길이 비교 |
| `C2_input_pattern_by_category.png` | 카테고리별 입력 패턴 적층 막대그래프 |
| `input_pattern_stats.csv` | 카테고리×패턴 통계표 |

### 결론

1. **입력 규칙 준수율 높음**: 전체의 81.7% (Both_Same + Content_Only)가 예상 규칙을 따름
2. **카테고리별 특성 명확**: 疑/策는 긴 산문, 詩/賦는 짧은 형식
3. **데이터 품질 양호**: 실질 누락(Neither)은 14.3%로 관리 가능한 수준
4. **번역 가능성 확인**: Claude API를 활용한 대규모 번역이 기술적/비용적으로 실현 가능

